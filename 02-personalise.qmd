
# Personalised tutor

This chapter will teach you how to use AI as a personalised tutor to explain concepts and functions you're struggling to understand, or would like more information on. AI can act as a study partner to explain concepts in multiple ways, but it is not a replacement for your own practice or your lecturer’s guidance. Think of it as a supplement, not a substitute.

It will be helpful to work through these activities with a specific week/chapter/lecture of your course in mind.

## Custom instructions

The key to maximising usefulness is to set up custom instructions (sometimes called “system prompts”). These apply across all chats so the AI remembers who you are and how you like answers to be framed. 

Here's some examples:

> Act as an expert tutor for the programming language R. I am a learner on  the course "Applied Data Skills". I have learned R in my first year and I have reasonably good general computer literacy. I will ask you questions about concepts and functions I do not understand based on my course materials. Always give me concrete examples when you provide an answer. Tailor your responses to my level of expertise. I am using R and RStudio on a Mac and the course will strongly use the tidyverse.

> Act as an expert tutor for the programming language R. I am a first year psychology student at the University of Glasgow and I am learning R for the first time. I have never learned a programming language before and I am not very confident with computers and I am anxious about learning programming. I have a Windows laptop. I will ask you questions about concepts and functions I do not understand based on my course materials. Always give me concrete examples when you provide an answer. Tailor your responses to my level of expertise. I am using R and RStudio and the course will strongly use the tidyverse.

This is mine. It doesn't always follow the instructions but it's much better than without it.

> I am a Professor of Evidence-Informed Education in the School of Psychology and Neuroscience with expertise in cognitive psychology, individual differences, and teaching beginner data skills. You should be formal and give as much detail as possible in your responses. If I ask for code, always give me R code with a tidyverse solution where possible. Always use British spelling. Avoid being sycophantic, hyperbolic, using promotional language, negative parallelisms, or editorializing. Provide evidence for all claims. Preferably peer reviewed and within the last 5 years. 


::: {.callout-note}
## Activity 1

Write your custom instructions and enter them into Copilot. Exactly what information you provide is up to you but make sure that you explain your level of knowledge, skill, confidence and previous experience. If you're using it for coding, you also want to give it some technical information about the software you're using (e.g., R and RStudio) and your operating system (Windows).

- To add your custom instructions in Copilot, click the three dots in the top right corner, then click settings, then Custom Instructions.
:::

## Example questions

Now that you've got your tutor set up, you can ask it questions. Here's some examples:

* Why do I have to learn to code?
* What is the difference between short-term memory and working memory?
* Give me examples of between-subject designs
* What is the difference between a function and an argument?
* Rewrite this explanation in 100 words or less.
* Explain what each part of this code is doing: `ggplot(survey_data, aes(x = wait_time, y = call_time)) +  geom_point()`
* Give me examples of when I would use different joins in R

::: {.callout-note}

## Activity 3

1. Ask the AI three questions based on your course materials for this week. If the output doesn't seem at the right level for you, consider editing your custom instructions and re-running the questions to see how the output changes. 

2. Try asking for two versions of the same answer (e.g., one simple, one more technical) and compare how the content changes.
:::

## Conversation

Another big difference between AI and a regular search engine is that you can have a conversation with it and follow-up on your original question. Some examples:

* Can you explain it again but compare coding in R to doing the same task in Excel?
* Expand on your explanation of `geom_point()`
* Give me another example of code that uses this approach
* Explain it again but in more technical / simpler terms 
* Ask me a question to test if I understand this correctly (*we're going to go into practice testing a lot more in the next chapter*)
* In your answer you said "In this example, c() is a function that combines values into a vector", what is a vector?

## Socratic tutor

Most people use AI as a one-way explainer, but you can also ask it to act like a Socratic tutor. This means instead of giving you the answer straight away, the AI asks you guiding questions so that you recall or work out the idea for yourself. This is important because actively retrieving information strengthens your learning much more than passively re-reading.

Example prompts you can try:

- “Act as a Socratic tutor. Do not tell me the answer yet. Ask me questions to guide me towards understanding correlation vs causation.”
- “Ask me a series of small questions until I can explain what a tibble is.”
“Quiz me step by step on how the function `filter()` works in R. Only give me the next hint if I get stuck.”

Learning often feels easier when you get a clear explanation, but you usually remember more when you struggle productively. The Socratic tutor style is designed to make you work a little, which improves long-term retention.

::: {.callout-note}

## Activity 4

1. Follow up on the responses it gave to your one of your three course questions with a similar prompt to the conversational examples give.

2. Then for another one of the questions, follow-up with a request to check your understanding but acting as a Socratic tutor.
:::

## Be critical

A personalised tutor is most powerful when it amplifies the cognitive processes that drive learning rather than replacing them. Three principles are central:

1. Metacognition: monitor what you do and do not understand, then adjust your strategy and difficulty accordingly. 
2. Desirable difficulties: small, well-scaffolded challenges that require effort improve long-term retention when paired with feedback.
3. Self-explanation: articulating why an answer is right, how a step works, or why an alternative is wrong deepens understanding and transfer. 

Use your AI tutor to create space for retrieval, explanation, and calibration, not to short-circuit them. Based on the three principles, here are some things to watch out for.

- If you provide detailed instructions (“I am anxious, please make it simple”), the AI may default to oversimplification. This risks the [expertise reversal effect](https://en.wikipedia.org/wiki/Expertise_reversal_effect) — information is too shallow once you gain competence.Similarly, if you do not [revisit or revise instructions](https://achemicalorthodoxy.co.uk/2019/10/02/guidance-fading-how-i-do-it/), you may “lock in” a static version of yourself (e.g., always a beginner), preventing growth and calibration.

- Asking the AI questions like “Why do I have to learn to code?” produces an explanation, but does not force you to generate an answer yourself. Research on [retrieval practice](https://www.learningscientists.org/blog/2016/6/23-1) shows that passive review is less effective for long-term retention.

- You may accept AI answers at face value, especially if they “sound fluent.” The [fluency illusion](https://sites.lafayette.edu/rothm/2015/04/08/the-fluency-illusion-and-a-better-way-to-study/) (e.g., when text feels easy to read) can lead to overconfidence.Unlike a lecturer who has genuine expertise, the AI cannot reliably detect specific misconceptions unless prompted very carefully. You might get partial reinforcement for incorrect ideas.

- Learning research shows benefits when you try, fail, and then see the solution. If AI always provides a clean solution first, you miss the benefits of "[desirable difficulities](https://www.learningscientists.org/blog/2017/7/16/weekly-digest-68)". Related, over-time, reliance on AI rather than working through the problem yourself will reduce your resilience, autonomy, and competence - you can only learn and believe you are capable of difficult things if you try and succeed at doing difficult things.


::: {.callout-tip}

## Key takeaways

1. Tell Copilot who you are, what course you’re on, and your level of confidence. This makes answers more tailored.

2. Follow up, ask for comparisons, or request simpler/more technical versions. This is how you refine understanding.

3. Instead of answers, ask Copilot to quiz you step by step. This supports retrieval and deeper learning.

4. AI can be over-confident and sometimes wrong. Always compare to course materials and test your own understanding.

5. Reading an AI explanation is easier than doing the work yourself, but retrieval, practice, and self-explanation build stronger memory.

:::

## Test yourself

```{r}
#| echo: false
library(webexercises)
```

1. Why are custom instructions important when using an AI as a personalised tutor?

```{r}
#| echo: false

opts_custom <- c(
"They ensure the AI can access your private course materials",
"They permanently fix the AI to one topic so it cannot change context",
answer = "They help the AI tailor explanations to your level, background, and software setup",
"They prevent the AI from asking follow-up questions"
)
```

`r longmcq(opts_custom)`

2. The purpose of using a Socratic tutor approach is to:

```{r}
#| echo: false
opts_socratic <- c(
"Get faster and clearer answers from the AI",
answer = "Encourage active recall and deeper learning by answering guided questions",
"Avoid making mistakes during study sessions",
"Replace feedback from human tutors entirely"
)
```

`r longmcq(opts_socratic)`

>

3.Metacognition means monitoring what you r fitb("know", ignore_case = TRUE) and understand, and adapting your learning strategies accordingly.

>

4. What is the expertise reversal effect?

```{r}

#| echo: false

opts_expertise <- c(
"When experts deliberately study beginner materials to refresh their skills",
answer = "When instructional support that benefits novices becomes counterproductive once you gain competence",
"When guidance that once helped becomes unhelpful as your knowledge increases",
"When AI stops following your custom instructions due to system updates"
)

```

`r longmcq(opts_expertise)`

>

5. According to research on desirable difficulties, what kind of learning conditions lead to stronger long-term retention?

```{r}
#| echo: false

opts_difficulties <- c("Effortless practice with immediate, perfect answers", answer = "Small, effortful challenges that require thought and feedback", "Passive rereading of well-written AI explanations", "Only working on tasks you already find easy"
)

```



