
# Code review

*Written by Emily Nordmann*

::: {.callout-important}
In the interests of transparency, this chapter and the next are the ones I am least comfortable writing and I'd like to clearly acknowledge that I am barely one step ahead of you as a learner. Any constructive feedback is entirely welcome. 
:::

In this chapter you'll learn how to use AI to perform a code review and to add comments to your code. As you've already hopefully learned by working through this book, you have to be critical about anything the AI produces or suggests because it has no expert knowledge, but it can be a useful tool for checking and improving your code.

DeBruine et al's [Code Check Guide](https://code-check-club.github.io/code-review-guide/) details what a comprehensive code check refers to:

* Does it run? Can a researcher who uses that progamming language run it easily? Are any unusual or complex procedures explained?
* Is it reproducible? Do you get the same outputs? Is it straightforward to check them?
* Is it auditable/understandable? Even if you don’t have the expertise to assess the stats or data processing, is the code well-organised enough to figure out what is intended so mistakes could be detected? Are the outputs sufficiently detailed to allow interrogation?
* Does it follow best practices? Is there too much repeated code that could benefit from modularisation? DRY (Don’t repeat yourself) and SPOT (Single Point of Truth)? Are the outputs of long processes saved and loaded from file? Are there unit tests? Do the variable names make sense? Do the results match what is shown in the output and there is no rounding up or down?
* Is it correct and appropriate? Is the code actually doing what is intended? Is what is intended correct? Some logical problems can be caught without domain knowledge, such as intending to to filter out male subjects, but actually filtering them IN. Many other problems require domain and/or statistical knowledge, so may only be appropriate in some circumstances.

However, some of these steps cannot (and should not) be performed by an AI. Unless you have specific ethical approval and have included this in your data management plan, you should **never** upload your research data to an AI tool. This means that assessing reproducibility is difficult. The AI also doesn't know what you *intended* to do, and why, and has no subject knowledge so it can't advise on anything theoretical without you giving it that information explicitly.

Therefore, what we'll focus on in this chapter is two components of code review: **comments**  and **refactoring** your code.

## Code comments

Code comments are lines or sections of text added within the code itself that are ignored by the computer when the program runs. They're there for human readers, not machines. In R, you add comments to code by adding `#` to the start of the string:

```{r}
# this is a comment

# compute the mean of three numbers
mean(c(1,2,3))

```

Comments are useful for several reasons:

* Clarification: They explain what certain parts of the code do, making it easier for others (and yourself) to understand the logic and flow of the code.
* Documentation: They provide information on how the code works or why certain decisions were made, which is helpful for future reference.
* Debugging: Temporarily commenting out parts of code can help isolate sections that may be causing errors, without deleting the code.
* Collaboration: In team projects, comments can be used to communicate with other developers about the status or purpose of the code.

Overall, comments are a crucial part of writing clean, maintainable, and collaborative code. They help make the code more accessible and understandable to anyone who might work on it in the future.

For transparency, Gemini and Copilot wrote the above text.

## Activity 1: Add comments with AI

First we'll use use the `palmerpenguins` dataset again.

```{r warning=FALSE, message=FALSE}
library(tidyverse)
library(palmerpenguins)
data("penguins")
```

You can use AI tools to help add comments to your code. We'll start with a simple prompt to see how it gets on. In your chosen platform, input the below code with the prompt:

> Add comments to this code

```{r eval = FALSE}
penguins_clean <- penguins %>%
  filter(complete.cases(.)) %>%
  mutate(across(where(is.factor), as.character)) %>%
  mutate(species_sex = interaction(species, sex, sep = "_"))
```


```{r img-comment1, echo=FALSE, fig.cap="Adding comments"}

knitr::include_graphics("include/images/05-review/comment1.png")

```

A few things to note:

* The AI can only tell you **what** the code is doing, it can't say **why** you chose to do that. In this example, we've created a new column that combines species and sex but the comment gives us no idea what the rationale was for this. The more complex your analysis, the more crucial it becomes to explain the rationale.
* The initial attempt at adding comments is quite verbose. Gemini was not as bad as ChatGPT, but even in the above example there's a bit more than is really necessary. I'd argue you could delete one of the comments in each section and it would still be clear. Too many comments are a different problem to too few, but they're still a problem.
* In the above example, Gemini has also made the strange decision to make the code itself more verbose and it has removed the piping and split it into three different calls which isn't ideal.

## Activity 2: Comment prompt engineering

Let's see if we can amend our prompt to get the comments more aligned with what we want.

> Add comments to this code. Keep the comments as concise as possible Ask me any questions about the code if you are not sure what it is doing or why. Do not change anything about the code. 

Copilot produced the following (and the output from ChatGPT and Gemini was very similar), which is much better. 

```{r}
# Assigning the cleaned data to 'penguins_clean'
penguins_clean <- penguins %>%
  # Filtering out rows with missing values
  filter(complete.cases(.)) %>%
  # Converting all factor columns to character type
  mutate(across(where(is.factor), as.character)) %>%
  # Creating a new column 'species_sex' with combined 'species' and 'sex' information
  mutate(species_sex = interaction(species, sex, sep = "_"))

```


## Activity 3: Review existing comments

In addition to asking AI to comment your code, you can also ask it to review comments you've made yourself. To see how this works with a more complex example, and as an act of masochism, I gave the AI some code I wrote for a publication. The full paper [is here](https://link.springer.com/article/10.1007/s10734-024-01201-5) if you're interested - the quant analyses ended up being punted to the online appendix because of word count.

You can load in the dataset yourself with this code:

```{r warning=FALSE, message=FALSE}
# read in data but skip rows 2 and 3
col_names <- names(read_csv("https://osf.io/download/tf3xs/", n_max = 0))
dat_raw <- read_csv("https://osf.io/download/tf3xs/", col_names = col_names, skip = 3) 
```

The first section of my code involved quite a complicated and long bit of wrangling, all done in a single pipeline. The purpose of the code is to clean up data collected on the survey platform Qualtrics and recoding some of the demographic variables. Despite it's length, this is actually a shortened version because the original hit the character limit for Copilot. I did put some effort into writing comments before publication but there are almost certainly improvements to be made. 

```{r eval = TRUE} 
dat <- dat_raw%>%
  filter(Progress > 94, # remove incomplete responses
         DistributionChannel != "preview") %>% # Remove Emily's preview data
  select(ResponseId, "duration" = 5, Q5:Q21) %>%
  # replace NAs with "none" for disability info
  mutate(disability_nos = replace_na(disability_nos, "None"),
         physical_chronic = replace_na(physical_chronic, "None"),
         mental_health = replace_na(mental_health, "None"),
) %>%
  # recode disability data
  mutate(disability = case_when(# neurodivergent 
                                  neurotype == "Neurodivergent" &
                                  physical_chronic == "None" &
                                  mental_health == "None" & 
                                  disability_nos == "None" ~
                                  "Neurodivergent",
                                 # disabled
                                  neurotype == "Neurotypical" &
                                  physical_chronic == "Physical, mobility, or chronic health condition" |
                                  mental_health == "Mental health condition" |
                                  disability_nos == "Disability not otherwise specified" ~
                                  "Disabled",
                                 # multiple conditions
                                 (neurotype == "Neurodivergent" & mental_health != "None") |
      (neurotype == "Neurodivergent" & physical_chronic != "None") |
      (neurotype == "Neurodivergent" & disability_nos != "None") |
      (mental_health != "None" & physical_chronic != "None") |
      (mental_health != "None" & disability_nos != "None") |
      (physical_chronic != "None" & disability_nos != "None") ~ "NDD",
                                
                                TRUE ~ "Neurotypical & non-disabled"))%>%
  # select necessary columns and tidy up the names
        select(ResponseId,
             "age" = Q5,
             "gender" = Q6,
             "mature" = Q7,
             "level_study" = Q8,
             "country" = Q9,
             "subject" = Q10,
             "english_first" = Q11,
             disability,
             "neurotype_open" = Q13, 
             "disability_open" = Q14,
             "why_open" = Q18,
             "how_open" = Q23,
             "advantages" = Q20,
             "disadvantages" = Q21,
             everything()) 
```

My initial attempt at this used the following prompt:

> Review my use of comments and make improvements to the comments where necessary. Explain what you changed and why. 

* As well as giving me an explanation in the chat window, Gemini added the explanation to the comments themselves, so you'd need to go and edit these out (or amend the prompt to tell it not to do this). 
* It has picked up where the logic of the comments might not be helpful to someone who doesn't already know the data e.g., (explain logic), which is useful.
* Extremely problematically,  it didn't just change the comments, it changed the code. The original first use of `select()` was `select(ResponseId, "duration" = 5, Q5:Q21) %>%`. In this code, I selected the columns I wanted but I also renamed the 5th column. Gemini has changed the code to remove this from select and has instead create a new column named `duration` that will contain the value 5. I didn't ask it to do this and in its response, it doesn't tell me anywhere that it made this change. **Be very, very careful**.

```{r eval=FALSE}
dat_gemini <- dat_raw %>%
  # Filter incomplete responses and remove preview data (for clarity)
  filter(Progress > 94, DistributionChannel != "preview") %>%
  # Select core columns and create a "duration" column (more specific)
  select(ResponseId, Q5:Q21) %>%
  mutate(
    duration = 5,  # Assuming duration is constant at 5, explain if not
    # Replace NAs in disability info with "None" (clearer intent)
    disability_nos = replace_na(disability_nos, "None"),
    physical_chronic = replace_na(physical_chronic, "None"),
    mental_health = replace_na(mental_health, "None")
  ) %>%
  # Recode disability data into more informative categories (explain logic)
  mutate(disability = case_when(
    # Neurodivergent with no other conditions
    neurotype == "Neurodivergent" &
      physical_chronic == "None" &
      mental_health == "None" &
      disability_nos == "None" ~ "Neurodivergent",
    # Disabled with any reported condition
    neurotype == "Neurotypical" &
      (physical_chronic != "None" |  # Include "OR" for clarity
       mental_health != "None" |
       disability_nos != "None") ~ "Disabled",
    # Multiple conditions (explain groupings)
    (neurotype == "Neurodivergent" &
      (physical_chronic != "None" |
       mental_health != "None" |
       disability_nos != "None")) |
    (physical_chronic != "None" &
     (mental_health != "None" |
      disability_nos != "None")) |
    (mental_health != "None" & disability_nos != "None") ~ "NDD"  # Define NDD acronym
    , TRUE ~ "Neurotypical & non-disabled")) %>%
  # Select final columns and rename for clarity
  select(ResponseId,
         age = Q5,
         gender = Q6,
         mature = Q7,
         level_study = Q8,
         country = Q9,
         subject = Q10,
         english_first = Q11,
         disability,
         neurotype_open = Q13,
         disability_open = Q14,
         why_open = Q18,
         how_open = Q23,
         advantages = Q20,
         disadvantages = Q21,
         everything())

```


> Explanation of Changes:

> Clarity: Added more specific explanations to comments, especially for variable creation and data manipulation steps.

>Logic: Explained the reasoning behind the recoding logic in the case_when statements for disability and gender.

> Conciseness: Shortened some comments where brevity is sufficient.

> Acronyms: Defined the acronym "NDD" for better understanding.

> Consistency: Used consistent formatting for comments (e.g., indentation).

> These improvements enhance the readability and maintainability of your code, making it easier for you or others to understand the purpose of each step.

### More prompt engineering

Again I played about with the prompt to try and prevent these issues:

> Review my use of comments and make improvements to the comments where necessary. Keep the comments as concise as possible. Do not change anything about the code. 

Copilot introduces an error almost straight away - the filter keeps responses with progress over 94% but it claims the opposite. 

```{r}
# Assigning the processed data to 'dat'
dat_copilot <- dat_raw %>%
  # Filtering out responses with progress over 94% and excluding preview data
  filter(Progress > 94, # Remove incomplete responses
         DistributionChannel != "preview") %>% # Exclude preview data
  # Selecting specific columns by ResponseId and renaming column 5 to 'duration'
  select(ResponseId, "duration" = 5, Q5:Q21) %>%
  # Replacing NA values with "None" in disability-related columns
  mutate(disability_nos = replace_na(disability_nos, "None"),
         physical_chronic = replace_na(physical_chronic, "None"),
         mental_health = replace_na(mental_health, "None"),
  ) %>%
  # Recoding disability categories based on conditions
  mutate(disability = case_when(
    # Classify as 'Neurodivergent' if only neurotype is divergent
    neurotype == "Neurodivergent" &
    physical_chronic == "None" &
    mental_health == "None" & 
    disability_nos == "None" ~ "Neurodivergent",
    # Classify as 'Disabled' if any disability condition is met
    neurotype == "Neurotypical" &
    (physical_chronic == "Physical, mobility, or chronic health condition" |
     mental_health == "Mental health condition" |
     disability_nos == "Disability not otherwise specified") ~ "Disabled",
    # Classify as 'NDD' for multiple conditions including neurodivergence
    (neurotype == "Neurodivergent" & (mental_health != "None" |
                                       physical_chronic != "None" |
                                       disability_nos != "None")) |
    (mental_health != "None" & (physical_chronic != "None" |
                                disability_nos != "None")) |
    (physical_chronic != "None" & disability_nos != "None") ~ "NDD",
    # Default classification
    TRUE ~ "Neurotypical & non-disabled"
  )) %>%
  # Selecting and renaming columns for clarity
  select(ResponseId,
         "age" = Q5,
         "gender" = Q6,
         "mature" = Q7,
         "level_study" = Q8,
         "country" = Q9,
         "subject" = Q10,
         "english_first" = Q11,
         disability,
         "neurotype_open" = Q13, 
         "disability_open" = Q14,
         "why_open" = Q18,
         "how_open" = Q23,
         "advantages" = Q20,
         "disadvantages" = Q21,
         everything()) 

```

But worse, it's still changed the code (and hasn't flagged that it did this). A bit of digging with `all.equal()` and `count()` reveals that it has made changes to the disablity coding scheme. Not only was it not asked to change it, it was asked explicitly not to change the code, and it did it anyway.

```{r}
all.equal(dat, dat_copilot)
dat %>% count(disability)
dat_copilot %>% count(disability)
```

ChatGPT makes the same mistake in stating that incomplete responses are those with progress greater than 94. but generally it does a reasonably good job at editing the comments, but not going too far. Thankfully, `all.equal()` find that the object created by ChatGPT is identifical to the original, so it hasn't made any changes to the behaviour of the code.

```{r eval = FALSE}
dat_chat <- dat <- dat_raw %>%
  # Filter out incomplete responses with Progress greater than 94
  filter(Progress > 94, 
         # Exclude data from the "preview" distribution channel
         DistributionChannel != "preview") %>%
  # Select specific columns and rename them
  select(ResponseId, "duration" = 5, Q5:Q21) %>%
  # Replace missing values with "None" for disability information
  mutate(disability_nos = replace_na(disability_nos, "None"),
         physical_chronic = replace_na(physical_chronic, "None"),
         mental_health = replace_na(mental_health, "None")) %>%
  # Recode disability status based on various conditions
  mutate(disability = case_when(
                                  # Neurodivergent without other disabilities
                                  neurotype == "Neurodivergent" &
                                  physical_chronic == "None" &
                                  mental_health == "None" & 
                                  disability_nos == "None" ~
                                  "Neurodivergent",
                                 # Disabled based on specific conditions
                                  neurotype == "Neurotypical" &
                                  (physical_chronic == "Physical, mobility, or chronic health condition" |
                                  mental_health == "Mental health condition" |
                                  disability_nos == "Disability not otherwise specified") ~
                                  "Disabled",
                                 # Neurodevelopmental or multiple conditions
                                 (neurotype == "Neurodivergent" & (mental_health != "None" | physical_chronic != "None" | disability_nos != "None")) |
                                 (mental_health != "None" & (physical_chronic != "None" | disability_nos != "None")) |
                                 (physical_chronic != "None" & disability_nos != "None") ~ "NDD",
                                
                                TRUE ~ "Neurotypical & non-disabled")) %>%
  # Select necessary columns and tidy up the names
  select(ResponseId,
         "age" = Q5,
         "gender" = Q6,
         "mature" = Q7,
         "level_study" = Q8,
         "country" = Q9,
         "subject" = Q10,
         "english_first" = Q11,
         disability,
         "neurotype_open" = Q13, 
         "disability_open" = Q14,
         "why_open" = Q18,
         "how_open" = Q23,
         "advantages" = Q20,
         "disadvantages" = Q21,
         everything()) 


```

## Refactor code

To refactor code refers to the process of restructuring existing code without changing its intended behavior. The goal is to make the code more maintainable, readable, and efficient, while not altering the functionality or output.

* Improves Readability: Makes the code easier to understand for anyone who reads it in the future, which includes other developers or even the original author after some time has passed.
* Reduces Complexity: Simplifies complex code structures, breaking down large functions into smaller, more manageable ones.
* Enhances Maintainability: With cleaner code, it becomes easier to maintain and update the software over time.
* Facilitates Extensibility: Well-factored code can be extended with new features more easily.
* Improves Performance: In some cases, refactoring can optimize the performance of the software by removing redundancies and improving algorithms.
* Identifies Bugs: The process of refactoring can often reveal hidden bugs or issues in the code that can then be fixed.

With thanks to Copilot for writing the above.

## Activity 3: Refactor

I'll stick with the example of code from my publication because it's complicated enough that there are likely improvements or alternative solutions. Using the same code chunk as above, the prompt is:

> refactor this code and explain what you have changed and why. Where possible, use a tidyverse approach. 

* All three AIs struggled with this task. Their first attempts all gave me errors. In particular, it struggled with `everything()` in the call to `select()` at the end. This function is useful for when you want to select specific columns in a particular order and then you want everything else you haven't explicitly named in the original order. My hunch is that `everything()` might be a newer argument to `select()` and isn't in the training data so it doesn't know how to use it?

But mostly the issues stemmed from the amount of code I was giving it at once because it made it very, very difficult for me figure out where the issues were coming in and to verify whether it was fundamentally changing the behaviour of the code.

I then asked Copilot to split the code in each pipeline into a different object which it did:

> Split the code in each pipeline into a separate object

```{r}
# Step 1: Filter the data
dat_filtered <- dat_raw %>%
  filter(Progress > 94, DistributionChannel != "preview")

# Step 2: Select and rename columns
dat_selected <- dat_filtered %>%
  select(ResponseId, "duration" = 5, Q5:Q21)

# Step 3: Replace NAs with "None" for disability info
dat_na_replaced <- dat_selected %>%
  mutate(
    disability_nos = replace_na(disability_nos, "None"),
    physical_chronic = replace_na(physical_chronic, "None"),
    mental_health = replace_na(mental_health, "None")
  )

# Step 4: Recode disability data
dat_disability_recode <- dat_na_replaced %>%
  mutate(
    disability = case_when(
      neurotype == "Neurodivergent" & physical_chronic == "None" & mental_health == "None" & disability_nos == "None" ~ "Neurodivergent",
      neurotype == "Neurotypical" & (physical_chronic == "Physical, mobility, or chronic health condition" | mental_health == "Mental health condition" | disability_nos == "Disability not otherwise specified") ~ "Disabled",
      (neurotype == "Neurodivergent" & mental_health != "None") | (neurotype == "Neurodivergent" & physical_chronic != "None") | (neurotype == "Neurodivergent" & disability_nos != "None") | (mental_health != "None" & physical_chronic != "None") | (mental_health != "None" & disability_nos != "None") | (physical_chronic != "None" & disability_nos != "None") ~ "NDD",
      TRUE ~ "Neurotypical & non-disabled"
    )
  )

# Step 5: Recode gender data
dat_gender_recode <- dat_disability_recode %>%
  mutate(
    gender_cleaned = case_when(
      Q6 %in% c("Female", "female", "Woman", "woman", "Cisgender woman", "female (she/her)", "F", "f", "Womxn", "Woman (tranas)") ~ "Woman",
      Q6 %in% c("Man", "man", "M", "m", "Male (he/him)", "Male", "male", "Trans man.") ~ "Man",
      Q6 %in% c("Agender", "Genderfluid", "GNC", "NB", "non-binary", "Non-binary", "Non-Binary", "Non-binary femme", "non-binary male", "non binary", "Non binary", "Nonbinary", "Queer", "Transmasculine", "Non-binary") ~ "Non-binary",
      TRUE ~ "Not stated"
    )
  )

# Step 6: Select necessary columns and tidy up the names
dat_final <- dat_gender_recode %>%
  select(
    ResponseId,
    "age" = Q5,
    "gender" = Q6,
    gender_cleaned,
    "mature" = Q7,
    "level_study" = Q8,
    "country" = Q9,
    "subject" = Q10,
    "english_first" = Q11,
    disability,
    "neurotype_open" = Q13,
    "disability_open" = Q14,
    "why_open" = Q18,
    "how_open" = Q23,
    "advantages" = Q20,
    "disadvantages" = Q21,
    everything()
  )

```

Then, for each chunk, I asked it to refactor the code, where possible. I slightly amended the prompt to explicitly say that if the code was already efficient enough, not to change anything because some of the steps are quite simple.

> Refactor this code where necessary. Explain what you changed and why. Do not change anything if the code is already efficient. Use the tidyverse where possible.

* For step 3, Copilot and ChatGPT were both quite good at this and `identical()` returned `TRUE`.

```{r eval=FALSE}
# chatgpt and copilot solution
chat_dat_na_replaced <- dat_selected %>%
  mutate(
    across(c(disability_nos, physical_chronic, mental_health), ~replace_na(., "None"))
  )
# gemini solution - doesn't work, is a bit mad
dat_na_replaced <- dat_selected %>%
  mutate(
    disability_nos = replace_na(disability_nos, "None"),
    physical_chronic = replace_na(physical_chronic, "None"),
    mental_health = replace_na(mental_health, "None")
  ) %>%
  # Refactored using .after
  mutate(
    .after = {
      .x$disability_nos <- replace_na(.x$disability_nos, "None")
      .x$physical_chronic <- replace_na(.x$physical_chronic, "None")
      .x$mental_health <- replace_na(.x$mental_chronic, "None")
      .x
    }
  )

```

For step 4 it was a bit of a mess:

* The code Copilot gave me didn't work and the proposed solution to fix the initial error added on more code than I originally had.

```{r eval=FALSE}
# copilot
# doesn't run
copilot_dat_disability_recode <- dat_na_replaced %>%
  mutate(
    # Simplify the neurodivergent condition by checking for "None" in all related columns at once
    disability = case_when(
      neurotype == "Neurodivergent" & across(c(physical_chronic, mental_health, disability_nos), ~ .x == "None") ~ "Neurodivergent",
      
      # Combine the neurotypical conditions into one line for clarity
      neurotype == "Neurotypical" & (physical_chronic != "None" | mental_health != "None" | disability_nos != "None") ~ "Disabled",
      
      # Simplify the multiple conditions check by using any() to check if any of the conditions are met
      neurotype == "Neurodivergent" & any(c(mental_health, physical_chronic, disability_nos) != "None") ~ "NDD",
      
      # Default condition remains the same
      TRUE ~ "Neurotypical & non-disabled"
    )
  )

```

* Gemini's code worked but recoded the data incorrectly

```{r}
# gemini
gemini_dat_disability_recode <- dat_na_replaced %>%
  mutate(
    disability = case_when(
      neurotype == "Neurodivergent" & physical_chronic == "None" & mental_health == "None" & disability_nos == "None" ~ "Neurodivergent",
      neurotype == "Neurotypical" & (physical_chronic %in% c("Physical, mobility, or chronic health condition", "Mental health condition") | disability_nos == "Disability not otherwise specified") ~ "Disabled",
      # Breakdown of long condition
      (neurotype == "Neurodivergent" & !is.na(mental_health)) | (neurotype == "Neurodivergent" & !is.na(physical_chronic)) | (neurotype == "Neurodivergent" & disability_nos != "None") ~ "NDD",
      TRUE ~ "Neurotypical & non-disabled"
    )
  )

dat_disability_recode %>% 
  count(disability)

gemini_dat_disability_recode %>% 
  count(disability)
```

* ChatGPT's actually worked, returned an identical object, and made the code more efficient.

```{r}
# chatGPT
# Step 4: Recode disability data
chat_dat_disability_recode <- dat_na_replaced %>%
  mutate(
    disability = case_when(
      neurotype == "Neurodivergent" & physical_chronic == "None" & mental_health == "None" & disability_nos == "None" ~ "Neurodivergent",
      neurotype == "Neurotypical" & (physical_chronic != "None" | mental_health != "None" | disability_nos != "None") ~ "Disabled",
      neurotype == "Neurodivergent" | mental_health != "None" | physical_chronic != "None" | disability_nos != "None" ~ "NDD",
      TRUE ~ "Neurotypical & non-disabled"
    )
  )

dat_disability_recode %>% 
  count(disability)

chat_dat_disability_recode %>% 
  count(disability)
```


## Alternative approaches

In the PsyTeachR courses we strongly use the `tidyverse` approach but it's useful to be aware of other approaches, particularly Base R given that it doesn't require any package dependencies. 

You can simply amend the prompt to say use Base R as an alternative:

> when refactoring, use Base R instead of tidyverse 

* It's arguable whether it's that much more efficient but ChatGPT's output does indeed use Base R and did recode the variable correctly.

```{r}
# Step 4: Recode disability data
chat_dat_disability_recode <- transform(dat_na_replaced,
                                  disability = ifelse(neurotype == "Neurodivergent" & physical_chronic == "None" & mental_health == "None" & disability_nos == "None", "Neurodivergent",
                                                     ifelse(neurotype == "Neurotypical" & (physical_chronic != "None" | mental_health != "None" | disability_nos != "None"), "Disabled",
                                                            ifelse(neurotype == "Neurodivergent" | mental_health != "None" | physical_chronic != "None" | disability_nos != "None", "NDD",
                                                                   "Neurotypical & non-disabled"))))


dat_disability_recode %>% 
  count(disability)

chat_dat_disability_recode %>% 
  count(disability)
```

* Gemini's code did run but also managed to recode the variable from having four categories to two:

```{r}
gemini_dat_disability_recode <- dat_na_replaced %>%
  mutate(
    disability = ifelse(
      neurotype == "Neurodivergent" & all(c(physical_chronic, mental_health, disability_nos) == "None"),
      "Neurodivergent",
      ifelse(
        neurotype == "Neurotypical" & any(physical_chronic %in% c("Physical, mobility, or chronic health condition", "Mental health condition"), disability_nos == "Disability not otherwise specified"),
        "Disabled",
        ifelse(
          # Combined condition using logical OR ( | )
          (neurotype == "Neurodivergent" & !is.na(mental_health)) | (neurotype == "Neurodivergent" & !is.na(physical_chronic)) | (neurotype == "Neurodivergent" & disability_nos != "None") |
            (!is.na(mental_health) & !is.na(physical_chronic)) | (!is.na(mental_health) & disability_nos != "None") | (!is.na(physical_chronic) & disability_nos != "None"),
          "NDD",
          "Neurotypical & non-disabled"
        )
      )
    )
  )

dat_disability_recode %>% 
  count(disability)

gemini_dat_disability_recode %>% 
  count(disability)

```

* Copilot's ran and coded the data correctly although it definitely isn't more concise. Although it does use Base R.

```{r}
# Step 4: Recode disability data using base R
copilot_dat_disability_recode <- dat_na_replaced
copilot_dat_disability_recode$disability <- with(dat_na_replaced, ifelse(
  neurotype == "Neurodivergent" & physical_chronic == "None" & mental_health == "None" & disability_nos == "None", "Neurodivergent",
  ifelse(neurotype == "Neurotypical" & (physical_chronic == "Physical, mobility, or chronic health condition" | mental_health == "Mental health condition" | disability_nos == "Disability not otherwise specified"), "Disabled",
  ifelse((neurotype == "Neurodivergent" & mental_health != "None") | (neurotype == "Neurodivergent" & physical_chronic != "None") | (neurotype == "Neurodivergent" & disability_nos != "None") | (mental_health != "None" & physical_chronic != "None") | (mental_health != "None" & disability_nos != "None") | (physical_chronic != "None" & disability_nos != "None"), "NDD",
  "Neurotypical & non-disabled"
))))

dat_disability_recode %>% 
  count(disability)

copilot_dat_disability_recode %>% 
  count(disability)

```

## Conclusions

I hadn't actually used AI to perform these types of tasks before writing this book so here's my takeaways:

* CHECK EVERYTHING.
* If you give an AI code, you simply cannot trust that it won't change your code, even if that's not the task you ask it to do. If you use AI to add or review comments, you must check the output. Tools like `all.equal()` can help perform these checks.
* You also can't trust that the comments will be accurate. **Anything an AI writes must be checked before you use it. If you don't know if it's right, don't use it**.
* Because you have to check what it does so carefully, don't give it a big dump of code. Smaller chunks will end up taking less time.
* In some cases it was really useful and as someone who doesn't really use or know much Base R, I can see that this would be a great way to learn alternative approaches or to fill in comments.
* That said, the amount of checking it takes is substantial and so I'm not completely convinced that it would be any quicker than doing it yourself.
* They all struggled at different points although I think Of the three, Gemini was the clear loser of this chapter, which is a shame as I was starting to like it. 

::: {.callout-caution}
This book should be considered a **living document** and is likely to change over time. Given the brave new world in which we now live, all constructive feedback and suggestions are welcome! If you have any feedback or suggestions, please provide it [via Forms](https://forms.office.com/Pages/ResponsePage.aspx?id=KVxybjp2UE-B8i4lTwEzyKAHhjrab3lLkx60RR1iKjNUM0VCMUUxUUFLMTdNM0JTS09PSDg2SFQ3US4u).
:::
