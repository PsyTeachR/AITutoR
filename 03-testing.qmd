# Practice testing

In this chapter you'll learn how to use AI to test yourself. Practice testing, or [retrieval practice](https://www.learningscientists.org/blog/2016/6/23-1), is one of the most effective ways to consolidate your learning and there's several different ways you can do it.

## Activity 1: Set-up {#sec-setup-testing}

In your AI of choice, create a new chat and give it your set-up blurb that you created in Chapter @sec-setup.

It would be helpful to have a specific chapter of your course in mind to work with. For the PsyTeachR courses, we'll be using the Intended Learning Outcomes, functions used, and glossary to help instruct the AI. If you're not working through a course, or it's not a PsyTeachR course, it would be helpful to have a list of functions or skills that you want to test. As an example, we'll use [Chapter 3 of Applied Data Skills](https://psyteachr.github.io/ads-v3/03-viz.html).

## Activity 2: Question prompt

Then we need to give it instructions for how to create the questions. There are other question types you could ask it for but as a starter pack, this should be useful.

> I would like you to generate practice questions to help consolidate my learning based on the learning outcomes, functions, and glossary used in my course materials this week that I will provide to you. I will ask you for three different types of questions.

> First, multiple choice questions. Each question should have 4 response options and one correct answer. Ask them one at a time and explain the answer to me and why the other options are incorrect after I provide my answer.

> Second, coding problems. Give me short problems that I need to provide the answer to. These should be fully reproducible and use datasets built into R or the tidyverse.

> Third, error mode. Give me code that will result in an error and then ask me to figure out what the error is, and then fix it. Again, these should be fully reproducible and use datasets built into R or the tidyverse.

> Don't give me questions until I ask and give me only 1 question at a time

The final instruction is added because the AI will occasionally get ahead of itself and it's more useful to control the output.

## Built-in datasets

As an aside, built-in datasets in R are sample datasets that come pre-loaded with the R software installation. They provide a convenient way to practice data manipulation, analysis, and visualization techniques without needing to import external data files. These datasets cover various domains and can be helpful for learning and demonstrating R functionalities.

You can get a full list of all the built-in datasets available to you by running the command `data()` in the console. Base R comes with datasets built in but when you install extra packages they also sometimes have extra datasets, for example, the tidyverse has a lot of extra datasets. A package needs to be loaded for you to use any datasets from it, or for them to show up in the list when you run `data()`.

```{r eval = FALSE}
# see list of datasets
data()

# load tidyverse to get access to extra sets
library(tidyverse)

# load in dataset to environment so it can be used
data("starwars")
```

## Activity 3: Content prompt

Now give it the learning outcomes, list of functions, and glossary terms you want it to quiz you on. You don't need to worry about copying and pasting these over with nice formatting, just dump it all in. For example, for Applied Data Skills Chapter 3, this is what I provided:

> Intended Learning Outcomes Be able to identify categorical versus continuous data Be able to create plots in layers using ggplot Be able to choose appropriate plots for data 3.1 Functions used aes(), as.numeric(), c(), col_character(), col_datetime(), col_double(), col_factor(), col_integer(), cols(), coord_cartesian(), count(), element_blank(), facet_wrap(), factor(), geom_bar(), geom_boxplot(), geom_col(), geom_histogram(), geom_jitter(), geom_point(), geom_smooth(), ggplot(), ggtitle(), glimpse(), guides(), mean(), now(), plot_layout(), read_csv(), rgb(), scale_fill_manual(), scale_x_continuous(), scale_x_date(), scale_x_discrete(), scale_y_continuous(), seq(), spec(), stat_summary(), theme(), theme_bw(), theme_gdocs(), theme_set(), today()

> 3.7 Glossary termdefinitionargumentA variable that provides input to a function.categoricalData that can only take certain values, such as types of pet.categoricalData that can only take certain values, such as types of pet.characterA data type representing strings of text.chunkA section of code in an R Markdown filecontinuousData that can take on any values between other existing values.continuousData that can take on any values between other existing values.data-typeThe kind of data represented by an object.default-valueA value that a function uses for an argument if it is skipped.doubleA data type representing a real decimal numberfactorA data type where a specific set of values are stored with labels; An explanatory variable manipulated by the experimentergeomThe geometric style in which data are displayed, such as boxplot, density, or histogram.integerA data type representing whole numbers.knitTo create an HTML, PDF, or Word document from an R Markdown (Rmd) documentlikertA rating scale with a small number of discrete points in orderlogicalA data type representing TRUE or FALSE values.medianThe middle number in a distribution where half of the values are larger and half are smaller.nominalCategorical variables that don't have an inherent order, such as types of animal.numericA data type representing a real decimal number or integer.observationAll of the data about a single trial or question.ordinalDiscrete variables that have an inherent order, such as level of education or dislike/like.outlierA data point that is extremely distant from most of the other data pointsr-markdownThe R-specific version of markdown: a way to specify formatting, such as headers, paragraphs, lists, bolding, and links, as well as code blocks and inline code.stringA piece of text inside of quotes.tidy-dataA format for data that maps the meaning onto the structure.valueA single number or piece of data.variable(coding): A word that identifies and stores the value of some data for later use; (stats): An attribute or characteristic of an observation that you can measure, count, or describevectorA type of data structure that collects values with the same data type, like T/F values, numbers, or strings.

## Activity 4: Generating questions

You should now be able to ask it to generate questions for you by typing `mcq` or `coding problem`. A few other prompts to consider:

-   More like this
-   Give me a harder/easier question
-   Coding problem about `stat_summary()`

## Cautions and caveats

The questions it generates are generally helpful, but not always. Here's the issues I've come across whilst writing this book that I have not been able to prevent entirely by tweaking my prompts.

### Mulitple-choice questions

-   It's rare, particularly with beginner level coding, but sometimes it is just plain wrong.
-   It may ask you questions about functions you've haven't covered in the course.
-   It may give you a question where there are multiple correct answers without indicating this is the case, which can be confusing.
-   It may focus too much on certain topics of functions and you have to ask it to give you questions on a topic/function specifically.

### Coding problems

-   It suggests using a built-in dataset that doesn't exist. In this case, tell it that's the case and it will suggest a different dataset for the problem.
- The example it gives isn't fully reproducible so you have to write the code without being able to run it in R.

### Error mode

-   This is the category the AI struggled with the most, to the point where at the time of writing, I can't say that it's up to the task. I have a premium ChatGPT subscription and I also tried using GPT4.0 and it didn't help. I've decided to leave it in this book because it's a useful cautionary tale of the limits of AI.
-   From a learning and teaching perspective, it's a good example of why teaching might actually be a skill and my job might be safe after all. When we use Error Mode type questions in our courses, we design the errors so that they're common mistakes learners make at that point in their journey, they're mistakes that learners would plausibly make, and solving them will teach you something of use. Even when the AI managed to create an accurate error mode problem, it still wasn't helpful for learning.
-   Gemini did poorly at this. It gave me code that did not have errors, or it would tell me what the errors were, or it would give errors that were so obvious they wouldn't help you learn at all. For example:

![](include/images/03-testing/obvious.png)

-   ChatGPT fared slightly better although all of the problems were very basic and of the same type (creating a vector) until I asked it to give me me a specific problem (e.g., error mode for ggplot).
-   ChatGPT also suffered from the same problems as Gemini in that it would tell you what the error was or produce code that did not have any errors. I particularly enjoyed this response whereby it seemed to pretend that it was doing it on purpose as a teachable moment. I know I am anthropomorphising the AI here but I imagine any educator will feel a sense of kinship at trying to make your mistakes seem intentional.

![](include/images/03-testing/noerrors.png)

- I asked Copilot four times to try and produce code with an error in it and each time it gave me functioning code. So I gave up.

![](include/images/03-testing/stillnoerror.png)
