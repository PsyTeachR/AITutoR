{
  "hash": "92408d60dfc26f0a898da4244ce36f49",
  "result": {
    "engine": "knitr",
    "markdown": "\n# Code review\n\nIn this chapter you'll learn how to use AI to perform a code review and to add comments to your code. As you've already hopefully learned by working through this book, you have to be critical about anything the AI produces or suggests because it has no expert knowledge, but it can be a useful tool for checking and improving your code.\n\nDeBruine et al's [Code Check Guide](https://code-check-club.github.io/code-review-guide/) details what a comprehensive code check refers to:\n\n* Does it run? Can a researcher who uses that progamming language run it easily? Are any unusual or complex procedures explained?\n* Is it reproducible? Do you get the same outputs? Is it straightforward to check them?\n* Is it auditable/understandable? Even if you don’t have the expertise to assess the stats or data processing, is the code well-organised enough to figure out what is intended so mistakes could be detected? Are the outputs sufficiently detailed to allow interrogation?\n* Does it follow best practices? Is there too much repeated code that could benefit from modularisation? DRY (Don’t repeat yourself) and SPOT (Single Point of Truth)? Are the outputs of long processes saved and loaded from file? Do the variable names make sense? Do the results match what is shown in the output and there is no rounding up or down?\n* Is it correct and appropriate? Is the code actually doing what is intended? Is what is intended correct? Some logical problems can be caught without domain knowledge, such as intending to to filter out male subjects, but actually filtering them IN. Many other problems require domain and/or statistical knowledge, so may only be appropriate in some circumstances.\n\nHowever, some of these steps cannot (and should not) be performed by an AI. Unless you have specific ethical approval and have included this in your data management plan, you should **never** upload your research data to an AI tool. This means that assessing reproducibility is difficult. The AI also doesn't know what you *intended* to do, and why, and has no subject knowledge so it can't advise on anything theoretical without you giving it that information explicitly.\n\nTherefore, what we'll focus on in this chapter is two components of code review: **comments**  and **refactoring** your code.\n\n## Code comments\n\nCode comments are lines or sections of text added within the code itself that are ignored by the computer when the program runs. They're there for human readers, not machines. In R, you add comments to code by adding `#` to the start of the string:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# this is a comment\n\n# compute the mean of three numbers\nmean(c(1,2,3))\n```\n:::\n\n\nComments are useful for several reasons:\n\n* Clarification: They explain what certain parts of the code do, making it easier for others (and yourself) to understand the logic and flow of the code.\n* Documentation: They provide information on how the code works or why certain decisions were made, which is helpful for future reference.\n* Debugging: Temporarily commenting out parts of code can help isolate sections that may be causing errors, without deleting the code.\n* Collaboration: In team projects, comments can be used to communicate with other developers about the status or purpose of the code.\n\nOverall, comments are a crucial part of writing clean, maintainable, and collaborative code. They help make the code more accessible and understandable to anyone who might work on it in the future.\n\n## Adding comments with AI\n\nFirst we'll use use the `palmerpenguins` dataset again.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(palmerpenguins)\ndata(\"penguins\")\n```\n:::\n\n\nYou can use AI tools to help add comments to your code. Previous experience has taught us that we need to be a bit specific with what we want the AI to do so we'll give it a clear prompt. \n\n::: {.callout-caution}\n\n## Caution!!!\n\nFor this chapter, be very, very careful to ensure you are using GPT-5, not GPT-4. The performance of GPT-5 is significantly better and avoids introducing errors into your code.\n\n:::\n\n::: {.callout-note}\n\n## Activity 1\n\nIn Copilot, input the below code with the prompt:\n\n> Please add concise, helpful comments to this code. Explain what each main step does, not every line. If you are unsure about what a section of code is doing or why it exists, ask me a clarifying question. Do not change the code itself in any way.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins_clean <- penguins %>%\n  filter(complete.cases(.)) %>%\n  mutate(across(where(is.factor), as.character)) %>%\n  mutate(species_sex = interaction(species, sex, sep = \"_\"))\n```\n:::\n\n\n:::\n\nHere's its suggested comments:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Clean data, convert factors to character, and create a combined label\npenguins_clean <- penguins %>% # start from the penguins data\n  filter(complete.cases(.)) %>% # keep only rows with no missing values in any column\n  mutate(across(where(is.factor), as.character)) %>%# convert all factor columns to character\n  mutate(species_sex = interaction(species, sex, sep = \"_\"))  # new factor combining species and sex, e.g., \"Adelie_female\"\n```\n:::\n\n\nHowever, the AI can only tell you **what** the code is doing, it can't say **why** you chose to do that. The more complex your analysis, the more crucial it becomes to explain the rationale and so ensuring your prompt encourages the AI to ask for clarification is vital and in order to be able to answer these questions **you need to know your data and what you're trying to achieve**. \n\n\n::: {.cell}\n::: {.cell-output-display}\n![Adding comments](include/images/05-review/comment1.png){width=406}\n:::\n:::\n\n\n\n## Review existing comments\n\nIn addition to asking AI to comment your code, you can also ask it to review comments you've made yourself. To see how this works with a more complex example, and as an act of masochism, I gave the AI some code I wrote for a publication. The full paper [is here](https://link.springer.com/article/10.1007/s10734-024-01201-5) if you're interested - the quant analyses ended up being punted to the online appendix because of word count.\n\n::: {.callout-note}\n\n## Activity 2\n\nLoad in the dataset yourself with this code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# read in data but skip rows 2 and 3\ncol_names <- names(read_csv(\"https://osf.io/download/tf3xs/\", n_max = 0))\ndat_raw <- read_csv(\"https://osf.io/download/tf3xs/\", col_names = col_names, skip = 3) \n```\n:::\n\n\n:::\n\nThe first section of my code involves quite a complicated and long bit of wrangling, all done in a single pipeline. The purpose of the code is to clean up data collected on the survey platform Qualtrics and recode some of the demographic variables. This is actually a shortened version because the original hit the character limit for Copilot. I did put some effort into writing comments before publication but there are almost certainly improvements to be made. \n\n::: {.callout-note}\n\n## Activity 3\n\nProvide the code with the following prompt followed by the below code:\n\n> Please review the comments in my code and improve them where needed. Make comments clear, concise, and useful for someone reading the code for the first time. Keep the meaning of existing comments, but reword or simplify them for better readability. \n\n> Add comments only where they genuinely help understanding (e.g., explaining intent or logic, not obvious code). Do not change any of the code itself. After editing, explain your reasoning for each change — briefly describe why the original comment needed improvement (e.g., too long, unclear, redundant, missing context, etc.).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat <- dat_raw%>%\n  filter(Progress > 94, # remove incomplete responses\n         DistributionChannel != \"preview\") %>% # Remove Emily's preview data\n  select(ResponseId, \"duration\" = 5, Q5:Q21) %>%\n  # replace NAs with \"none\" for disability info\n  mutate(disability_nos = replace_na(disability_nos, \"None\"),\n         physical_chronic = replace_na(physical_chronic, \"None\"),\n         mental_health = replace_na(mental_health, \"None\"),\n) %>% # recode gender data\n  mutate(gender_cleaned = case_when(Q6 %in% c(\"Female\", \"female\", \"Woman\",\n                                              \"woman\", \n                                              \"Cisgender woman\",\n                                              \"female (she/her)\", \n                                              \"F\", \"f\", \"Womxn\", \n                                              \"Woman (tranas)\") ~ \"Woman\",\n                                    Q6 %in% c(\"Man\", \"man\", \"M\", \"m\", \n                                              \"Male (he/him)\", \"Male\",\n                                              \"male\", \"Trans man.\") ~\n                                      \"Man\",\n                                    Q6 %in% c(\"Agender\", \"Genderfluid\",\n                                    \"GNC\", \"NB\", \"non-binary\", \n                                    \"\tNon-binary\", \"Non-Binary\",\n                                    \"Non-binary femme\", \"non-binary male\",\n                                    \"non binary\", \"Non binary\",\n                                    \"Nonbinary\", \"Queer\", \"Transmasculine\",\n                                    \"Non-binary\") ~ \"Non-binary\",\n                            TRUE ~ \"Not stated\")) %>%\n  # select necessary columns and tidy up the names\n        select(ResponseId,\n             \"age\" = Q5,\n             \"gender\" = Q6,\n             \"mature\" = Q7,\n             \"level_study\" = Q8,\n             \"country\" = Q9,\n             \"subject\" = Q10,\n             \"english_first\" = Q11,\n             \"neurotype_open\" = Q13, \n             \"disability_open\" = Q14,\n             \"why_open\" = Q18,\n             \"how_open\" = Q23,\n             \"advantages\" = Q20,\n             \"disadvantages\" = Q21,\n             everything()) \n```\n:::\n\n\n\n:::\n\n::: {.callout-caution}\n\n## Have I mentioned you need to be careful?\n\n1. In an earlier version of this book, providing this prompt resulting in it changing the code without telling me so that not only did it not do what I intended, it also didn't work so you need to **be very, very careful**. \n\n2. Using GPT-4 for this task resulted in incorrect comments, which then affected subsequent reasoning and introduced errors into the code.\n\n**If you use AI without thinking and accidentally commit research fraud, don't blame me, I did try and warn you :)**\n\n:::\n\nTo check that it hasn't changed any code you can run `all.equal()` to compare two datasets. If it returns true, it means that the result of your initial code and the new code are identical. This is a really important check. \n\nHere's the code with the new comments:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# this is the code copied from Copilot with the edited comments\n\ndat_copilot <- dat_raw %>%\n  filter(Progress > 94, # keep responses with >94% progress\n         DistributionChannel != \"preview\") %>% # exclude preview/test responses\n  select(ResponseId, \"duration\" = 5, Q5:Q21) %>%  # select ID, rename column 5 as 'duration', keep Q5–Q21\n  # fill missing disability-related fields with \"None\"\n  mutate(disability_nos = replace_na(disability_nos, \"None\"),\n         physical_chronic = replace_na(physical_chronic, \"None\"),\n         mental_health = replace_na(mental_health, \"None\"),\n  ) %>%\n  # standardise gender responses into four categories\n  mutate(gender_cleaned = case_when(Q6 %in% c(\"Female\", \"female\", \"Woman\",\n                                              \"woman\", \n                                              \"Cisgender woman\",\n                                              \"female (she/her)\", \n                                              \"F\", \"f\", \"Womxn\", \n                                              \"Woman (tranas)\") ~ \"Woman\",\n                                    Q6 %in% c(\"Man\", \"man\", \"M\", \"m\", \n                                              \"Male (he/him)\", \"Male\",\n                                              \"male\", \"Trans man.\") ~\n                                      \"Man\",\n                                    Q6 %in% c(\"Agender\", \"Genderfluid\",\n                                    \"GNC\", \"NB\", \"non-binary\", \n                                    \"\tNon-binary\", \"Non-Binary\",\n                                    \"Non-binary femme\", \"non-binary male\",\n                                    \"non binary\", \"Non binary\",\n                                    \"Nonbinary\", \"Queer\", \"Transmasculine\",\n                                    \"Non-binary\") ~ \"Non-binary\",\n                            TRUE ~ \"Not stated\")) %>%\n  # rename key columns for clarity and keep all remaining variables\n  select(ResponseId,\n         \"age\" = Q5,\n         \"gender\" = Q6,\n         \"mature\" = Q7,\n         \"level_study\" = Q8,\n         \"country\" = Q9,\n         \"subject\" = Q10,\n         \"english_first\" = Q11,\n         \"neurotype_open\" = Q13, \n         \"disability_open\" = Q14,\n         \"why_open\" = Q18,\n         \"how_open\" = Q23,\n         \"advantages\" = Q20,\n         \"disadvantages\" = Q21,\n         everything())\n\n\n# then we can test if the two objects are identical to ensure it hasn't changed anything\n\nall.equal(dat, dat_copilot)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\n`all.equal()` returns true which means the two datasets are identical.\n\n\n## Refactoring code\n\nRefactoring means improving the structure of your code without changing what it does. You are not adding new features or fixing bugs, you are just making the code cleaner, easier to read, and easier to work with. Refactoring is like tidying your desk: everything still works the same, but it is more organised and makes future work easier. \n\nRefactoring:\n\n* Makes your code easier to read so that you (and others) can quickly understand what it does later on.\n* Simplifies your code by breaking big, messy pieces into smaller, easier-to-manage parts.\n* Keeps your code easy to update as clean, consistent code makes it easier to fix bugs or add new features later.\n* Helps you avoid and remove duplicated or unnecessary code.\n* Sometimes make it faster. Tidier code can help your program run more efficiently.\n* Can help spot hidden problems. While cleaning up, you might notice bugs or logic errors that you had missed before.\n\n::: {.callout-caution}\n\n## Caution!!!\n\nAre you using GPT-5 as instructed? The next section goes very badly if you aren't.\n\n:::\n\n::: {.callout-note}\n\n## Activity 4\n\nWe'll stick with the example of code from my publication because it's complicated enough that there are likely improvements or alternative solutions. Enter the following prompt followed by the code (use the original, not the Copilot commented version):\n\n> I would like you to refactor the following code. Keep the behaviour and output exactly the same, but make the code cleaner, easier to read, and more efficient. Please:\n\n> Add helpful comments where needed.\n> Use clear and consistent variable and function names.\n> Remove any unnecessary repetition.\n> Break long sections into smaller, logical parts if possible.\n> Follow good coding style for R and use a tidyverse approach where possible.\n> After refactoring, briefly explain what changes you made and why.\n\n:::\n\nHere's the refactored code it gave me:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Clean and prepare the survey data\ndat_copilot <- dat_raw %>%\n  # 1) Keep only near-complete, real responses\n  filter(\n    Progress > 94,                          # exclude incomplete responses\n    DistributionChannel != \"preview\"        # exclude preview entries\n  ) %>%\n  # 2) Retain core identifiers and items for analysis\n  #    Note: 'duration = 5' selects the 5th column by position and renames it to 'duration'\n  select(\n    ResponseId,\n    duration = 5,\n    Q5:Q21\n  ) %>%\n  # 3) Impute missing values for disability-related items with \"None\"\n  mutate(\n    across(\n      c(disability_nos, physical_chronic, mental_health),\n      ~ tidyr::replace_na(.x, \"None\")\n    )\n  ) %>%\n  # 4) Harmonise reported gender text into a clean categorical variable\n  mutate(\n    gender_cleaned = dplyr::case_when(\n      Q6 %in% c(\n        \"Female\", \"female\", \"Woman\", \"woman\", \"Cisgender woman\",\n        \"female (she/her)\", \"F\", \"f\", \"Womxn\", \"Woman (tranas)\"\n      ) ~ \"Woman\",\n      Q6 %in% c(\n        \"Man\", \"man\", \"M\", \"m\", \"Male (he/him)\", \"Male\",\n        \"male\", \"Trans man.\"\n      ) ~ \"Man\",\n      Q6 %in% c(\n        \"Agender\", \"Genderfluid\", \"GNC\", \"NB\", \"non-binary\",\n        \"    Non-binary\", \"Non-Binary\", \"Non-binary femme\",\n        \"non-binary male\", \"non binary\", \"Non binary\",\n        \"Nonbinary\", \"Queer\", \"Transmasculine\", \"Non-binary\"\n      ) ~ \"Non-binary\",\n      TRUE ~ \"Not stated\"\n    )\n  ) %>%\n  # 5) Final tidy selection and renaming for analytical clarity\n  select(\n    ResponseId,\n    age            = Q5,\n    gender         = Q6,\n    mature         = Q7,\n    level_study    = Q8,\n    country        = Q9,\n    subject        = Q10,\n    english_first  = Q11,\n    neurotype_open = Q13,\n    disability_open= Q14,\n    why_open       = Q18,\n    how_open       = Q23,\n    advantages     = Q20,\n    disadvantages  = Q21,\n    dplyr::everything()\n  )\n```\n:::\n\n\nAnd here's the explanation:\n\n**What changed and why**\n\n1. Structured the pipeline into five clearly labelled stages. Improves readability and helps future maintainers understand intent at a glance without scanning each line.\n2. Consistent tidyverse style and explicit namespaces where helpful. Retained %>%, used across() for grouped NA imputation, and added dplyr:: or tidyr:: qualifiers where ambiguity could arise in larger projects.\n3. Reduced repetition safely Replaced three separate mutate() calls for NA handling with a single mutate(across(...)), which is more concise and makes the imputation intent explicit while keeping the exact same behaviour.\n4. Clear, descriptive comments. Comments explain the purpose of each main step without annotating every line, matching your instruction and making the code easier to review.\n5. Preserved semantics of position-based selection for duration. Kept duration = 5 to ensure identical behaviour, as it renames the fifth column of the current data to duration.\n\nAgain, it's very important to check that this refactored code has the same result as the original. **There is no shortcut for knowing and checking your data**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall.equal(dat, dat_copilot)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\n\n## Be critical\n\nFrom both cognitive science and motivational psychology, writing your own comments and understanding your code before refactoring are key to developing genuine expertise and confidence. As we've mentioned several times already, research on [retrieval practice](https://www.learningscientists.org/blog/2016/6/23-1) shows that learning is stronger when you produce information yourself rather than copying or reading it. Writing your own code comments works like taking your own lecture notes: the act of explaining what your code does, in your own words, strengthens understanding and recall. Similarly, [elaboration](https://www.learningscientists.org/blog/2016/7/7-1) - adding meaning and connections - helps transform isolated code into a coherent mental model of whatever it is you're doing\n\nThese processes also feed into psychological needs identified in [self-determination theory](https://positivepsychology.com/self-determination-theory/): competence, autonomy, and relatedness. Each time you explain your code or verify that a refactor still works, you experience a small mastery moment, evidence that you can and do actually understand and control what you are doing. These mastery experiences are the foundation of [self-efficacy](https://www.simplypsychology.org/self-efficacy.html), the belief that you can succeed in similar tasks in the future. Over time, writing and refining your own comments builds both technical skill and the confidence to tackle new coding challenges independently.\n\nBy contrast, outsourcing explanations or edits to AI may help short-term efficiency but undermines these motivational and cognitive benefits. When an AI provides ready-made comments or “cleaner” code, it might fuel the [Dunning-Kruger effect](https://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect), the systematic tendancy of people with low ability to over-estimate their competence. This false fluency weakens both comprehension and autonomy: the more you depend on external solutions, the less opportunity you have to consolidate your own knowledge and sense of competence.\n\nIn practice: write your own comments first, then use AI to critique or refine them. When refactoring, ensure you can explain what each variable represents, why each step exists, and how the data should behave before you let AI suggest changes. Doing so keeps you in control, supports your autonomy as a learner, and transforms code review from a mechanical task into an act of understanding.\n\n\n::: {.callout-tip}\n## Key takeaways\n\nI hadn't used AI to perform these types of tasks before writing this book so here's my takeaways:\n\n* DID I MENTION? CHECK EVERYTHING.\n* If you give an AI code, you simply cannot trust that it won't change your code, even if that's not the task you ask it to do. If you use AI to add or review comments, you must check the output. Tools like `all.equal()` can help perform these checks.\n* You also can't trust that the comments will be accurate. **Anything an AI writes must be checked before you use it. If you don't know if it's right, don't use it**.\n* Because you have to check what it does so carefully, don't give it a big dump of code. Smaller chunks will end up taking less time.\n\n:::\n\n## Test yourself\n\n\n::: {.cell}\n\n:::\n\n\n1. Why can AI assist in code review but not replace a human reviewer?\n<select class='webex-select'><option value='blank'></option><option value=''>Because AI tools cannot access RStudio’s environment variables</option><option value=''>Because AI can only detect missing commas and syntax errors</option><option value='answer'>Because AI lacks domain knowledge and intent—it can describe what code does, but not whether it does the right thing</option><option value=''>Because AI cannot interpret comments embedded in R scripts</option></select>\n\n>\n\n2. Why should you never upload your research data to AI for code review? \n<div class='webex-radiogroup' id='radio_ZBXGCAFPNK'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_ZBXGCAFPNK\" value=\"\"></input> <span>To rewrite code so that it matches the reviewer’s preferred style</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_ZBXGCAFPNK\" value=\"answer\"></input> <span>To ensure that code runs correctly, is reproducible, auditable, and follows best practices without altering its intended behaviour</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_ZBXGCAFPNK\" value=\"\"></input> <span>To replace inefficient code with faster alternatives regardless of readability</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_ZBXGCAFPNK\" value=\"\"></input> <span>To simplify all code into a single consistent template across projects</span></label></div>\n\n\n>\n\n3. What is the purpose of adding comments to code?\n<div class='webex-radiogroup' id='radio_CVFUZHDVKE'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_CVFUZHDVKE\" value=\"\"></input> <span>To satisfy formal documentation requirements only</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_CVFUZHDVKE\" value=\"answer\"></input> <span>To clarify the logic and purpose of code for human readers without affecting execution</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_CVFUZHDVKE\" value=\"\"></input> <span>To improve runtime performance by reducing computation</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_CVFUZHDVKE\" value=\"\"></input> <span>To make AI-generated code easier to parse</span></label></div>\n\n\n>\n\n4. What is the main distinction between commenting and refactoring?\n<select class='webex-select'><option value='blank'></option><option value=''>Commenting explains existing code; refactoring changes the code structure without changing outputs</option><option value='answer'>Commenting explains what and why; refactoring improves organisation and efficiency while preserving behaviour</option><option value=''>Both are the same if code readability improves</option><option value=''>Refactoring focuses on aesthetics, while commenting affects execution</option></select>\n\n>\n\n5. How does writing your own code comments support learning and motivation?\n\n<div class='webex-radiogroup' id='radio_FRMZWNEGUH'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_FRMZWNEGUH\" value=\"\"></input> <span>It allows you to memorise function syntax without understanding logic</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_FRMZWNEGUH\" value=\"answer\"></input> <span>It promotes self-explanation, builds mastery experiences, and strengthens self-efficacy through active engagement</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_FRMZWNEGUH\" value=\"\"></input> <span>It reduces the need for metacognitive reflection and deliberate practice</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_FRMZWNEGUH\" value=\"\"></input> <span>It ensures that AI-generated comments remain concise and accurate</span></label></div>\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}