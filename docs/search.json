[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AI TutoR",
    "section": "",
    "text": "Overview\nThis book aims to teach students how to use AI to support their learning journey. The philosophy of this book is firmly rooted in the cognitive science of learning and as such, retrieval practice, distributed practice, and elaboration will all play a key role.\nIt is perhaps easier to start by explaining what this book is not:\n\nThis book is not a stand-alone resource. It is intended to be used alongside other course materials. To make the most out of this book, you will need things like Intended Learning Outcomes or key terms.\nThis book will not encourage learners to take short-cuts. That students should be able to understanding the principles of what they are learning and to critically evaluate writing on the topic, regardless of who or what wrote it, is non-negotiable.\nThis book is not an endorsement of AI nor is it uncritical of its impact, either on learning or the environment. It is written because we have thousands of student using AI in a way that damages their learning and I do not believe that preaching abstinence is an effective solution.\nFor the coding aspects of this book, we will not not teach you how to use platforms like Github Copilot and it is not aimed at proficient or advanced programmers.\n\nInstead, this book will aim to help learners use AI platforms critically. By the end of this book, learners should be able to:\n\nUse AI to explain concepts and functions in a level of detail and technicality appropriate to the knowledge and skill of the learner\nUse AI to generate practice questions to test understanding\nUse AI to debug errors in code\nUse AI to review, comments, and refactor code\nUse AI to responsibly assist with writing code\nCritically evaluate and appraise the output of AI\n\n\n\n\n\n\n\nCaution\n\n\n\nThis book was written in Spring 2024 (and is currently being updated in September 2025) and should be considered a living document. The functionality and capability of AI is changing rapidly and the most recent advances may not reflect what is described in this book.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "01-intro.html",
    "href": "01-intro.html",
    "title": "\n1  Intro to using AI\n",
    "section": "",
    "text": "1.1 A brief introduction\nThere are a range of AIs and an even larger number of niche apps and platforms but we’re going to focus on Microsoft’s Copilot signed in via your UofG account. The reason we’ve chosen Copilot is that all University of Glasgow students have access to the same plan and functionality and the UofG Copilot has enhanced security, which is particularly important when you’re considering using AI to help with data analysis.\nSince 2024, generative AI tools have become embedded in most productivity software (Word, Excel, PowerPoint, Teams, Google Workspace, Adobe Creative Suite). Whilst this book uses Copilot, you should expect to see AI features in many of the tools you already use.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "01-intro.html#a-brief-introduction",
    "href": "01-intro.html#a-brief-introduction",
    "title": "\n1  Intro to using AI\n",
    "section": "",
    "text": "1.1.1 AI model vs AI platforms\nThere are more qualified people who can explain AI better than I, but a brief but important distinction is between the AI model and the AI platform. The underlying AI model is a Large Language Model (LLM) that essentially does extremely sophisticated predictive text - it’s not thinking, it’s not conscious, it just is very good at deciding what word is likely to come after another word in a way that is human-like.\nDifferent software companies have created different AI models. OpenAI has a series of models it refers to as Generative Pre-trained Transformers (GPTs). The explosion in AI in terms of public awareness came about when OpenAI released GPT version 3 and the most recent version is 5. The capability of each successive AI is claimed to increase significantly, both in terms of its ability (e.g., to pass standardised tests) and in the human-ness of its responses. In addition to GPT-5, other widely used models include Claude 3.5 (Anthropic), Gemini 1.5 (Google/DeepMind), and LLaMA 3 (Meta). Different platforms may give slightly different results because they are tuned differently.\nUnlike earlier versions, most current models are multimodal by default: they can process text, images, and in some cases audio and video. Copilot inherits some of this, for example analysing images or diagrams when pasted in.\nIn some cases, the name of the model and the name of the platform you use are the same. ChatGPT is the name of the platform, but the underlying model it uses is GPT5. Additionally, other companies and apps can licence use of the models so Microsoft’s Copilot also uses GPT5.\nIt isn’t necessary that you understand all of this in detail. The key thing is that the underlying model is the same for some platforms (so you should expect similar capabilities) and that this model can and will update.\n\n1.1.2 Ethics and AI\nIt’s beyond the scope of this book (and my expertise) to go into much detail about the ethics of AI but I want to acknowledge that in several ways, they’re hugely problematic.\nFirst, and most importantly, AIs are trained on huge corpora of human language. Humans are full of bias and prejudice and consequently, so are our offspring AIs who have been repeatedly found to encode sexist, racist, and abelist views in their outputs.\n\nTeaching AI Ethics: Bias and Discrimination\n\nSecond, many of the developers that have produced AI models have done so behind closed doors and are very secretive about exactly what data the models have been trained on. One of the reasons for this is because it is very clearly apparent that many AI models have been given access to copyrighted sources (e.g., books and film scripts) and there are an increasing number of lawsuits being filed although it remains unclear what the future holds given how far and how fast the horse has already bolted.\n\nAI Infringement Case Updates\n\nThird, whilst the use of AI has been touted as a solution to help us manage climate change, it’s also a direct contributor to the problem because of the energy demands.\n\nExplained: Generative AI’s environmental impact\n\nFourth, training and moderation often rely on hidden human labour. Low-paid workers, often in the Global South, are employed to filter harmful content or annotate data. This raises ethical questions about labour exploitation.\n\nHow We Investigated the Human Labor Behind AI\n\nRegulation is catching up: the EU AI Act will begin to take effect in 2025, and the UK is consulting on its own frameworks. This means that how we are expected to use AI responsibly may change rapidly. AI Now 2025 Report provides an annual overview of social, ethical, and political issues in AI.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "01-intro.html#ai-platforms",
    "href": "01-intro.html#ai-platforms",
    "title": "\n1  Intro to using AI\n",
    "section": "\n1.2 AI platforms",
    "text": "1.2 AI platforms\n\n1.2.1 ChatGPT\nYou can sign-up for ChatGPT at https://chat.openai.com/. The free version uses 4o although there are limits on how many messagfes you can send in a certain time period and it is sometimes unavailable. When this happens, it will revert to 3.5. The free version is very fast and for beginner level courses does perform quite well. I’ve also found that ChatGPT is good at understanding the intent of what I want. ChatGPT also makes it easy to save your chat history so that you can continue working in previous chats at a later date. A useful feature is the “regenerate” function whereby if you’re not completely happy with the response, you can quickly ask it to generate another attempt and compare them. ChatGPT has a mobile app and allows you to share links to saved chats.\nThe disadvantages of ChatGPT are that it has limited internet connectivity and the information in its database will be restricted. At the time of writing this book, ChatGPT’s training data extends until January 2022, so it can’t tell you about anything that happened after that point (regardless of whether that’s world event or a new R function). Whilst it does depend on which version you’re using, it rarely gives you links to sources for where it has found the information.\n\n\n\n\nusing ChatGPT\n\n\n\n\n1.2.2 Copilot\nMicrosoft Copilot can be accessed at https://copilot.microsoft.com/ and you can sign-in with your Microsoft Account. If you are a University of Glasgow student (and also at many other universities), you can access Copilot through your university account and your Office365 subscription. If you do so, you’ll be able to access the Enterprise version of Copilot. The advantage of using your Enterprise account is that the data is processed more securely and what you input won’t be used to train the model. The price you pay for this security - and it’s such a big price that I don’t use it much for this reason - is that it doesn’t save your chat history so you start each time afresh. If you use a personal account, it will save your chat history, but also use your data to train the model.\nHowever, where Copilot shines is that it has access to the internet and will give you links to where it got its information so it’s easier to verify the output than ChatGPT. Additionally, they don’t make this clear but if you select the conversation style to be “Creative”, it will use GPT4.0.\nI have found that Copilot more frequently doesn’t understand the intent of what I am asking and with the same prompt as ChatGPT will give me a useless answer, but let’s see how I feel about that by the end of writing this book.\nMy general approach is that if I want to be able to return to my conversation, I use ChatGPT and if I want links to sources, I use Copilot.\n\n\n\n\nusing ChatGPT",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "01-intro.html#activity-1",
    "href": "01-intro.html#activity-1",
    "title": "\n1  Intro to using AI\n",
    "section": "\n1.3 Activity 1",
    "text": "1.3 Activity 1\n\nChoose one of the AIs and create an account/login. You can also do this activity with both AIs to see the difference in output if you’re interested.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "01-intro.html#activity-2",
    "href": "01-intro.html#activity-2",
    "title": "\n1  Intro to using AI\n",
    "section": "\n1.4 Activity 2",
    "text": "1.4 Activity 2\nThe key difference between using an AI and a regular search engine is that you can shape the output of the AI by “prompt engineering”, which is the phrase used to describe the art of asking the question in a way that gives you the answer you want. It’s easier to show than tell.\nThink of a book, TV show, film, or video game that you know really well. I chose Final Fantasy VII (the original PlayStation version). Ask the AI to give you three different summaries and try out the functionality of each platform. For example, for ChatGPT ask it to regenerate the response, for Copilot, click on any links it provides.\n\nFirst, ask it for a summary without any additional context e.g., “Give me a summary of Final Fantasy VII (original playstation version)”\nThen, ask it for a summary but give it a steer on the intended audience, e.g., “Give me a summary of Final Fantasy VII (original playstation version) for someone who knows nothing about videogames” or “Give me a summary of Final Fantasy VII (original playstation version) for an expert gamer who has played it many times”\nFinally, ask it for a summary, but give it a steer on how it should act, e.g., “Act as an expert videogame reviewer for the Guardian. Give me a summary of Final Fantasy VII (original playstation version) for an expert gamer who has played it many times” or “Act as someone who spends too much time on Reddit and thinks they know everything. Give me a summary of Final Fantasy VII (original playstation version) for an expert gamer who has played it many times”.\n\nThe key takeaways to remember for your learning journey are:\n\nTell it how to act\nTell it who you are\n\nReflect on the differences between the summaries - the technicality of the language, the accuracy and nuance of the information, what it chose to focus on, and what it chose to omit. The reason I asked you to create a summary of something you already know well is that you’re aware of where the gaps are. Remember this when you’re asking an AI something you don’t know as well. Just because you can’t see the gaps, inaccuracies, and biases, doesn’t mean they’re not there.\n\n\n\n\n\n\nCaution\n\n\n\nThis book was written in Spring 2024 and should be considered a living document. The functionality and capability of AI is changing rapidly and the most recent advances may not reflect what is described in this book. Given the brave new world in which we now live, all constructive feedback and suggestions are welcome! If you have any feedback or suggestions, please provide it via Forms.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "01-intro.html#footnotes",
    "href": "01-intro.html#footnotes",
    "title": "\n1  Intro to using AI\n",
    "section": "",
    "text": "I ran this explanation through an AI and it was not happy with me and wants you to know that it can also perform tasks like translation, question answering, and even generate creative text formats like poems or code. Calm down Felicia.↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "02-personalise.html",
    "href": "02-personalise.html",
    "title": "2  Personalised tutor",
    "section": "",
    "text": "2.1 Custom instructions\nThis chapter will teach you how to use AI as a personalised tutor to explain concepts and functions you’re struggling to understand, or would like more information on. AI can act as a study partner to explain concepts in multiple ways, but it is not a replacement for your own practice or your lecturer’s guidance. Think of it as a supplement, not a substitute.\nIt will be helpful to work through these activities with a specific week/chapter/lecture of your course in mind.\nThe key to maximising usefulness is to set up custom instructions (sometimes called “system prompts”). These apply across all chats so the AI remembers who you are and how you like answers to be framed.\nHere’s some examples:\nThis is mine. It doesn’t always follow the instructions but it’s much better than without it.\nTo add your custom instructions in Copilot, click the three dots in the top right corner, then click settings, then Custom Instructions.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#set-up",
    "href": "02-personalise.html#set-up",
    "title": "2  Personalised tutor",
    "section": "",
    "text": "Act as an expert tutor for the programming language R. I am a learner on an Upskilling course “Applied Data Skills” and I am learning R for the first time. I work in the NHS in Health Informatics. I have never learned a programming language before. I have used Excel and SPSS. I have reasonably good general computer literacy. I will ask you questions about concepts and functions I do not understand based on my course materials. Always give me concrete examples when you provide an answer. Tailor your responses to my level of expertise. I am using R and RStudio on a Mac and the course will strongly use the tidyverse.\n\n\nAct as an expert tutor for the programming language R. I am a first year psychology student at the University of Glasgow and I am learning R for the first time. I have never learned a programming language before and I am not very confident with computers and I am anxious about learning programming. I have a Windows laptop. I will ask you questions about concepts and functions I do not understand based on my course materials. Always give me concrete examples when you provide an answer. Tailor your responses to my level of expertise. I am using R and RStudio and the course will strongly use the tidyverse.\n\n\nAct as an expert psychology tutor for university level study. I am a second year psychology student at the University of Glasgow. I will ask you questions about concepts and theories based on my course materials. Always give me concrete examples when you provide an answer. Tailor your responses to my level of expertise.\n\n\nAct as an expert careers advisor. I am about to graduate with a psychology degree and I would like help applying for jobs. Your responses should be relevant to working in the UK with a BPS accredited degree. Any writing you produce should be of an appropriate formality and tone.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#sec-setup",
    "href": "02-personalise.html#sec-setup",
    "title": "2  Personalised tutor",
    "section": "2.2 Activity 1: Write your set-up",
    "text": "2.2 Activity 1: Write your set-up\n\nWrite and save your set-up. It’s worth spending some time to get this right, you’re going to use it a lot.\n\nExactly what information you provide is up to you but make sure that you explain your level of knowledge, skill, confidence and previous experience. By specifying what your field is (psychology, NHS etc.) it can then give you examples related to these fields which will make it easier for you to understand and connect your new knowledge to existing knowledge. Finally, if you’re using it for coding, you also want to give it some technical information about the software you’re using (e.g., R and RStudio) and your operating system (Windows).",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#activity-2-instruct-the-ai",
    "href": "02-personalise.html#activity-2-instruct-the-ai",
    "title": "2  Personalised tutor",
    "section": "2.3 Activity 2: Instruct the AI",
    "text": "2.3 Activity 2: Instruct the AI\n\nEnter your set-up into a new chat on your AI of choice. If you’re using an AI that saves your chats, you could also rename the chat to “Personal Tutor” or “Week 1 Tutor” or anything else that make sense to you.\n\nDepending on what information you give it, it may give you e.g., some intro to R tips and information which may be more or less useful, so if it’s confusing, just ignore it until you’ve given it more specific prompts.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#example-questions",
    "href": "02-personalise.html#example-questions",
    "title": "2  Personalised tutor",
    "section": "2.2 Example questions",
    "text": "2.2 Example questions\nNow that you’ve got your tutor set up, you can ask it questions. Here’s some examples:\n\nWhy do I have to learn to code?\nWhat is the difference between short-term memory and working memory?\nGive me examples of between-subject designs\nWhat is the difference between a function and an argument?\nRewrite this explanation in 100 words or less.\nExplain what each part of this code is doing: ggplot(survey_data, aes(x = wait_time, y = call_time)) +  geom_point()\nGive me examples of when I would use different joins in R\n\n\n\n\n\n\n\nNoteActivity 3\n\n\n\n\nAsk the AI three questions based on your course materials for this week. If the output doesn’t seem at the right level for you, consider editing your custom instructions and re-running the questions to see how the output changes.\nTry asking for two versions of the same answer (e.g., one simple, one more technical) and compare how the content changes.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#activity-3-questions",
    "href": "02-personalise.html#activity-3-questions",
    "title": "2  Personalised tutor",
    "section": "2.5 Activity 3: Questions",
    "text": "2.5 Activity 3: Questions\n\nAsk the AI three questions based on your course materials. If the output doesn’t seem at the right level for you, consider editing your initial set-up prompt and re-running the questions to see how the output changes.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#conversation",
    "href": "02-personalise.html#conversation",
    "title": "2  Personalised tutor",
    "section": "2.3 Conversation",
    "text": "2.3 Conversation\nAnother big difference between AI and a regular search engine is that you can have a conversation with it and follow-up on your original question. Some examples:\n\nCan you explain it again but compare coding in R to doing the same task in Excel?\nExpand on your explanation of geom_point()\nGive me another example of code that uses this approach\nExplain it again but in more technical / simpler terms\nAsk me a question to test if I understand this correctly (we’re going to go into practice testing a lot more in the next chapter)\nIn your answer you said “In this example, c() is a function that combines values into a vector”, what is a vector?",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#activity-4-follow-up",
    "href": "02-personalise.html#activity-4-follow-up",
    "title": "2  Personalised tutor",
    "section": "2.7 Activity 4: Follow-up",
    "text": "2.7 Activity 4: Follow-up\n\nAsk a follow-up question to each of your original questions. Additionally, try out the features of each AI. For ChatGPT, use regenerate response. For Copilot, click on the suggested follow-up questions or any links it provides.\n\n\n\n\n\n\n\nCaution\n\n\n\nThis book was written in Spring 2024 and should be considered a living document. The functionality and capability of AI is changing rapidly and the most recent advances may not reflect what is described in this book. Given the brave new world in which we now live, all constructive feedback and suggestions are welcome! If you have any feedback or suggestions, please provide it via Forms.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "03-testing.html",
    "href": "03-testing.html",
    "title": "\n3  Practice testing\n",
    "section": "",
    "text": "3.1 Question types\nIn this chapter you’ll learn how to use AI to test yourself. Practice testing, or retrieval practice, is one of the most effective ways to consolidate learning, and it can be applied in several formats. This chapter was written with a data skills course in mind but it applies to any type of course.\nYou should have a specific week/chapter/lecture of your course to work with. For PsyTeachR courses like Applied Data Skills, we’ll be using the Intended Learning Outcomes, functions used, and glossary to help instruct the AI. If you’re not working through a course, or it’s not a PsyTeachR course, it would be helpful to have a list of functions, concepts, or skills that you want to test.\nIt’s very important that you use Copilot through your UofG account so that the course content you share is not used to train the model. You should also ensure that you have the consent of your lecturer to do this (if you’re enrolled on Applied Data Skills, you have our consent to upload any course material to Copilot, but not to platforms like ChatGPT).\nThe first thing we’re going to do is set-up several different prompts to create different types of practice questions. Which of these you end up using will depend on what you’re trying to study. Different question formats test different aspects of your knowledge. Here’s what each type is for and what the AI will produce when you ask for it.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#sec-setup-testing",
    "href": "03-testing.html#sec-setup-testing",
    "title": "\n3  Practice testing\n",
    "section": "",
    "text": "In your AI of choice, create a new chat and give it your set-up blurb that you created in Chapter ?sec-setup.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#activity-2-question-prompt",
    "href": "03-testing.html#activity-2-question-prompt",
    "title": "\n3  Practice testing\n",
    "section": "\n3.2 Activity 2: Question prompt",
    "text": "3.2 Activity 2: Question prompt\nAfter you have given it your set-up prompt, you can give it instructions for how to create each type of question.\n\n3.2.1 Multiple choice questions\nFirst, prompt the AI with guidance for how to write effective MCQs. This ensures that the questions it produces have a better chance of being well-formed:\n\nRead and summarise the guidance on this page, paying particular attention to the construction of the stem and the response options https://cft.vanderbilt.edu/guides-sub-pages/writing-good-multiple-choice-test-questions/\n\nFollow this up with:\n\nNow, read and summarise the guidance on this page on the different types of MCQs: https://www.utm.utoronto.ca/rgasc/media/2097/download?inline\n\nThen give the AI context about the type of questions you need. Include the level of the learner and any other information. You may want to edit this depending on your question set-up and rules:\n\nI would like you to write multiple choice questions that are appropriate for students in their first year of an undergraduate psychology degree.\n\n\n\nAll questions should follow the guidance above on best practices for MCQs\nAll questions should have four responses and one correct answer. Each response option should be on a separate line.\nAll questions should align with the intended learning outcomes\nAll questions should be challenging in difficulty.\n\n\n\n\nI will upload the learning outcomes and content for the class I want you to test me on. Give me questions one at a time. Ask me for the correct answer and then give me an explanation for each option. Do not give any suggestions as to what the right answer is, for suggested follow up responses in Copilot only give the option “skip question\n\n\n\n3.2.2 True-or-false (TOF)\n\nI would like you to write TRUE or FALSE questions (TOF) that are appropriate for students in their first year of an undergraduate psychology degree. Provide a statement and then ask me to determine whether the statement is true or false. All questions should be challenging in difficulty.\n\n\nI will upload the learning outcomes and content for the class I want you to test me on. Give me questions one at a time. Ask me for the correct answer and then give me an explanation.\n\n\n3.2.3 Short-answer-questions\n\nI would like you to write short answer questions (SAQ) that are appropriate for students in their first year of an undergraduate psychology degree. Each question should ask about one specific concept, theory, or term, and I should be able to answer it in 100 words or fewer. All questions should be challenging in difficulty.\n\n\nI will upload the learning outcomes and content for the class I want you to test me on. Give me questions one at a time. Ask me for the correct answer and then give me an explanation.\n\n\n3.2.4 Fill-in-the-blanks (coding)\n\nI would like you to write fill-in-the-blank questions (FITB) that are appropriate for students in their first year of an undergraduate psychology degree. Provide a line of R code that has one or more missing arguments or functions and ask me to complete the code. All questions should be challenging in difficulty.\n\n\nI will upload the learning outcomes and content for the class I want you to test me on. Give me questions one at a time. Ask me for the correct answer and then give me an explanation.\n\n\n3.2.5 Fill-in-the-blanks (theory)\n\nI would like you to write fill-in-the-blank questions (FITB) that are appropriate for students in their first year of an undergraduate psychology degree. Provide a statement that has one or more missing words and ask me to fill in the blanks. All questions should be challenging in difficulty.\n\n\nI will upload the learning outcomes and content for the class I want you to test me on. Give me questions one at a time. Ask me for the correct answer and then give me an explanation.\n\n\n3.2.6 Coding problems\n\nI would like you to write coding problems (CP) that are appropriate for students in their first year of an undergraduate psychology degree learning R. Give me short problems that I need to provide the answer to. These should be fully reproducible and use datasets built into R or the tidyverse. I will upload the learning outcomes and functions you should test me on. Where necessary, give me the code to load any packages or datasets that I will need. All questions should be challenging in difficulty.\n\n\nGive me questions one at a time. Ask me for the correct answer and then give me an explanation.\n\n\n3.2.7 Error mode\n\nI would like you to write error mode problems (EM) that are appropriate for students in their first year of an undergraduate psychology degree learning R.Give me code that will result in an error. Explain what the code is intended to do and then ask me to figure out what the error is, and then fix it. The errors should be plausible errors that a beginner would be likely to make but do not tell me what the error is. The errors should be fully reproducible and use datasets built into R or the tidyverse so that I can run the code and fix them in R. All questions should be challenging in difficulty.\n\n\nI will upload the learning outcomes and functions you should test me on. Where necessary, give me the code to load any packages or datasets that I will need. Give me questions one at a time. Ask me for the correct answer and then give me an explanation.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#built-in-datasets",
    "href": "03-testing.html#built-in-datasets",
    "title": "\n3  Practice testing\n",
    "section": "\n3.3 Built-in datasets",
    "text": "3.3 Built-in datasets\nIf you’re using AI to help with coding, built-in datasets in R are sample datasets that come pre-loaded with the R software installation. They provide a convenient way to practice data manipulation, analysis, and visualization techniques without needing to import external data files. These datasets cover various domains and can be helpful for learning and demonstrating R functionalities.\nYou can get a full list of all the built-in datasets available to you by running the command data() in the console. Base R comes with datasets built in but when you install extra packages they also sometimes have extra datasets, for example, the tidyverse has a lot of extra datasets. A package needs to be loaded for you to use any datasets from it, or for them to show up in the list when you run data().\n\n# see list of datasets\ndata()\n\n# load tidyverse to get access to extra sets\nlibrary(tidyverse)\n\n# load in dataset to environment so it can be used\ndata(\"starwars\")",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#activity-3-content-prompt",
    "href": "03-testing.html#activity-3-content-prompt",
    "title": "\n3  Practice testing\n",
    "section": "\n3.4 Activity 3: Content prompt",
    "text": "3.4 Activity 3: Content prompt\nNow give it the learning outcomes, list of functions, and glossary terms you want it to quiz you on. You don’t need to worry about copying and pasting these over with nice formatting, just dump it all in. For example, for Applied Data Skills Chapter 3, this is what I provided:\n\nIntended Learning Outcomes Be able to identify categorical versus continuous data Be able to create plots in layers using ggplot Be able to choose appropriate plots for data 3.1 Functions used aes(), as.numeric(), c(), col_character(), col_datetime(), col_double(), col_factor(), col_integer(), cols(), coord_cartesian(), count(), element_blank(), facet_wrap(), factor(), geom_bar(), geom_boxplot(), geom_col(), geom_histogram(), geom_jitter(), geom_point(), geom_smooth(), ggplot(), ggtitle(), glimpse(), guides(), mean(), now(), plot_layout(), read_csv(), rgb(), scale_fill_manual(), scale_x_continuous(), scale_x_date(), scale_x_discrete(), scale_y_continuous(), seq(), spec(), stat_summary(), theme(), theme_bw(), theme_gdocs(), theme_set(), today()\n\n\n3.7 Glossary termdefinitionargumentA variable that provides input to a function.categoricalData that can only take certain values, such as types of pet.categoricalData that can only take certain values, such as types of pet.characterA data type representing strings of text.chunkA section of code in an R Markdown filecontinuousData that can take on any values between other existing values.continuousData that can take on any values between other existing values.data-typeThe kind of data represented by an object.default-valueA value that a function uses for an argument if it is skipped.doubleA data type representing a real decimal numberfactorA data type where a specific set of values are stored with labels; An explanatory variable manipulated by the experimentergeomThe geometric style in which data are displayed, such as boxplot, density, or histogram.integerA data type representing whole numbers.knitTo create an HTML, PDF, or Word document from an R Markdown (Rmd) documentlikertA rating scale with a small number of discrete points in orderlogicalA data type representing TRUE or FALSE values.medianThe middle number in a distribution where half of the values are larger and half are smaller.nominalCategorical variables that don’t have an inherent order, such as types of animal.numericA data type representing a real decimal number or integer.observationAll of the data about a single trial or question.ordinalDiscrete variables that have an inherent order, such as level of education or dislike/like.outlierA data point that is extremely distant from most of the other data pointsr-markdownThe R-specific version of markdown: a way to specify formatting, such as headers, paragraphs, lists, bolding, and links, as well as code blocks and inline code.stringA piece of text inside of quotes.tidy-dataA format for data that maps the meaning onto the structure.valueA single number or piece of data.variable(coding): A word that identifies and stores the value of some data for later use; (stats): An attribute or characteristic of an observation that you can measure, count, or describevectorA type of data structure that collects values with the same data type, like T/F values, numbers, or strings.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#activity-4-generating-questions",
    "href": "03-testing.html#activity-4-generating-questions",
    "title": "\n3  Practice testing\n",
    "section": "\n3.5 Activity 4: Generating questions",
    "text": "3.5 Activity 4: Generating questions\nYou should now be able to ask it to generate questions for you by typing mcq or coding problem. A few other prompts to consider:\n\nMore like this\nGive me a harder/easier question\nCoding problem about stat_summary()",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#cautions-and-caveats",
    "href": "03-testing.html#cautions-and-caveats",
    "title": "\n3  Practice testing\n",
    "section": "\n3.6 Cautions and caveats",
    "text": "3.6 Cautions and caveats\nThe questions it generates are generally helpful, but not always. Here’s the issues we’ve come across whilst writing this book that we have not been able to prevent entirely by tweaking the prompts.\n\n3.6.1 Mulitple-choice / TOF / SAQ questions\n\nSometimes it is just plain wrong. The answer here should be C. If you tell it that it is wrong, it can correct itself (but also if you tell it that it is wrong even when it is right, it sometimes accepts that it is wrong). Bear this in mind if you ever use it to produce anything that AI does not have any knowledge, it’s just a very sophisticated parrot.\nIt may ask you questions about functions or concepts you’ve haven’t covered in the course.\nIt may give you a question where there are multiple correct answers without indicating this is the case, which can be confusing.\nIt may focus too much on certain topics of functions and you have to ask it to give you questions on a topic/function specifically.\n\n3.6.2 Coding problems\n\nIt suggests using a built-in dataset that doesn’t exist. In this case, tell it that’s the case and it will suggest a different dataset for the problem.\nThe example it gives isn’t fully reproducible so you have to write the code without being able to run it in R. For example, it assumes you have a dataset with columns named “number” and “price”, but loads no such dataset, so you can’t actually try out the code. It’s still possible to write the code, but without being able to run it, much more difficult, particularly as a beginner.\n\n3.6.3 Error mode\n\nThis is the category the AI struggled with the most, to the point where at the time of writing, we can’t say that it’s up to the task. We have tried writing the prompts multiple times and whilst we have seen some improvement, it’s not consistent. We have a premium ChatGPT subscription and also tried using GPT4.0 and it didn’t help.\n\n\n\n\n\n\n\nImportant\n\n\n\nUpdate! OpenAI released GPT4o in May 2024 and this can produce sensible error mode problems. We’ve left the below in this book because at the time of writing, Copilot and earlier versions of GPT can’t and it’s an interesting insight into some of the issues with AI.\n\n\n\nFrom a learning and teaching perspective, it’s a good example of why teaching might actually be a skill and our job might be safe after all. When we use Error Mode type questions in our courses, we design the errors so that they’re common mistakes learners make at that point in their journey, they’re mistakes that learners would plausibly make, and solving them will teach you something of use. Even when the AI managed to create an accurate error mode problem, it still wasn’t helpful for learning.\nChatGPT fared slightly better although all of the problems were very basic and of the same type (creating a vector) until we asked it to give us a specific problem (e.g., error mode for ggplot).\nChatGPT also suffered from the problem that it would tell you what the error was or produce code that did not have any errors. We particularly enjoyed this response whereby it seemed to pretend that it was doing it on purpose as a teachable moment. We know we are anthropomorphising the AI here but we imagine any educator will feel a sense of kinship at trying to make your mistakes seem intentional.\n\n\n\nIt often won’t tell you what built-in dataset you need to load to run the code (and this isn’t the intended error). Unless you have a working knowledge of built-in datasets in R and the packages they’re from, this is unnecessarily confusing.\nThere is no prompt we could give Copilot that will result in it producing code with an error (even when the same prompt works with ChatGPT). So we gave up.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nThis chapter was last updated in November 2024 and should be considered a living document. The functionality and capability of AI is changing rapidly and the most recent advances may not reflect what is described in this book.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "04-errors.html",
    "href": "04-errors.html",
    "title": "\n4  Error checking and debugging\n",
    "section": "",
    "text": "4.1 Simple errors\nIn this chapter, you’ll learn how to use AI to identify and fix coding errors. This is probably the best use case of AI: using it to debug code that you wrote. Human expertise drives the code, while AI’s attention to detail can help spot small mistakes such as missing commas.\nAI is generally good at this task, although the more complex your code, the more likely it is to struggle. This chapter gives examples to help you with prompt engineering for error checking.\nSo that you can reproduce the same errors, let’s create a reproducible example and load some packages and a dataset.\nUnlike the other chapters you don’t need to do any set-up, in fact, you can often just copy and paste the code and error in and it will figure out that you want it to fix it without even needing to explicitly ask.\nHere’s a simple error where we have given it the wrong function name:\nggplot(penguins, aes(x = species)) +\n   geom_barchart()\n\nError in geom_barchart(): could not find function \"geom_barchart\"\nFixing a simple error",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "04-errors.html#sec-simple-errors",
    "href": "04-errors.html#sec-simple-errors",
    "title": "\n4  Error checking and debugging\n",
    "section": "",
    "text": "NoteActivity 2\n\n\n\nGive Copilot both the code and the error. One without the other is likely to result in a poor or incomplete answer (whether you ask a human or an AI).",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "04-errors.html#activity-3-contextual-errors",
    "href": "04-errors.html#activity-3-contextual-errors",
    "title": "\n4  Error checking and debugging\n",
    "section": "\n4.2 Activity 3: Contextual errors",
    "text": "4.2 Activity 3: Contextual errors\nSomething that catches many people out is when the error is actually being caused by code further up your script rather than the bit that is results in the error.\nFor example, in this code, what we intended to do was to create a dataset that just has penguins from Biscoe Island and then calculate their mean body mass. This code will run, but it produces NaN as the value.\n\nbiscoe_penguins &lt;- penguins %&gt;%\n  filter(island == \"biscoe\")\n\nbiscoe_penguins %&gt;%\n  summarise(mean_mass = mean(body_mass_g))\n\n\n\n\nmean_mass\n\n\nNaN\n\n\n\n\n\nIf you just give an AI the code and the table and ask it to explain what’s happening, it will do its best but without knowing the dataset or what code has preceded it, it won’t give you the exact answer, although in this case it hints at it.\n\n\n\n\nChatGPT giving its best guess\n\n\n\nThere’s a couple of things you can do at this point:\n\nGive the AI all the code you’ve used so far\nGive the AI more information about the dataset.\n\nYou can manually type out a description but there’s some functions you can use that can automate this.\nsummary() is useful because it provides a list of all variables with some descriptive statistics so that the AI has a sense of the type and range of data:\n\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2                                 \n\n\nstr() is also useful because it lists the variables, their data type, and the initial values for each variable. However, that means that you are giving it at least some of the raw data so you have to be very careful if you have sensitive / confidential data and you must ensure that any use of AI is in line with your data management plan. Using Copilot Enterprise means the data won’t be stored and used to train the AI further so it’s potentially the best option (which is not to say it’s safe or problem free, please be careful and critical!).\n\nstr(penguins)\n\ntibble [344 × 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n\nFinally, ls() provides a list of all the variables in a given object. It doesn’t provide any info on the variable type or sample, but that does mean it’s the most secure and depending on the task, this might be all the info you really need to give the AI. I would suggest starting with ls() and only scaling up if necessary (and your data isn’t sensitive):\n\nls(penguins)\n\n[1] \"bill_depth_mm\"     \"bill_length_mm\"    \"body_mass_g\"      \n[4] \"flipper_length_mm\" \"island\"            \"sex\"              \n[7] \"species\"           \"year\"             \n\n\n\nRun summary(biscoe_penguins) and give the AI the output so that it better understands the structure and contents of the datasets and then give it the code you used to filter the dataset.\n\nIf you haven’t spotted it by now, the error is that in the filter biscoe should be Biscoe with a capital B. There is no shortcut for knowing your data.\n\n\n\n\nCopilot getting very close",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "04-errors.html#activity-4-incorrect-but-functional-code",
    "href": "04-errors.html#activity-4-incorrect-but-functional-code",
    "title": "\n4  Error checking and debugging\n",
    "section": "\n4.3 Activity 4: Incorrect (but functional) code",
    "text": "4.3 Activity 4: Incorrect (but functional) code\nSometimes (often) when we write code, the issue isn’t that our code doesn’t work, but that it doesn’t do what we intended to do and we can’t figure out why.\nFor example, let’s say that we want to calculate the average body_mass_g for each species by sex. We’re feeling a bit lazy and we copy and paste in the following from a previous script we have:\n\npenguins %&gt;%\n  group_by(sex, species) %&gt;%\n  summarise(mean_body_mass = sd(body_mass_g, na.rm = TRUE))\n\n\n\n\nsex\nspecies\nmean_body_mass\n\n\n\nfemale\nAdelie\n269.3801\n\n\nfemale\nChinstrap\n285.3339\n\n\nfemale\nGentoo\n281.5783\n\n\nmale\nAdelie\n346.8116\n\n\nmale\nChinstrap\n362.1376\n\n\nmale\nGentoo\n313.1586\n\n\nNA\nAdelie\n477.1661\n\n\nNA\nGentoo\n338.1937\n\n\n\n\n\n\nWe know something isn’t right here. Because we’re responsible researchers, we’ve taken time to understand our dataset and what plausible values should be and we know there’s no way that the average body mass of a penguin is 269 grams (unless the penguin is made of chocolate). But the code is running fine, we know it’s worked before, and we can’t see what we’ve done wrong.\nYou can ask the AI to help you but you can’t just give it the code and output, you also need to tell it what you intended to do. The more complex your code, the more information you will need to give it in order for it to help you find the error.\n\n\n\n\nFixing a functional error\n\n\n\nThis is a good example of why there is no AI tool that allows you to skip understanding the data you’re working with and knowing what it is you’re trying to do.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "04-errors.html#activity-5-rmd-errors",
    "href": "04-errors.html#activity-5-rmd-errors",
    "title": "\n4  Error checking and debugging\n",
    "section": "\n4.5 Activity 5: Rmd errors",
    "text": "4.5 Activity 5: Rmd errors\nIf you’re working in R Markdown or Quarto, sometimes the errors will stem from your code chunk settings or YAML.\nIn your Rmd file, create a new code chunk and copy and paste the following:\n\npenguins %&gt;%\n  count()\n\nBut then delete one of the final back ticks (`) from the code chunk.\nThe code is fine, it provides a simple count of the number of observations in the dataset. But if you try and knit the file, you’ll get a long ! attempt to use zero-length variable name. Copilot wasn’t that helpful because all of its suggestions relate to checking your code:\n\n\n\n\nMissing the mark\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nI know I might be starting to sound like a broken record but please remember that artificial intelligence is not actually intelligent. It’s not thinking, it’s not making conscious decisions, it has no expert subject matter knowledge. No matter how helpful it is, you must always check the output of the code it gives you.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nThis book was written in Spring 2024 and should be considered a living document. The functionality and capability of AI is changing rapidly and the most recent advances may not reflect what is described in this book. Given the brave new world in which we now live, all constructive feedback and suggestions are welcome! If you have any feedback or suggestions, please provide it via Forms.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "05-review.html",
    "href": "05-review.html",
    "title": "\n5  Code review\n",
    "section": "",
    "text": "5.1 Code comments\nCode comments are lines or sections of text added within the code itself that are ignored by the computer when the program runs. They’re there for human readers, not machines. In R, you add comments to code by adding # to the start of the string:\n# this is a comment\n\n# compute the mean of three numbers\nmean(c(1,2,3))\n\n[1] 2\nComments are useful for several reasons:\nOverall, comments are a crucial part of writing clean, maintainable, and collaborative code. They help make the code more accessible and understandable to anyone who might work on it in the future.\nFor transparency, Copilot wrote the above text.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "05-review.html#code-comments",
    "href": "05-review.html#code-comments",
    "title": "\n5  Code review\n",
    "section": "",
    "text": "Clarification: They explain what certain parts of the code do, making it easier for others (and yourself) to understand the logic and flow of the code.\nDocumentation: They provide information on how the code works or why certain decisions were made, which is helpful for future reference.\nDebugging: Temporarily commenting out parts of code can help isolate sections that may be causing errors, without deleting the code.\nCollaboration: In team projects, comments can be used to communicate with other developers about the status or purpose of the code.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "05-review.html#activity-1-add-comments-with-ai",
    "href": "05-review.html#activity-1-add-comments-with-ai",
    "title": "\n5  Code review\n",
    "section": "\n5.2 Activity 1: Add comments with AI",
    "text": "5.2 Activity 1: Add comments with AI\nFirst we’ll use use the palmerpenguins dataset again.\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\ndata(\"penguins\")\n\nYou can use AI tools to help add comments to your code. Previous experience has taught us that we need to be a bit specific with what we want the AI to do so we’ll give it a clear prompt. In your chosen platform, input the below code with the prompt:\n\nAdd comments to this code. Keep the comments as concise as possible Ask me any questions about the code if you are not sure what it is doing or why. Do not change anything about the code.\n\n\npenguins_clean &lt;- penguins %&gt;%\n  filter(complete.cases(.)) %&gt;%\n  mutate(across(where(is.factor), as.character)) %&gt;%\n  mutate(species_sex = interaction(species, sex, sep = \"_\"))\n\n\n\n\n\nAdding comments\n\n\n\nA couple of notes:\n\nThe AI can only tell you what the code is doing, it can’t say why you chose to do that. In this example, we’ve created a new column that combines species and sex but the comment gives us no idea what the rationale was for this. The more complex your analysis, the more crucial it becomes to explain the rationale.\nWe’ve reminded it to be concise but still remember that not all the comments necessary. Too many comments are a different problem to too few, but they’re still a problem so always review what it produces.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "05-review.html#activity-2-review-existing-comments",
    "href": "05-review.html#activity-2-review-existing-comments",
    "title": "\n5  Code review\n",
    "section": "\n5.3 Activity 2: Review existing comments",
    "text": "5.3 Activity 2: Review existing comments\nIn addition to asking AI to comment your code, you can also ask it to review comments you’ve made yourself. To see how this works with a more complex example, and as an act of masochism, I gave the AI some code I wrote for a publication. The full paper is here if you’re interested - the quant analyses ended up being punted to the online appendix because of word count.\nYou can load in the dataset yourself with this code:\n\n# read in data but skip rows 2 and 3\ncol_names &lt;- names(read_csv(\"https://osf.io/download/tf3xs/\", n_max = 0))\ndat_raw &lt;- read_csv(\"https://osf.io/download/tf3xs/\", col_names = col_names, skip = 3) \n\nThe first section of my code involved quite a complicated and long bit of wrangling, all done in a single pipeline. The purpose of the code is to clean up data collected on the survey platform Qualtrics and recoding some of the demographic variables. This is actually a shortened version because the original hit the character limit for Copilot. I did put some effort into writing comments before publication but there are almost certainly improvements to be made.\n\ndat &lt;- dat_raw%&gt;%\n  filter(Progress &gt; 94, # remove incomplete responses\n         DistributionChannel != \"preview\") %&gt;% # Remove Emily's preview data\n  select(ResponseId, \"duration\" = 5, Q5:Q21) %&gt;%\n  # replace NAs with \"none\" for disability info\n  mutate(disability_nos = replace_na(disability_nos, \"None\"),\n         physical_chronic = replace_na(physical_chronic, \"None\"),\n         mental_health = replace_na(mental_health, \"None\"),\n) %&gt;%\n   # recode gender data\n\n  mutate(gender_cleaned = case_when(Q6 %in% c(\"Female\", \"female\", \"Woman\", \"woman\", \"Cisgender woman\",\"female (she/her)\", \"F\", \"f\", \"Womxn\", \"Woman (tranas)\") ~ \"Woman\",\n                                    Q6 %in% c(\"Man\", \"man\", \"M\", \"m\", \"Male (he/him)\", \"Male\", \"male\", \"Trans man.\") ~ \"Man\",\n                                    Q6 %in% c(\"Agender\", \"Genderfluid\", \"GNC\", \"NB\", \"non-binary\", \"    \nNon-binary\", \"Non-Binary\", \"Non-binary femme\", \"non-binary male\", \"non binary\",\n\"Non binary\", \"Nonbinary\", \"Queer\", \"Transmasculine\", \"Non-binary\") ~ \"Non-binary\",\n                            TRUE ~ \"Not stated\")) %&gt;%\n  # select necessary columns and tidy up the names\n        select(ResponseId,\n             \"age\" = Q5,\n             \"gender\" = Q6,\n             \"mature\" = Q7,\n             \"level_study\" = Q8,\n             \"country\" = Q9,\n             \"subject\" = Q10,\n             \"english_first\" = Q11,\n             \"neurotype_open\" = Q13, \n             \"disability_open\" = Q14,\n             \"why_open\" = Q18,\n             \"how_open\" = Q23,\n             \"advantages\" = Q20,\n             \"disadvantages\" = Q21,\n             everything()) \n\nProvide the code with the following prompt:\n\nReview my use of comments and make improvements to the comments where necessary. Keep the comments as concise as possible. Do not change anything about the code.\n\nIn an earlier version of this book with a different AI tool (Gemini) providing this prompt resulting in it changing the code without telling me so that not only did it not do what I intended but it also didn’t work so you need to be very, very careful.\nTo check that it hasn’t changed any code you can run all.equal() to compare two datasets. If it returns true, it means that the result of your inital code and the new code are identical. This is a really important check.\n\n# Assigning the processed data to 'dat'\ndat_copilot &lt;- dat_raw %&gt;%\n  filter(Progress &gt; 94, # Exclude responses below 95% completion\n       DistributionChannel != \"preview\") %&gt;% # Exclude preview data\nselect(ResponseId, \"duration\" = 5, Q5:Q21) %&gt;%\nmutate(\n  disability_nos = replace_na(disability_nos, \"None\"), # Default 'None' for missing disability info\n  physical_chronic = replace_na(physical_chronic, \"None\"),\n  mental_health = replace_na(mental_health, \"None\")\n) %&gt;%\nmutate(\n  gender_cleaned = case_when(\n    Q6 %in% c(\"Female\", \"female\", \"Woman\", \"woman\", \"Cisgender woman\",\"female (she/her)\", \"F\", \"f\", \"Womxn\", \"Woman (tranas)\") ~ \"Woman\",\n    Q6 %in% c(\"Man\", \"man\", \"M\", \"m\", \"Male (he/him)\", \"Male\", \"male\", \"Trans man.\") ~ \"Man\",\n    Q6 %in% c(\"Agender\", \"Genderfluid\", \"GNC\", \"NB\", \"non-binary\", \"Non-binary\", \"Non-Binary\", \"Non-binary femme\", \"non-binary male\", \"non binary\", \"Non binary\", \"Nonbinary\", \"Queer\", \"Transmasculine\", \"Non-binary\") ~ \"Non-binary\",\n    TRUE ~ \"Not stated\"\n  ) # Standardize gender representation\n) %&gt;%\nselect(\n  ResponseId,\n  \"age\" = Q5, # Rename Q5 to 'age'\n  \"gender\" = Q6, # Rename Q6 to 'gender'\n  \"mature\" = Q7, # Rename Q7 to 'mature'\n  \"level_study\" = Q8, # Rename Q8 to 'level_study'\n  \"country\" = Q9, # Rename Q9 to 'country'\n  \"subject\" = Q10, # Rename Q10 to 'subject'\n  \"english_first\" = Q11, # Rename Q11 to 'english_first'\n  \"neurotype_open\" = Q13, # Rename Q13 to 'neurotype_open'\n  \"disability_open\" = Q14, # Rename Q14 to 'disability_open'\n  \"why_open\" = Q18, # Rename Q18 to 'why_open'\n  \"how_open\" = Q23, # Rename Q23 to 'how_open'\n  \"advantages\" = Q20, # Rename Q20 to 'advantages'\n  \"disadvantages\" = Q21, # Rename Q21 to 'disadvantages'\n  everything() # Include all remaining columns\n)",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "05-review.html#refactor-code",
    "href": "05-review.html#refactor-code",
    "title": "\n5  Code review\n",
    "section": "\n5.4 Refactor code",
    "text": "5.4 Refactor code\nTo refactor code refers to the process of restructuring existing code without changing its intended behavior. The goal is to make the code more maintainable, readable, and efficient, while not altering the functionality or output. The benefits of refactoring code should be that it:\n\nImproves Readability: Makes the code easier to understand for anyone who reads it in the future, which includes other developers or even the original author after some time has passed.\nReduces Complexity: Simplifies complex code structures, breaking down large functions into smaller, more manageable ones.\nEnhances Maintainability: With cleaner code, it becomes easier to maintain and update the software over time.\nFacilitates Extensibility: Well-factored code can be extended with new features more easily.\nImproves Performance: In some cases, refactoring can optimize the performance of the software by removing redundancies and improving algorithms.\nIdentifies Bugs: The process of refactoring can often reveal hidden bugs or issues in the code that can then be fixed.\n\nWith thanks to Copilot for writing the above.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "05-review.html#activity-3-refactor",
    "href": "05-review.html#activity-3-refactor",
    "title": "\n5  Code review\n",
    "section": "\n5.5 Activity 3: Refactor",
    "text": "5.5 Activity 3: Refactor\nI’ll stick with the example of code from my publication because it’s complicated enough that there are likely improvements or alternative solutions. Using the same code chunk as above, the prompt is:\n\nrefactor this code and explain what you have changed and why. Where possible, use a tidyverse approach.\n\nCopilot’s first attempt produces an error\n\ndat_copilot &lt;- dat_raw %&gt;%\n  filter(Progress &gt; 94, DistributionChannel != \"preview\") %&gt;% # Keep only complete and non-preview data\n  rename(duration = Q5) %&gt;% # Rename Q5 here to avoid repetition\n  select(ResponseId, duration, Q6:Q21) %&gt;% # Select relevant columns once\n  mutate(\n    across(c(disability_nos, physical_chronic, mental_health), ~replace_na(., \"None\")), # Use across() for NAs\n    gender_cleaned = case_when(\n      Q6 %in% c(\"Female\", \"female\", \"Woman\", \"woman\", \"Cisgender woman\", \"female (she/her)\", \"F\", \"f\", \"Womxn\", \"Woman (tranas)\") ~ \"Woman\",\n      Q6 %in% c(\"Man\", \"man\", \"M\", \"m\", \"Male (he/him)\", \"Male\", \"male\", \"Trans man.\") ~ \"Man\",\n      Q6 %in% c(\"Agender\", \"Genderfluid\", \"GNC\", \"NB\", \"non-binary\", \"Non-binary\", \"Non-Binary\", \"Non-binary femme\", \"non-binary male\", \"non binary\", \"Non binary\", \"Nonbinary\", \"Queer\", \"Transmasculine\", \"Non-binary\") ~ \"Non-binary\",\n      TRUE ~ \"Not stated\"\n    ) # Recode gender once\n  ) %&gt;%\n  select(\n    ResponseId,\n    duration,\n    gender_cleaned,\n    across(Q7:Q21, .names = \"{.col}_cleaned\") # Clean up column names in one go\n  )\n\nError in `select()`:\n! Problem while evaluating `across(Q7:Q21, .names = \"{.col}_cleaned\")`.\nCaused by error in `across()`:\n! Must only be used inside data-masking verbs like `mutate()`,\n  `filter()`, and `group_by()`.\n\n\nChatGPT 4o introduces an error in that it’s changed \"duration\" = 5 to duration = Q5. The original code was selecting the column by index number (i.e., the 5th column), this isn’t the name of a column and so it doesn’t run (although if you fix this it does then run and all.equal() returns true.\n\ndat_chat &lt;- dat_raw %&gt;%\n  # Remove incomplete responses and preview data\n  filter(Progress &gt; 94, DistributionChannel != \"preview\") %&gt;%\n  \n  # Select necessary columns and rename them\n  select(ResponseId, duration = Q5, Q5:Q21) %&gt;%\n  \n  # Replace NAs with \"None\" for disability info\n  mutate(across(c(disability_nos, physical_chronic, mental_health), ~ replace_na(.x, \"None\"))) %&gt;%\n  \n  # Recode gender data\n  mutate(gender_cleaned = case_when(\n    Q6 %in% c(\"Female\", \"female\", \"Woman\", \"woman\", \"Cisgender woman\", \"female (she/her)\", \"F\", \"f\", \"Womxn\", \"Woman (tranas)\") ~ \"Woman\",\n    Q6 %in% c(\"Man\", \"man\", \"M\", \"m\", \"Male (he/him)\", \"Male\", \"male\", \"Trans man.\") ~ \"Man\",\n    Q6 %in% c(\"Agender\", \"Genderfluid\", \"GNC\", \"NB\", \"non-binary\", \"Non-binary\", \"Non-Binary\", \"Non-binary femme\", \"non-binary male\", \"non binary\", \"Non binary\", \"Nonbinary\", \"Queer\", \"Transmasculine\", \"Non-binary\") ~ \"Non-binary\",\n    TRUE ~ \"Not stated\"\n  )) %&gt;%\n  \n  # Select and rename necessary columns\n  select(\n    ResponseId,\n    age = Q5,\n    gender = Q6,\n    mature = Q7,\n    level_study = Q8,\n    country = Q9,\n    subject = Q10,\n    english_first = Q11,\n    neurotype_open = Q13,\n    disability_open = Q14,\n    why_open = Q18,\n    how_open = Q23,\n    advantages = Q20,\n    disadvantages = Q21,\n    everything()\n  )\n\nError in `select()`:\n! Can't subset columns that don't exist.\n✖ Column `Q5` doesn't exist.\n\n\nBecause you have to check everything so carefully, I wondered if it might be easier to give it less code at any one time so I asked Copilot to split the code in each pipeline into a different object which it did:\n\nSplit the code in each pipeline into a separate object\n\n\n# Filter complete and non-preview data\nfiltered_data &lt;- dat_raw %&gt;%\n  filter(Progress &gt; 94,\n         DistributionChannel != \"preview\")\n\n# Select and rename columns\nselected_data &lt;- filtered_data %&gt;%\n  select(ResponseId, \"duration\" = 5, Q5:Q21)\n\n# Replace NAs with \"None\" for disability info\nna_replaced_data &lt;- selected_data %&gt;%\n  mutate(\n    disability_nos = replace_na(disability_nos, \"None\"),\n    physical_chronic = replace_na(physical_chronic, \"None\"),\n    mental_health = replace_na(mental_health, \"None\")\n  )\n\n# Recode gender data\ngender_recoded_data &lt;- na_replaced_data %&gt;%\n  mutate(\n    gender_cleaned = case_when(\n      Q6 %in% c(\"Female\", \"female\", \"Woman\", \"woman\", \"Cisgender woman\", \"female (she/her)\", \"F\", \"f\", \"Womxn\", \"Woman (tranas)\") ~ \"Woman\",\n      Q6 %in% c(\"Man\", \"man\", \"M\", \"m\", \"Male (he/him)\", \"Male\", \"male\", \"Trans man.\") ~ \"Man\",\n      Q6 %in% c(\"Agender\", \"Genderfluid\", \"GNC\", \"NB\", \"non-binary\", \"Non-binary\", \"Non-Binary\", \"Non-binary femme\", \"non-binary male\", \"non binary\", \"Non binary\", \"Nonbinary\", \"Queer\", \"Transmasculine\", \"Non-binary\") ~ \"Non-binary\",\n      TRUE ~ \"Not stated\"\n    )\n  )\n\n# Final selection and renaming of columns\nfinal_data &lt;- gender_recoded_data %&gt;%\n  select(\n    ResponseId,\n    \"age\" = Q5,\n    \"gender\" = gender_cleaned,\n    \"mature\" = Q7,\n    \"level_study\" = Q8,\n    \"country\" = Q9,\n    \"subject\" = Q10,\n    \"english_first\" = Q11,\n    \"neurotype_open\" = Q13,\n    \"disability_open\" = Q14,\n    \"why_open\" = Q18,\n    \"how_open\" = Q23,\n    \"advantages\" = Q20,\n    \"disadvantages\" = Q21,\n    everything()\n  )\n\n# The final dataset is now stored in 'final_data'\n\nThen, for each chunk, I asked it to refactor the code, where possible. I slightly amended the prompt to explicitly say that if the code was already efficient enough, not to change anything because some of the steps are quite simple.\n\nRefactor this code where necessary. Explain what you changed and why. Do not change anything if the code is already efficient. Use the tidyverse where possible.\n\n\nFor step 3, Copilot and ChatGPT were both quite good at this and all.equal() returned TRUE.\n\n\n# chatgpt and copilot solution\nchat_dat_na_replaced &lt;- dat_selected %&gt;%\n  mutate(\n    across(c(disability_nos, physical_chronic, mental_health), ~replace_na(., \"None\"))\n  )\n\nFor step 4 it was a bit of a mess:\nBoth Copilot removed everything() with this explanation:\n\nRemoved everything(): The everything() argument in select is redundant here because you’ve explicitly specified all the columns you want to keep.\n\nWhich is just wrong and means you end up not selecting the rest of the columns.\n\nfinal_data_copilot &lt;- gender_recoded_data %&gt;%\n  # Select & rename columns (exclude everything())\n  select(ResponseId,\n         age = Q5,\n         gender = gender_cleaned,\n         mature = Q7,\n         level_study = Q8,\n         country = Q9,\n         subject = Q10,\n         english_first = Q11,\n         neurotype_open = Q13,\n         disability_open = Q14,\n         why_open = Q18,\n         how_open = Q23,\n         advantages = Q20,\n         disadvantages = Q21)\n\nChatGPT’s actually worked and returned an identical object although I am not convinced that this code is better, I think it’s just more verbose:\n\nClarity: Using rename makes it clear which columns are being renamed before they are selected. This separates the concerns of renaming and selecting, which can improve readability. Maintainability: If additional columns need to be renamed or if the selection needs to be modified, having separate rename and select steps makes it easier to adjust the code.\n\n\nfinal_data_chat &lt;- gender_recoded_data %&gt;%\n  rename(\n  age = Q5,\n  gender = gender_cleaned,\n  mature = Q7,\n  level_study = Q8,\n  country = Q9,\n  subject = Q10,\n  english_first = Q11,\n  neurotype_open = Q13,\n  disability_open = Q14,\n  why_open = Q18,\n  how_open = Q23,\n  advantages = Q20,\n  disadvantages = Q21\n) %&gt;%\nselect(ResponseId, age, gender, mature, level_study, country, subject, english_first, neurotype_open, disability_open, why_open, how_open, advantages, disadvantages, everything())",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "05-review.html#alternative-approaches",
    "href": "05-review.html#alternative-approaches",
    "title": "\n5  Code review\n",
    "section": "\n5.6 Alternative approaches",
    "text": "5.6 Alternative approaches\nIn the PsyTeachR courses we strongly use the tidyverse approach but it’s useful to be aware of other approaches, particularly Base R given that it doesn’t require any package dependencies.\nYou can simply amend the prompt to say use Base R as an alternative:\n\nwhen refactoring, use Base R instead of tidyverse\n\n\nIt’s definitely not more efficient but ChatGPT’s output does indeed use Base R and did recode the variable correctly.\n\n\n# Recode gender data\ngender_recoded_data_chat &lt;- na_replaced_data\n\n# Define the recoding function\nrecode_gender &lt;- function(gender) {\n  if (gender %in% c(\"Female\", \"female\", \"Woman\", \"woman\", \"Cisgender woman\", \"female (she/her)\", \"F\", \"f\", \"Womxn\", \"Woman (tranas)\")) {\n    return(\"Woman\")\n  } else if (gender %in% c(\"Man\", \"man\", \"M\", \"m\", \"Male (he/him)\", \"Male\", \"male\", \"Trans man.\")) {\n    return(\"Man\")\n  } else if (gender %in% c(\"Agender\", \"Genderfluid\", \"GNC\", \"NB\", \"non-binary\", \"Non-binary\", \"Non-Binary\", \"Non-binary femme\", \"non-binary male\", \"non binary\", \"Non binary\", \"Nonbinary\", \"Queer\", \"Transmasculine\", \"Non-binary\")) {\n    return(\"Non-binary\")\n  } else {\n    return(\"Not stated\")\n  }\n}\n\n# Apply the recoding function to the 'Q6' column\ngender_recoded_data_chat$gender_cleaned &lt;- sapply(na_replaced_data$Q6, recode_gender)\n\nall.equal(gender_recoded_data, gender_recoded_data_chat)\n\n[1] \"Component \\\"gender_cleaned\\\": names for current but not for target\"",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "05-review.html#conclusions",
    "href": "05-review.html#conclusions",
    "title": "\n5  Code review\n",
    "section": "\n5.7 Conclusions",
    "text": "5.7 Conclusions\nI hadn’t actually used AI to perform these types of tasks before writing this book so here’s my takeaways:\n\nCHECK EVERYTHING.\nIf you give an AI code, you simply cannot trust that it won’t change your code, even if that’s not the task you ask it to do. If you use AI to add or review comments, you must check the output. Tools like all.equal() can help perform these checks.\nYou also can’t trust that the comments will be accurate. Anything an AI writes must be checked before you use it. If you don’t know if it’s right, don’t use it.\nBecause you have to check what it does so carefully, don’t give it a big dump of code. Smaller chunks will end up taking less time.\nIn some cases it was really useful and as someone who doesn’t really use or know much Base R, I can see that this would be a great way to learn alternative approaches or to fill in comments.\nThat said, the amount of checking it takes is substantial and so I’m not completely convinced that it would be any quicker than doing it yourself.\n\n\n\n\n\n\n\nCaution\n\n\n\nThis book was written in Spring 2024 and should be considered a living document. The functionality and capability of AI is changing rapidly and the most recent advances may not reflect what is described in this book. Given the brave new world in which we now live, all constructive feedback and suggestions are welcome! If you have any feedback or suggestions, please provide it via Forms.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "06-writing.html",
    "href": "06-writing.html",
    "title": "\n6  Writing Code with AI\n",
    "section": "",
    "text": "6.1 Activity 1: Set-up\nAgain we’ll use the palmerpenguins dataset for this exercise so open up an Rmd and run the following:\nlibrary(tidyverse)\nlibrary(palmerpenguins)\ndata(\"penguins\")\nWe’ll also do a little bit of set-up for the AI:",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "06-writing.html#activity-1-set-up",
    "href": "06-writing.html#activity-1-set-up",
    "title": "\n6  Writing Code with AI\n",
    "section": "",
    "text": "Act like an expert programmer in R. I want you to help me write code. The code should be commented and should use the tidyverse where possible. Ask me questions about the code before you write it if necessary.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "06-writing.html#activity-2-knowledge-is-power",
    "href": "06-writing.html#activity-2-knowledge-is-power",
    "title": "\n6  Writing Code with AI\n",
    "section": "\n6.2 Activity 2: Knowledge is power",
    "text": "6.2 Activity 2: Knowledge is power\nWhen you input this starting prompt, there’s a good chance you’ll get something like the following:\n\n\n\n\nMore info needed\n\n\n\nBefore you ask the AI to write code, it’s helpful to give it as much information as you can about your dataset. You could write out a description manually but there’s a few options to automate.\nsummary() is useful because it provides a list of all variables with some descriptive statistics so that the AI has a sense of the type and range of data:\n\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2                                 \n\n\nstr() is also useful because it lists the variables, their data type, and the initial values for each variable. However, that means that you are giving it at least some of the raw data so you have to be very careful if you have sensitive / confidential data and you must ensure that any use of AI is in line with your data management plan. Using Copilot Enterprise means the data won’t be stored and used to train the AI further so it’s potentially the best option (which is not to say it’s safe or problem free, please be careful and critical!).\n\nstr(penguins)\n\ntibble [344 × 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n\nFinally, ls() provides a list of all the variables in a given object. It doesn’t provide any info on the variable type or sample, but that does mean it’s the most secure and depending on the task, this might be all the info you really need to give the AI. I would suggest starting with ls() and only scaling up if necessary (and your data isn’t sensitive):\n\nls(penguins)\n\n[1] \"bill_depth_mm\"     \"bill_length_mm\"    \"body_mass_g\"      \n[4] \"flipper_length_mm\" \"island\"            \"sex\"              \n[7] \"species\"           \"year\"             \n\n\nIn your AI of choice, input the following:\n\nhere are the variables in my data set\n\n\nls(penguins) [1] “bill_depth_mm” “bill_length_mm” “body_mass_g” “flipper_length_mm” [5] “island” “sex” “species” “year”\n\nWithout being asked, Copilot has provided some examples of how you might analyse this data using R and the code all works as intended.\n\n# Load the tidyverse package\nlibrary(tidyverse)\n\n# Assuming your data is in a dataframe called 'penguins'\n# Let's start by getting a summary of each numerical variable\npenguins %&gt;%\n  summarise(\n    Average_Bill_Depth = mean(bill_depth_mm, na.rm = TRUE),\n    Average_Bill_Length = mean(bill_length_mm, na.rm = TRUE),\n    Average_Body_Mass = mean(body_mass_g, na.rm = TRUE),\n    Average_Flipper_Length = mean(flipper_length_mm, na.rm = TRUE)\n  )\n\n\n\n\n\n\n\n\n\n\nAverage_Bill_Depth\nAverage_Bill_Length\nAverage_Body_Mass\nAverage_Flipper_Length\n\n\n17.15117\n43.92193\n4201.754\n200.9152\n\n\n\n\n# Now, let's see the distribution of species across different islands\npenguins %&gt;%\n  count(island, species) %&gt;%\n  ggplot(aes(x = island, y = n, fill = species)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Distribution of Penguin Species Across Islands\",\n       x = \"Island\",\n       y = \"Count\")\n\n\n\n\n\n\n# We can also explore the relationship between flipper length and body mass\npenguins %&gt;%\n  ggplot(aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point(aes(color = species)) +\n  geom_smooth(method = \"lm\") +\n  labs(title = \"Relationship Between Flipper Length and Body Mass\",\n       x = \"Flipper Length (mm)\",\n       y = \"Body Mass (g)\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n# If you want to perform more specific analyses or visualizations,\n# please let me know what you're interested in!\n\nI find this hugely problematic. Psychology has spent the last decade dealing with a replication and reproducibility crisis stemming in part because of questionable research practices. As a researcher, you should be making informed decisions as to how you analyse your data and I fear that this type of output is going to increase phishing and atheoretical, exploratory-as-confirmatory nonsense. What happens when the example code the AI spits out without being asked turns out to be a significant regression model that you would never have predicted or run yourself? Are you going to delete it? Or convince yourself that you were going to run it anyway and there’s a perfectly logical explanation?\nBefore I have a full blown existential crisis, let’s get back on track.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "06-writing.html#activity-3-writing-code",
    "href": "06-writing.html#activity-3-writing-code",
    "title": "\n6  Writing Code with AI\n",
    "section": "\n6.3 Activity 3: Writing code",
    "text": "6.3 Activity 3: Writing code\nFirst, we’ll aim to produce a table of descriptive statistics for body_mass_g and a histogram. Because it has the exact variable and object names, it should write code we can easily copy and paste:\n\nCreate a table of descriptive statistics for body mass and a histogram of that variable\n\nThis is ChatGPT’s output (Copilot was very similar):\n\n# Load the tidyverse package\nlibrary(tidyverse)\n\n# Load the penguins dataset (assuming it's from the palmerpenguins package)\ndata(\"penguins\")\n\n# Check the structure of the dataset\nstr(penguins)\n\ntibble [344 × 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n# Summary statistics for body mass\nbody_mass_summary &lt;- penguins %&gt;%\n  summarise(\n    Mean = mean(body_mass_g, na.rm = TRUE),\n    Median = median(body_mass_g, na.rm = TRUE),\n    SD = sd(body_mass_g, na.rm = TRUE),\n    Min = min(body_mass_g, na.rm = TRUE),\n    Max = max(body_mass_g, na.rm = TRUE)\n  )\n\n# Print the summary statistics\nprint(body_mass_summary)\n\n# A tibble: 1 × 5\n   Mean Median    SD   Min   Max\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt;\n1 4202.   4050  802.  2700  6300\n\n# Create a histogram of body mass\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(fill = \"skyblue\", color = \"black\", bins = 20) +\n  labs(\n    title = \"Distribution of Body Mass\",\n    x = \"Body Mass (g)\",\n    y = \"Frequency\"\n  ) +\n  theme_minimal()\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\nSome notes:\n\nI didn’t have to use the exact variable name body_mass_g, it has figured out from my request that’s the one I want to use.\nIt’s also figured out that we’re using the palmerpenguins dataset, although it hasn’t given us the code to load that package so if we just copied and pasted this into a fresh script without having loaded the data already, it wouldn’t work.\nIt’s used na.rm = TRUE to ignore missing values. This is a very common choice but remember it is a choice. You might not want this.\nSimilarly, it’s specified binwidth = 20 for the histogram. Looking at the data this seems like a reasonable binwidth to use, but again, it is a decision the AI has imposed and you must be aware of what you’re accepting.\nI am aware that I am using phrases like “choice” and “decision” that imbue the AI with consciousness. I know that’s not true, I just can’t figure out how to write it any other way.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "06-writing.html#activity-4-giving-the-ai-more-freedom",
    "href": "06-writing.html#activity-4-giving-the-ai-more-freedom",
    "title": "\n6  Writing Code with AI\n",
    "section": "\n6.4 Activity 4: Giving the AI more freedom",
    "text": "6.4 Activity 4: Giving the AI more freedom\nMy initial request to write code was relatively simple and relatively well-specified but let’s try an example where there’s more room for the AI to make choices.\n\nCreate a new variable that codes each penguin as chonky_boi if they’re a large male, chonky_gurl if they’re a large female, smol_boi if they’re a small male, and smol_boi if they’re a small female.\n\nThis prompt gives a lot of leeway. I haven’t specified what to call the new variable, what criteria should be used to determine large and small, or what to do with observations that are neither.\nChatGPT used percentiles to determine category, however, this code didn’t work - it returns all observations as “average”:\n\n# Create a new variable based on conditions\npenguins &lt;- penguins %&gt;%\n  mutate(chonkiness = case_when(\n    sex == \"Male\" & body_mass_g &gt; quantile(body_mass_g, 0.75, na.rm = TRUE) ~ \"chonky_boi\",\n    sex == \"Female\" & body_mass_g &gt; quantile(body_mass_g, 0.75, na.rm = TRUE) ~ \"chonky_gurl\",\n    sex == \"Male\" & body_mass_g &lt;= quantile(body_mass_g, 0.25, na.rm = TRUE) ~ \"smol_boi\",\n    sex == \"Female\" & body_mass_g &lt;= quantile(body_mass_g, 0.25, na.rm = TRUE) ~ \"smol_gurl\",\n    TRUE ~ \"average\"\n  ))\n\n\nIn this code:\n\n\nWe use the case_when() function to define the conditions based on sex and body mass to categorize the penguins.\n\n\nFor males with a body mass greater than the 75th percentile, they are categorized as “chonky_boi.” For females with a body mass greater than the 75th percentile, they are categorized as “chonky_gurl.”\n\n\nFor males with a body mass less than or equal to the 25th percentile, they are categorized as “smol_boi.” For females with a body mass less than or equal to the 25th percentile, they are also categorized as “smol_gurl.”\n\n\nAll other penguins are categorized as “average.”\n\n\nWe then use mutate() to create the new variable “chonkiness” based on these conditions.\n\nI will spare you the full adventure (my chat history is here if you’d like to see) but after quite a bit of back-and-forth I realised that in the dataset “male” and “female” should both be lowercase and the code ChatGPT gave me had capitalised them both. There is no substitute for knowing your data.\nOnce I changed this, it worked.\n\n# Create a new variable based on conditions\npenguins &lt;- penguins %&gt;%\n  mutate(chonkiness = case_when(\n    sex == \"male\" & body_mass_g &gt; quantile(body_mass_g, 0.75, na.rm = TRUE) ~ \"chonky_boi\",\n    sex == \"female\" & body_mass_g &gt; quantile(body_mass_g, 0.75, na.rm = TRUE) ~ \"chonky_gurl\",\n    sex == \"male\" & body_mass_g &lt;= quantile(body_mass_g, 0.25, na.rm = TRUE) ~ \"smol_boi\",\n    sex == \"female\" & body_mass_g &lt;= quantile(body_mass_g, 0.25, na.rm = TRUE) ~ \"smol_gurl\",\n    TRUE ~ \"average\"\n  ))\n\nCopilot used a median split and didn’t try and create a third category, which is a questionable choice because the wording of the prompt really implies there needs to be something that the penguins are larger or smaller than. The code did work out of the box but remember the Jurassic Park rule: just because you can, doesn’t mean you should.\n\n# Assuming 'penguins' is your dataframe and 'body_mass_g' is the variable for body mass\n# First, we need to define what we consider 'large' and 'small'. \n# For this example, let's assume penguins heavier than the median are 'large', \n# and those equal or lighter are 'small'.\n\n# Calculate the median body mass\nmedian_body_mass &lt;- median(penguins$body_mass_g, na.rm = TRUE)\n\n# Create the new variable 'size_category'\npenguins &lt;- penguins %&gt;%\n  mutate(size_category = case_when(\n    body_mass_g &gt; median_body_mass & sex == \"male\"   ~ \"chonky_boi\",\n    body_mass_g &gt; median_body_mass & sex == \"female\" ~ \"chonky_gurl\",\n    body_mass_g &lt;= median_body_mass & sex == \"male\"   ~ \"smol_boi\",\n    body_mass_g &lt;= median_body_mass & sex == \"female\" ~ \"smol_gurl\",\n    TRUE ~ NA_character_  # for missing or other values\n  ))\n\nThis code is a good example of why LLMs are inherently Luddites, even if they produce working code. When there’s missing data, case_when() used to require you to specify the type of NA, in this case NA_character. This is very uninintuitive, particularly when you’re trying to teach beginner coders (how can missing data have a type? is an entirely reasonable question) so I was delighted when it updated to remove this requirement. Additionally, TRUE was also changed to default which is a bit more readable.\nHowever, these changes are not reflected in Copilot’s code suggestion because the training data is older than the most recent update to case_when(). This example is relatively minor but it’s important to recognise that if you only use these kinds of AI to write code, you will very quickly be writing outdated code and using deprecated functions.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "06-writing.html#activity-5-further-analysis",
    "href": "06-writing.html#activity-5-further-analysis",
    "title": "\n6  Writing Code with AI\n",
    "section": "\n6.5 Activity 5: Further analysis",
    "text": "6.5 Activity 5: Further analysis\nTo give one last example, I entered the following prompt:\n\nwrite me code to run a linear regression predicting body mass from sex. also include the code to perform necessary assumption tests using the easystats performance package.\n\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n# Load the penguins dataset\ndata(\"penguins\")\n\n# Filter out rows with missing values in body mass or sex\npenguins &lt;- penguins %&gt;%\n  filter(!is.na(body_mass_g) & !is.na(sex))\n\n# Convert sex to lowercase\npenguins$sex &lt;- tolower(penguins$sex)\n\n# Run linear regression predicting body mass from sex\nlm_model &lt;- lm(body_mass_g ~ sex, data = penguins)\n\n# Display summary of the linear regression model\nsummary(lm_model)\n\n\nCall:\nlm(formula = body_mass_g ~ sex, data = penguins)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1295.7  -595.7  -237.3   737.7  1754.3 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3862.27      56.83  67.963  &lt; 2e-16 ***\nsexmale       683.41      80.01   8.542  4.9e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 730 on 331 degrees of freedom\nMultiple R-squared:  0.1806,    Adjusted R-squared:  0.1781 \nF-statistic: 72.96 on 1 and 331 DF,  p-value: 4.897e-16\n\n# Perform assumption tests using the performance package\ncheck_assumptions(lm_model)\n\nError in check_assumptions(lm_model): could not find function \"check_assumptions\"\n\n\nChatGPT refuses to forget that in my conversation history there was an issue with the code not being lowercase, so it’s now including functions to covert to lowercase, even though it’s completely unnecessary.\nIt’s also introduced an error. The function should be check_model() not check_assumptions(). I know this because I know the package. The further away you get from what you could do yourself, the harder it will be to fix any errors and check what it has gotten wrong.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "06-writing.html#conclusions-and-musings",
    "href": "06-writing.html#conclusions-and-musings",
    "title": "\n6  Writing Code with AI\n",
    "section": "\n6.6 Conclusions and musings",
    "text": "6.6 Conclusions and musings\nA large part of coding is looking up examples of code you’ve used before and then tweaking it to your new use case. If you use AI like this, then it can really help speed you up by giving you access to boiler plate code you can adapt. I also find it very useful for those functions that just refuse to stick in my brain - every time I try to change the labels on a faceted ggplot() I get it wrong. These days I just go straight to ChatGPT.\nAdditionally, if what you’re wanting to achieve is relatively simple - descriptive stats, basic plots, simple wrangling and cleaning - it can’t go that far wrong and it’s usually easy enough to spot when something is wrong.\nThese use cases work well because it’s your expertise that drives what the AI does and reviewing and tweaking the output is built-in to these workflows. These are the AI skills that everyone is going to need.\nBut using code written by an AI that you don’t understand is dangerous and irresponsible. Think of all the stupid errors it has made throughout this book, and then imagine someone using it to write code for their medical research. I dread to think of the impact that this abdication of responsibility and expertise is going to have (and will already be having).\nThis is a depressing way to end this book so I gave all three AIs the prompt:\n\nWrite me a fun piece of R code.\n\nChatGPT reassuring me comedy isn’t going to be outsourced any time soon:\n\n# Function to generate a random joke\ngenerate_joke &lt;- function() {\n  jokes &lt;- c(\n    \"Why don't scientists trust atoms? Because they make up everything!\",\n    \"I told my wife she was drawing her eyebrows too high. She looked surprised!\",\n    \"Why did the scarecrow win an award? Because he was outstanding in his field!\",\n    \"Why don't skeletons fight each other? They don't have the guts!\",\n    \"I'm reading a book on anti-gravity. It's impossible to put down!\"\n  )\n  return(sample(jokes, 1))\n}\n\n# Generate and print a random joke\ncat(\"Here's a random joke for you:\\n\")\n\nHere's a random joke for you:\n\ncat(generate_joke(), \"\\n\")\n\nWhy did the scarecrow win an award? Because he was outstanding in his field! \n\n\nCopilot on its way to Vegas (ok I actually quite like this one):\n\n# Simple Slot Machine in R\nset.seed(Sys.time()) # Seed for randomness based on current time\n\n# Function to spin the slot machine\nspin_slot_machine &lt;- function() {\n  fruits &lt;- c(\"🍒\", \"🍋\", \"🍊\", \"🍉\", \"🍇\", \"🍓\")\n  spin &lt;- sample(fruits, size = 3, replace = TRUE)\n  cat(\"Spinning... You got:\", spin, \"\\n\")\n  \n  if (length(unique(spin)) == 1) {\n    cat(\"Congratulations! You won! 🎉\\n\")\n  } else {\n    cat(\"Try again! 🍀\\n\")\n  }\n}\n\n# Spin the slot machine\nspin_slot_machine()\n\nSpinning... You got: 🍉 🍇 🍇 \nTry again! 🍀\n\n\n\n\n\n\n\n\nCaution\n\n\n\nThis book was written in Spring 2024 and should be considered a living document. The functionality and capability of AI is changing rapidly and the most recent advances may not reflect what is described in this book. Given the brave new world in which we now live, all constructive feedback and suggestions are welcome! If you have any feedback or suggestions, please provide it via Forms.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "webexercises.html",
    "href": "webexercises.html",
    "title": "Appendix A — Webexercises",
    "section": "",
    "text": "A.1 Example Questions",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Webexercises</span>"
    ]
  },
  {
    "objectID": "webexercises.html#example-questions",
    "href": "webexercises.html#example-questions",
    "title": "Appendix A — Webexercises",
    "section": "",
    "text": "A.1.1 Fill-In-The-Blanks (fitb())\nCreate fill-in-the-blank questions using fitb(), providing the answer as the first argument.\n\n2 + 2 is \n\n\nYou can also create these questions dynamically, using variables from your R session.\n\nThe square root of 25 is: \n\n\nThe blanks are case-sensitive; if you don’t care about case, use the argument ignore_case = TRUE.\n\nWhat is the letter after D? \n\n\nIf you want to ignore differences in whitespace use, use the argument ignore_ws = TRUE (which is the default) and include spaces in your answer anywhere they could be acceptable.\n\nHow do you load the tidyverse package? \n\n\nYou can set more than one possible correct answer by setting the answers as a vector.\n\nType a vowel: \n\n\nYou can use regular expressions to test answers against more complex rules.\n\nType any 3 letters: \n\n\nA.1.2 Multiple Choice (mcq())\n\n“Never gonna give you up, never gonna: \nlet you go\nturn you down\nrun away\nlet you down”\n“I \nbless the rains\nguess it rains\nsense the rain down in Africa” -Toto\n\nA.1.3 True or False (torf())\n\nTrue or False? You can permute values in a vector using sample(). \nTRUE\nFALSE\n\n\nA.1.4 Longer MCQs (longmcq())\nWhen your answers are very long, sometimes a drop-down select box gets formatted oddly. You can use longmcq() to deal with this. Since the answers are long, It’s probably best to set up the options inside an R chunk with echo=FALSE.\nWhat is a p-value?\n\nthe probability that the null hypothesis is truethe probability of the observed, or more extreme, data, under the assumption that the null-hypothesis is truethe probability of making an error in your conclusion\n\nWhat is true about a 95% confidence interval of the mean?\n\nthere is a 95% probability that the true mean lies within this rangeif you repeated the process many times, 95% of intervals calculated in this way contain the true mean95% of the data fall within this range",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Webexercises</span>"
    ]
  },
  {
    "objectID": "webexercises.html#checked-sections",
    "href": "webexercises.html#checked-sections",
    "title": "Appendix A — Webexercises",
    "section": "\nA.2 Checked sections",
    "text": "A.2 Checked sections\nCreate sections with the class webex-check to add a button that hides feedback until it is pressed. Add the class webex-box to draw a box around the section (or use your own styles).\n\nI am going to learn a lot: \nTRUE\nFALSE\nWhat is a p-value?\n\nthe probability that the null hypothesis is truethe probability of the observed, or more extreme, data, under the assumption that the null-hypothesis is truethe probability of making an error in your conclusion",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Webexercises</span>"
    ]
  },
  {
    "objectID": "webexercises.html#hidden-solutions-and-hints",
    "href": "webexercises.html#hidden-solutions-and-hints",
    "title": "Appendix A — Webexercises",
    "section": "\nA.3 Hidden solutions and hints",
    "text": "A.3 Hidden solutions and hints\nYou can fence off a solution area that will be hidden behind a button using hide() before the solution and unhide() after, each as inline R code. Pass the text you want to appear on the button to the hide() function.\nIf the solution is a code chunk, instead of using hide() and unhide(), simply set the webex.hide chunk option to TRUE, or set it to the string you wish to display on the button.\nRecreate the scatterplot below, using the built-in cars dataset.\n\n\n\n\n\n\n\n\n\n\nI need a hint\n\nSee the documentation for plot() (?plot)\n\n\n\n\n\nClick here to see the solution\n\nplot(cars$speed, cars$dist)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Webexercises</span>"
    ]
  },
  {
    "objectID": "01-intro.html#login",
    "href": "01-intro.html#login",
    "title": "\n1  Intro to using AI\n",
    "section": "\n1.3 Login",
    "text": "1.3 Login\n\n\n\n\n\n\nNoteActivity 1\n\n\n\nLogin to Copilot using your University of Glasgow account.\n\n\nAt the time of writing (September 2025), in order to access GPT-5, you need to toggle this on so make sure you also click the button in the top right that says “Try GPT-5”.\nRemember that “Copilot” is a family of tools. The link above takes you to Copilot Chat, which is the safest environment for coursework. Copilot in Word/Excel/PowerPoint may look slightly different but uses the same underlying model.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "01-intro.html#prompting",
    "href": "01-intro.html#prompting",
    "title": "\n1  Intro to using AI\n",
    "section": "\n1.4 Prompting",
    "text": "1.4 Prompting\nThe key difference between using an AI and a regular search engine is that you can shape the output of the AI by “prompt engineering”, which is the phrase used to describe the art of asking the question in a way that gives you the answer you want. It’s easier to show than tell.\n\n\n\n\n\n\nNoteActivity 2\n\n\n\nThink of a book, TV show, film, or video game that you know really well. I chose Final Fantasy VII (the original PlayStation version). Ask Copilot to give you three different summaries for different audiences.\n\nAsk it for a summary without any additional context e.g., “Give me a summary of Final Fantasy VII (original playstation version)”\nThen, ask it for a summary but give it a steer on the intended audience, e.g., “Give me a summary of Final Fantasy VII (original playstation version) for someone who knows nothing about videogames” or “Give me a summary of Final Fantasy VII (original playstation version) for an expert gamer who has played it many times”\nFinally, ask it for a summary, but give it a steer on how it should act, e.g., “Act as an expert videogame reviewer for the Guardian. Give me a summary of Final Fantasy VII (original playstation version) for an expert gamer who has played it many times” or “Act as someone who spends too much time on Reddit and thinks they know everything. Give me a summary of Final Fantasy VII (original playstation version) for an expert gamer who has played it many times”.\n\nReflect on the differences in the information and detail it gives you for each one and how you’re able to evaluate the accuracy of the summaries because of your existing expert knowledge.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "01-intro.html#copilot-features",
    "href": "01-intro.html#copilot-features",
    "title": "\n1  Intro to using AI\n",
    "section": "\n1.5 Copilot features",
    "text": "1.5 Copilot features\nWhilst many AIs use the same underlying model (e.g., GPT-5), the platforms can differ in their functionality.\n\nThe “Read Aloud” function will get Copilot to read it’s response to you.\nThe “Share prompt and copy response” button will copy your prompt and the response which you can then paste into e.g., a Word document. This is useful because if you’re ever asked to provide more information on how you have used AI at University, you can use this feature to assist with being transparent.\nSuggested follow-up prompts give you ideas for further prompting (although I have never found these useful).\nThe dictate function allows you to speak your prompt to the AI. On a laptop you may have to ensure your microphone settings allow access. This is often easier on a phone.\n“Edit in Pages” opens an editable page so you can add to and edit the response. You can also then ask an additional prompt and add new responses and share with others. We’re not really going to use this feature but if you want to know more, Microsoft have additional info and training.\nAdd a file to Copilot to use as part of your prompt. Because you’re signed in using your UofG account it will automatically connect to your OneDrive. Even though Copilot connects securely to OneDrive, you should check your module handbook and lecturer guidance before uploading slides, datasets, or assignments. Not all materials are permitted to be shared with AI.\n\n\n\n\n\nCopilot features\n\n\n\n\n\n\n\n\n\nNoteActivity 3\n\n\n\nTry out each of the six features described above and reflect on which ones you find useful and why.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#custom-instructions",
    "href": "02-personalise.html#custom-instructions",
    "title": "2  Personalised tutor",
    "section": "",
    "text": "Act as an expert tutor for the programming language R. I am a learner on the course “Applied Data Skills”. I have learned R in my first year and I have reasonably good general computer literacy. I will ask you questions about concepts and functions I do not understand based on my course materials. Always give me concrete examples when you provide an answer. Tailor your responses to my level of expertise. I am using R and RStudio on a Mac and the course will strongly use the tidyverse.\n\n\nAct as an expert tutor for the programming language R. I am a first year psychology student at the University of Glasgow and I am learning R for the first time. I have never learned a programming language before and I am not very confident with computers and I am anxious about learning programming. I have a Windows laptop. I will ask you questions about concepts and functions I do not understand based on my course materials. Always give me concrete examples when you provide an answer. Tailor your responses to my level of expertise. I am using R and RStudio and the course will strongly use the tidyverse.\n\n\n\nI am a Professor of Evidence-Informed Education in the School of Psychology and Neuroscience with expertise in cognitive psychology, individual differences, and teaching beginner data skills. You should be formal and give as much detail as possible in your responses. If I ask for code, always give me R code with a tidyverse solution where possible. Always use British spelling. Avoid being sycophantic, hyperbolic, using promotional language, negative parallelisms, or editorializing. Provide evidence for all claims. Preferably peer reviewed and within the last 5 years. Do not use the word delve or interplay. Do not use em dashes when writing and do not use bold to highlight text.\n\n\n\n\n\n\n\n\nNoteActivity 1\n\n\n\nWrite your custom instructions and enter them into Copilot. Exactly what information you provide is up to you but make sure that you explain your level of knowledge, skill, confidence and previous experience. If you’re using it for coding, you also want to give it some technical information about the software you’re using (e.g., R and RStudio) and your operating system (Windows).",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#socratic-tutor",
    "href": "02-personalise.html#socratic-tutor",
    "title": "2  Personalised tutor",
    "section": "2.4 Socratic tutor",
    "text": "2.4 Socratic tutor\nMost people use AI as a one-way explainer, but you can also ask it to act like a Socratic tutor. This means instead of giving you the answer straight away, the AI asks you guiding questions so that you recall or work out the idea for yourself. This is important because actively retrieving information strengthens your learning much more than passively re-reading.\nExample prompts you can try:\n\n“Act as a Socratic tutor. Do not tell me the answer yet. Ask me questions to guide me towards understanding correlation vs causation.”\n“Ask me a series of small questions until I can explain what a tibble is.” “Quiz me step by step on how the function filter() works in R. Only give me the next hint if I get stuck.”\n\nLearning often feels easier when you get a clear explanation, but you usually remember more when you struggle productively. The Socratic tutor style is designed to make you work a little, which improves long-term retention.\n\n\n\n\n\n\nNoteActivity 4\n\n\n\n\nFollow up on the responses it gave to your one of your three course questions with a similar prompt to the conversational examples give.\nThen for another one of the questions, follow-up with a request to check your understanding but acting as a Socratic tutor.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#be-critical",
    "href": "02-personalise.html#be-critical",
    "title": "2  Personalised tutor",
    "section": "2.5 Be critical",
    "text": "2.5 Be critical\nA personalised tutor is most powerful when it amplifies the cognitive processes that drive learning rather than replacing them. Three principles are central. Metacognition: monitor what you do and do not understand, then adjust your strategy and difficulty accordingly. Desirable difficulties: small, well-scaffolded challenges that require effort improve long-term retention when paired with feedback. Self-explanation: articulating why an answer is right, how a step works, or why an alternative is wrong deepens understanding and transfer. Use the tutor to create space for retrieval, explanation, and calibration, not to short-circuit them.\n\nIf you provide detailed instructions (“I am anxious, please make it simple”), the AI may default to oversimplification. This risks the expertise reversal effect — information is too shallow once you gain competence.\nSimilarly, if you do not revisit or revise instructions, you may “lock in” a static version of yourself (e.g., always a beginner), preventing growth and calibration.\nAsking the AI questions like “Why do I have to learn to code?” produces an explanation, but does not force you to generate an answer yourself. Research on retrieval practice shows that passive review is less effective for long-term retention.\nYou may accept AI answers at face value, especially if they “sound fluent.” The fluency illusion (e.g., when text feels easy to read) can lead to overconfidence.\nUnlike a lecturer who has genuine expertise, the AI cannot reliably detect specific misconceptions unless prompted very carefully. You might get partial reinforcement for incorrect ideas.\nIf the AI provides subtly wrong examples (e.g., incorrect R syntax), you may encode misconceptions. This is especially problematic because initial exposure can create a strong anchoring effect.\nLearning research shows benefits when you try, fail, and then see the solution. If AI always provides a clean solution first, you miss the benefits of “desirable difficulities”.\nSome students may outsource all explanations (“explain my lecture in simple words”) rather than engaging with primary materials. This could erode germane cognitive load — the mental effort that builds durable schemas.\n\n\n\n\n\n\n\nTipKey takeaways\n\n\n\n\nTell Copilot who you are, what course you’re on, and your level of confidence. This makes answers more tailored.\nFollow up, ask for comparisons, or request simpler/more technical versions. This is how you refine understanding.\nInstead of answers, ask Copilot to quiz you step by step. This supports retrieval and deeper learning.\nAI can be over-confident and sometimes wrong. Always compare to course materials and test your own understanding.\nReading an AI explanation is easier than doing the work yourself, but retrieval, practice, and self-explanation build stronger memory.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "01-intro.html#criticality-and-ai",
    "href": "01-intro.html#criticality-and-ai",
    "title": "\n1  Intro to using AI\n",
    "section": "\n1.2 Criticality and AI",
    "text": "1.2 Criticality and AI\nWhen using AI, it is not enough to know how to operate the tools, you also need to approach them critically. That means asking not just “what can this do for me?” but also “how trustworthy is this output, and what are the wider implications of relying on it?”\n\n1.2.1 Accuracy\nAI tools are trained to generate fluent and convincing text, but this does not mean it is correct. They frequently “hallucinate” — producing confident but false information such as incorrect references, fabricated statistics, or misattributed quotes. You should treat outputs as drafts or starting points, not final answers and verify with authoritative sources.\n\n1.2.2 Authority and Expertise\nAI cannot tell the difference between high-quality peer-reviewed research and a random blogpost unless explicitly instructed. It mirrors patterns in its training data rather than exercising judgement. Always consider who should be the authority on a question — a textbook, journal article, or your lecturer — and cross-check AI outputs accordingly.\n\n1.2.3 Transparency\nYou cannot see the training data or the “reasoning” steps of the model. That lack of transparency makes it hard to know why it gave a particular answer or whether it is missing key perspectives. Ask yourself what might have been left out or under-represented, and be cautious about treating AI answers as comprehensive.\n\n1.2.4 Epistemic Caution\nAIs generate text that looks authoritative, which can give a false sense of understanding. This risks shallow learning if students accept outputs uncritically rather than grappling with concepts themselves. Use AI as a “thinking partner,” but make sure you can explain ideas in your own words without relying on its phrasing.\n\n1.2.5 Equity and Access\nEven though UofG provides Copilot securely, in wider society access to premium AI tools is uneven. This creates new digital divides: between those who can afford subscription services and those who cannot, or between those trained to use AI critically and those left behind. Reflect on whose voices are privileged or excluded in AI-mediated work.\n\n1.2.6 Over-reliance and deskilling\nOutsourcing too much to AI can erode your own skills in writing, problem-solving, or coding. Just as calculators changed how we teach arithmetic, AI may change what we expect students to be able to do unaided. Use AI strategically, but keep developing your own capacity, especially in core academic skills such as argumentation, critical reading, and data analysis.\n\n1.2.7 Copilot\nMicrosoft Copilot is not one single tool but a family of services (e.g., in Word, Excel, Edge, Outlook). In this book, we focus on Copilot Chat accessed via Office365 using your University account, because this is the secure, enterprise version.\nMicrosoft Copilot can be accessed at by signing into Office365 with your University of Glasgow student account. Whilst ChatGPT is the most widely known and used, the advantage of using your Enterprise account is that the data is processed more securely and what you input won’t be used to train the model.\nThis is really, really important and if you’re found to have uploaded sensitive data to an unsecure AI you can be accused of academic and/or research misconduct. So if you’re using AI for any University work, use Copilot.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "01-intro.html#be-critical",
    "href": "01-intro.html#be-critical",
    "title": "\n1  Intro to using AI\n",
    "section": "\n1.6 Be critical",
    "text": "1.6 Be critical\nGood AI use should strengthen, not substitute, your learning processes and your motivation to learn and this is what we’re going to try and convince you of through this book. Two additional ideas matter here.\nFirst, self-determination theory suggests that high-quality learning is supported when activities nurture autonomy (choice and voice), competence (a sense of effectiveness), and relatedness (feeling connected to others or to authentic goals).\nSecond, self-efficacy grows primarily through mastery experiences: every time you attempt an answer first, then use AI to check, refine, and correct, you accumulate evidence that you can succeed again. Over-scaffolding (“just tell me the answer”) risks undermining both autonomy and self-efficacy.\n\n\n\n\n\n\nTipKey takeaways\n\n\n\nReflect on the differences between the summaries - the technicality of the language, the accuracy and nuance of the information, what it chose to focus on, and what it chose to omit. The reason I asked you to create a summary of something you already know well is that you’re aware of where the gaps are. Remember this when you’re asking an AI something you don’t know as well. Just because you can’t see the gaps, inaccuracies, and biases, doesn’t mean they’re not there.\n\nTell it how to act\nTell it who you are\nAlways check for gaps, errors, or bias\nFluency ≠ truth and persuasive text may still be wrong\nAuthority matters! Ask yourself “who should be the expert here?”\nOver-reliance risks deskilling. Keep practising your own academic skills",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "03-testing.html#question-types",
    "href": "03-testing.html#question-types",
    "title": "\n3  Practice testing\n",
    "section": "",
    "text": "3.1.1 Questions that test recognition\n\n3.1.1.1 Multiple choice questions\nMCQs tests recognition and your ability to spot the best answer among distractors. Each item has a stem (the question) followed by four labelled options (A–D). Only one is correct. MQCs are efficient for covering a wide range of content, easy to self-check, and useful for practising discrimination between similar concepts. However, they can also encourage recognition more than recall, and can sometimes be answered by guessing or test-wise strategies.\nExample:\n\nWhich of the following functions is used to create a scatterplot in R? A) geom_bar() B) geom_point() C) geom_boxplot() D) geom_histogram()\n\n\n3.1.1.2 True-or-false (TOF)\nTOF questions are a quick way to check factual accuracy and basic conceptual understanding and involve a single statement for you to judge as true or false. TOF questions are very quick to complete and good for simple checks of knowledge but have a high chance of guessing correctly (50%) and can oversimplify complex concepts and have limited diagnostic value.\nExample:\n\nTrue or false? The mean() function in R returns the median of a numeric vector.\n\n\n3.1.1.3 Fill-in-the-blanks (coding)\nThese questions strengthen fluency with R syntax by making you supply missing functions or arguments but are easier than writing out the full code from scratch These questions involve a line of R code with a missing element. These questions support recall of key syntax and reduce cognitive load compared to writing from scratch but they can be too easy and may not transfer well to real coding tasks.\nExample:\n\nggplot(mtcars, aes(x = wt, y = mpg)) + ____()\n\n\n3.1.1.4 Fill-in-the-blanks (theory)\nSimilarly, for theory, FITB helps memorise key terms, definitions, or concepts without giving the full answer. These questions will be a sentence with 1–2 blanks, sometimes with hints. FIT is good for reinforcing vocabulary and key concepts and are quick to create and practise. But, there is a risk of rote memorisation without deeper understanding and answers may sometimes be ambiguous.\nExample:\n\n“A variable that can take on any value between two points is called a ______.”\n\n\n3.1.2 Questions that test production\n\n3.1.2.1 Short-answer-questions\nSAQs require you to recall and explain in your own words, building deeper understanding. These are focused, open questions that should be answered in &lt;100 words. SAQs promote active recall and deeper processing and are flexible enough to test conceptual understanding. However, they are harder to self-mark and may be more time-consuming to generate and answer.\nExample:\n\nExplain the difference between a categorical and a continuous variable.\n\n\n3.1.2.2 Coding problems\nCoding problems let you apply your skills to solve a real task, similar to authentic assessments. They usually involve a short programming challenge using a real dataset. Coding problems closely mimic real-world problem solving, encourage transfer of knowledge, and consolidate multiple skills at once. The higher difficulty can be discouraging for beginners and they may be harder to self-assess without feedback.\nExample:\n\n“Using the penguins dataset, create a boxplot of body mass grouped by species.”\n\n\n3.1.2.3 Error mode\nError mode is debugging practice which builds resilience and problem-solving skills, and teaches you to spot common mistakes. It involves a runnable piece of R code that contains one plausible error. Error mode develops error-detection and debugging skills and mirrors real-world coding experience. However, it can be frustrating for novices and requires baseline knowledge to be effective.\nExample:\n\nggplot(mtcars, aes(x = wt, y = mpg))\ngeom_point()\n\n\n(Error: missing + before geom_point())",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#practical-tip-built-in-datasets",
    "href": "03-testing.html#practical-tip-built-in-datasets",
    "title": "\n3  Practice testing\n",
    "section": "\n3.2 Practical tip: Built-in datasets",
    "text": "3.2 Practical tip: Built-in datasets\nWhen practising coding questions with AI, you need a dataset you can actually run code on. A common problem with AI-generated exercises is that it invents datasets or column names that do not exist, which makes it impossible to test your solution. One way to avoid this is to rely on built-in datasets.\nBuilt-in datasets in R are sample datasets that come pre-loaded with the software or with specific packages. They cover a variety of domains (e.g., cars, gemstones, movies, penguins) and are designed to help you practise data manipulation, analysis, and visualisation without importing external files.\nYou can get a full list of available datasets by running data() in the console. Base R provides some, and additional packages (e.g., tidyverse, palmerpenguins) add more. Remember that a package must be loaded before its datasets are accessible.\n\n# see list of datasets\ndata()\n\n# load tidyverse to get access to extra sets\nlibrary(tidyverse)\n\n# see list of datasets expanded to include tidyverse ones\ndata()\n\n# load in dataset to environment so it can be used\ndata(\"starwars\")",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#question-prompt",
    "href": "03-testing.html#question-prompt",
    "title": "\n3  Practice testing\n",
    "section": "\n3.3 Question prompt",
    "text": "3.3 Question prompt\nWe will now design a prompt that will set-up Copilot to give you different types of questions.\n\n\n\n\n\n\nNoteActivity 1\n\n\n\nEdit the below template to suit your needs. For example, change the role, the sources you’re going to use, and if relevant, the datasets it should draw on in constraints. You can also change the other details although most of them should work for you without any changes.\n\n\n\n\n\n\n\n\nTipTemplate prompt to copy and paste into Copilot\n\n\n\nRole: You are a strict practice-testing tutor for second year undergraduate students learning R.\nSources: I will paste Intended Learning Outcomes (ILOs), function lists, and glossary terms from my course Applied Data Skills.\nProtocol:\n\nAsk one question at a time of the requested type.\nDo not reveal the answer until I reply.\nDo not give the answer away in the suggested follow-up prompts. For example, for MCQs, give suggested prompts for each answer option, not just the correct answer.\nAfter I answer, mark it, then give a short explanation (2–4 sentences).\n\nConstraints:\n\nAll questions must align to ILOs and be challenging but fair.\nFor coding questions, avoid imaginary datasets or columns. Instead, use only use the following datasets: starwars, diamonds, penguins.\n\nControls I will use:\n\ntype: … (see list below)\ncalibrate: harder | easier\n\nQuestion Types (with rules):\n\nMCQ (Multiple choice) – 4 options (A–D), 1 correct. Plausible distractors. After marking, explain each option briefly.\nTOF (True/False) – One statement; avoid trivially true/false. After marking, if false, rewrite as a correct statement.\nSAQ (Short answer) – Ask about one concept. I should be able to answer in &lt;100 words. After marking, provide a 2–3 point ideal outline.\nFITB_code (Fill-in-the-blank: coding) – One line of R with a missing function/argument. Must run on an approved dataset. State expected output shape (e.g., “tibble: 3 × 2”).\nFITB_theory (Fill-in-the-blank: theory) – A statement with up to 2 blanks. Give part-of-speech hints (e.g., [noun]).\nCP (Coding problem) – Minimal complete example using an approved dataset. Specify columns that exist. Do not invent data.\nEM (Error mode) – Provide a minimal reproducible example that fails using a specified dataset. The code should include the call to load the dataset and any required packages. Include exactly one plausible beginner-level error but give no hint as to what the error is. State intended outcome. Hold back the fix until after I attempt a solution. Then reveal the correction and what it teaches.\n\nFirst action: Confirm readiness and ask me to provide the sources.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#sources",
    "href": "03-testing.html#sources",
    "title": "\n3  Practice testing\n",
    "section": "\n3.4 Sources",
    "text": "3.4 Sources\nOnce you have set up this prompt, you can give it the sources to work from—for example, copy and paste the ILOs, a list of functions, and/or key terms you want it to quiz you on. Do not worry about formatting: just paste the text in as it is.\n\n\n\n\n\n\nNoteActivity 2\n\n\n\nAdd in your sources for the content you want to study.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nThe suggested follow-up prompts in Copilot sometimes indicate what the correct answer is, particularly for closed-questions. I’ve not found a reliable way to stop it from doing this - let me know if you crack it.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#be-critical",
    "href": "03-testing.html#be-critical",
    "title": "\n3  Practice testing\n",
    "section": "\n3.6 Be critical",
    "text": "3.6 Be critical\nEffective practice testing is not just about answering more questions; it is about engaging the cognitive processes that drive learning. Three ideas are central here. First, metacognition: accurate monitoring and control of learning (calibration) helps you choose the right strategies and difficulty. Second, desirable difficulties: tasks that are effortful—retrieval, generation, discrimination—strengthen long-term retention when paired with feedback. Third, self-explanation: articulating why an answer is right or wrong deepens understanding and transfer. Use AI to amplify these processes, not to bypass them. Treat every AI-generated item as an opportunity to retrieve, explain, and calibrate.\nThe questions AI generates can be useful, but they can also introduce illusions of fluency and miscalibration.\n\n3.6.1 Multiple-choice / TOF / SAQ questions\n\nSometimes the answers are simply wrong. If you challenge the AI, it will usually correct itself—but it will also agree with you if you claim an answer is wrong when it is not. The risk is that you accidentally encode misinformation. Remember: AI does not “know” anything; it is a sophisticated pattern-matcher, not a reliable authority.\nIt may generate questions about functions or concepts not covered in your course, which can cause confusion and unnecessary anxiety.\nOccasionally it poses a question with multiple correct answers without making this clear, which is frustrating.\nIt may overemphasise particular topics or functions unless you explicitly direct it to vary the focus.\n\n3.6.2 Coding problems\n\nThe examples are not always reproducible. For instance, it might assume the existence of a dataset with variables called “number” and “price” but provide no such dataset, making it impossible to run the code. You can still attempt the problem, but this adds extra difficulty—especially for beginners.\nIt sometimes uses functions or approaches you have not been taught, such as defaulting to Base R instead of tidyverse.\n\n3.6.3 Error mode\n\nIn the first iteration of this book, AI could not create error mode problems - the code either ran fine or the errors were so stupid and obvious it was of no educational benefit. Models have improved, and they can now generate plausible errors, which is an interesting sign of progress.\nEven so, AI often hints heavily at the error or simply tells you the answer, which reduces the learning benefit.\nWhilst it can now generate plausible errors, it doesn’t have the benefit of years of teaching experience. When we design error mode questions, they’re based on our knowledge of what students frequently get wrong so AI error mode isn’t always as targeted and therefore as useful as questions written by an expert educator. Maybe our jobs are safe for a little while longer.\n\n\n\n\n\n\n\nTipKey Takeaways\n\n\n\n\nRegular retrieval strengthens memory more than re-reading or highlighting.\nChoose the right format for questions: MCQs/TOF are good for recognition and breadth but weaker for recall. SAQs/FITB ae better for active recall and vocabulary but risk of rote learning. Coding problems/Error mode are closest to authentic tasks, but require more effort and background knowledge.\nPaste ILOs, function lists, or glossaries into Copilot to ensure it’s specific to what you are studying. Avoid imaginary datasets—stick to built-in ones like mtcars, penguins, or iris.\nAI outputs can be wrong, misleading, or oddly focused. Correcting them is part of the learning process and strengthens metacognition.\nAI is a tool, not a teacher. It lacks expert judgement about what learners typically get wrong. Use it to supplement, not replace, structured practice and seeking help from your lectuers and tutors.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#test-yourself",
    "href": "03-testing.html#test-yourself",
    "title": "\n3  Practice testing\n",
    "section": "\n3.5 Test yourself",
    "text": "3.5 Test yourself\nYou can now ask it to generate questions for you by typing mcq or coding problem. If the questions seem too easy or hard, you can adjust them by using calibrate: easier or calibrate: harder\n\n\n\n\n\n\nNoteActivity 3\n\n\n\nAsk if for one question of each type and work through them. Reflect on whether they are challenging enough, if they align with your course content, and how they might differ from practice questions you have been given by a human.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "04-errors.html#activity-5-document-errors",
    "href": "04-errors.html#activity-5-document-errors",
    "title": "\n4  Error checking and debugging\n",
    "section": "\n4.4 Activity 5: Document errors",
    "text": "4.4 Activity 5: Document errors\nIf you’re working in Rmd or Quarto, sometimes the errors will stem from your code chunk settings or YAML in the document.\nIn your Rmd or Qmd file, create a new code chunk and copy and paste the following:\n\npenguins %&gt;%\n  count()\n\nBut then delete one of the final back ticks (`) from the code chunk.\nThe code is fine, it provides a simple count of the number of observations in the dataset. But if you try and knit the file in Rmd you’ll get a very long error message and if you render the file in Quarto, it will work, but it won’t actually execute the code, it will just render it as text.\nIn these cases you have two options.\n\nCopy and paste the entire document into Copilot, not just the code but include the code chunks etc. This means it can see the formatting as well as the code.\nTake a screenshot. This can also sometimes help diagnose working directory issues if you include the files pane.\n\nIf you’re not at all sure where the issue is stemming from, you might need a combination of both. But whatever you do, make sure that you verify the explanation of the error, don’t trust it blindly.\n\n\n\n\nMissing the mark\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nI know I might be starting to sound like a broken record but please remember that artificial intelligence is not actually intelligent. It’s not thinking, it’s not making conscious decisions, it has no expert subject matter knowledge. No matter how helpful it is, you must always check the output of the code it gives you.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "04-errors.html#be-critical",
    "href": "04-errors.html#be-critical",
    "title": "\n4  Error checking and debugging\n",
    "section": "\n4.5 Be critical",
    "text": "4.5 Be critical\nFrom a cognitive science perspective, being critical when debugging with AI matters because learning is strongest when you engage in active processing rather than relying on external answers. Research on desirable difficulties shows that struggling with a problem, even briefly, improves long-term retention and transfer. Similarly, studies of self-explanation demonstrate that learners build deeper understanding when they articulate why an error occurred and how to fix it. If you immediately outsource error checking to AI, you bypass the very processes that consolidate your knowledge of syntax, functions, and debugging strategies.\nAnother benefit of practising debugging yourself—before turning to AI—is the development of self-efficacy and autonomy. In Bandura’s terms, mastery experiences are the strongest source of self-efficacy: each time you locate and fix an error unaided, you build the expectation that you can do so again.\nAutonomy is likewise enhanced when you make choices about how to proceed rather than defaulting to external solutions. Framed through self-determination theory, brief, well-timed AI support can still help, provided it is autonomy-supportive (you decide when to ask), competence-supportive (it explains rather than replaces your reasoning), and scaffolded (assistance fades as you improve).\nIn practice: attempt a fix first, articulate a hypothesis about the bug, then use AI to test or refine that hypothesis. This preserves a sense of authorship over your code, strengthens future problem-solving, and reduces learned dependence on external help.\n\n4.5.1 Common errors\nCoding errors tend to repeat and there’s actually a fairly small set of errors you will make constantly. But you won’t learn these patterns if you always ask the AI.\n\nMissing or extra ()\nMissing or extra commas\nMissing or extra quotation marks\nTypos in object or variable names - remember R is case sensitive\nMissing + for ggplot()\nMissing |&gt; or %&gt;% for piped lines of code\nUsing = instead of ==\n\nWriting code but not running it so that e.g., a package isn’t loaded or an object isn’t created that you later need.\nTrying to perform a numerical operation on a character/factor variable (or vice versa).\n\nTo help boost your confidence in error checking and debugging, you can create Error Mode questions like we showed you in Chapter 3. You could sk it to give you examples based on the common list of errors noted above and work your way through them until you’re more comfortable spotting them in your own code.\n\n\n\n\n\n\nTipKey Takeaways\n\n\n\n\nTry first, then ask AI. Read the error message, inspect recent edits, and attempt a fix before consulting AI. This strengthens understanding and builds self-efficacy.\nProvide full context. When you do use AI, include the code and the exact error message. Add brief intent (“what I meant to do”) and, if safe, a minimal reproducible example.\nKnow your data. Many “mystery” errors are case sensitivity, misspellings, or filtering mistakes. Use summary(), str(), or ls() to verify assumptions.\nProtect sensitive data. Prefer ls() first; only share summary()/str() outputs if your data management plan permits. Copilot Enterprise reduces but does not remove risk.\nExpect and learn common patterns in errors.\nState the goal. Tell AI what outcome you intended (e.g., “mean by species and sex”), not just the code, to help it detect functional (not just syntactic) errors.\nUse screenshots or full documents for format bugs. For Rmd/Qmd issues, share the whole document or a screenshot showing YAML, chunk fences, and working directory.\nTreat AI as scaffolding. Ask it to explain rather than replace reasoning, and fade assistance over time to preserve autonomy and develop durable debugging habits.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "04-errors.html#contextual-errors",
    "href": "04-errors.html#contextual-errors",
    "title": "\n4  Error checking and debugging\n",
    "section": "\n4.2 Contextual errors",
    "text": "4.2 Contextual errors\nA common issue is when the error stems from code earlier in your script, even though it shows up later.\nFor example, in this code, what we intended to do was to create a dataset that just has penguins from Biscoe Island and then calculate their mean body mass. This code will run, but it produces NaN as the value.\n\nbiscoe_penguins &lt;- penguins %&gt;%\n  filter(island == \"biscoe\")\n\nbiscoe_penguins %&gt;%\n  summarise(mean_mass = mean(body_mass_g))\n\n\n\n\nmean_mass\n\n\nNaN\n\n\n\n\n\nIf you just give an AI the code and the table and ask it to explain what’s happening, it will do its best but without knowing the dataset or what code has preceded it, it won’t give you the exact answer, although in this case it hints at it.\n\n\n\n\nCopilot giving its best guess\n\n\n\nThere’s a couple of things you can do at this point:\n\nGive the AI all the code you’ve used so far\nGive the AI more information about the dataset.\n\nYou can manually type out a description but there’s some functions you can use that can automate this.\nsummary() is useful because it provides a list of all variables with some descriptive statistics so that the AI has a sense of the type and range of data:\n\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2                                 \n\n\nstr() is also useful because it lists the variables, their data type, and the initial values for each variable.\n\nstr(penguins)\n\ntibble [344 × 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n\nFinally, ls() provides a list of all the variables in a given object. It doesn’t provide any info on the variable type or sample, but this might be all the info you really need to give the AI.\n\nls(penguins)\n\n[1] \"bill_depth_mm\"     \"bill_length_mm\"    \"body_mass_g\"      \n[4] \"flipper_length_mm\" \"island\"            \"sex\"              \n[7] \"species\"           \"year\"             \n\n\n\n\n\n\n\n\nCaution\n\n\n\nBe careful with sensitive data. str() and summary() reveal actual data values, so only use them if your data management plan permits it. Using Copilot Enterprise reduces (but does not remove) risk, since data is not used for model training. Start with ls(), which only lists variable names, and scale up if safe.\n\n\n\n\n\n\n\n\nNoteActivity 3\n\n\n\nRun summary(biscoe_penguins) and give the AI the output so that it better understands the structure and contents of the datasets.\nThen give it the code you used to filter the dataset.\n::\nIf you haven’t spotted it by now, the error is that in the filter biscoe should be Biscoe with a capital B.\nThere is no shortcut for knowing your data.\n\n\n\n\nCopilot getting very close\n\n\n\n\n4.3 Incorrect (but functional) code\nSometimes (often) when we write code, the issue isn’t that our code doesn’t work, but that it doesn’t do what we intended to do and we can’t figure out why.\nFor example, let’s say that we want to calculate the average body_mass_g for each species by sex. We’re feeling a bit lazy and we copy and paste in the following from a previous script we have:\n\npenguins %&gt;%\n  group_by(sex, species) %&gt;%\n  summarise(mean_body_mass = sd(body_mass_g, na.rm = TRUE))\n\n\n\n\nsex\nspecies\nmean_body_mass\n\n\n\nfemale\nAdelie\n269.3801\n\n\nfemale\nChinstrap\n285.3339\n\n\nfemale\nGentoo\n281.5783\n\n\nmale\nAdelie\n346.8116\n\n\nmale\nChinstrap\n362.1376\n\n\nmale\nGentoo\n313.1586\n\n\nNA\nAdelie\n477.1661\n\n\nNA\nGentoo\n338.1937\n\n\n\n\n\n\nWe know something isn’t right here. Because we’re responsible researchers, we’ve taken time to understand our dataset and what plausible values should be and we know there’s no way that the average body mass of a penguin is 269 grams (unless the penguin is made of chocolate). But the code is running fine, we know it’s worked before, and we can’t see what we’ve done wrong.\nYou can ask the AI to help you but you can’t just give it the code and output, you also need to tell it what you intended to do. The more complex your code, the more information you will need to give it in order for it to help you find the error.\n\n\n\n\nFixing a functional error\n\n\n\nThis is a good example of why there is no AI tool that allows you to skip understanding the data you’re working with and knowing what it is you’re trying to do.\n\n4.4 Document errors\nIf you’re working in Rmd or Quarto, sometimes the errors will stem from your code chunk settings or YAML in the document.\n\n\n\n\n\n\nNoteActivity 4\n\n\n\n\nIn your Rmd or Qmd file, create a new code chunk and copy and paste the following:\n\n\npenguins %&gt;%\n  count()\n\n\nDelete one of the final back ticks (`) from the code chunk.\nTry and run the code and knit/render the file.\n\n\n\nThe code is fine, it provides a simple count of the number of observations in the dataset. But if you try and knit the file in Rmd you’ll get a very long error message and if you render the file in Quarto, it will work, but it won’t actually execute the code, it will just render it as text.\nIn these cases you have two options.\n\nCopy and paste the entire document into Copilot, not just the code but include the code chunks etc. This means it can see the formatting as well as the code.\nTake a screenshot. This can also sometimes help diagnose working directory issues if you include the files pane.\n\nIf you’re not at all sure where the issue is stemming from, you might need a combination of both. But whatever you do, make sure that you verify the explanation of the error, don’t trust it blindly.\n\n\n\n\n\n\nNoteActivity 5\n\n\n\nTry pasting the entire document into Copilot and/or providing a screenshot until it can diagnose the missing backtick.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nI know I might be starting to sound like a broken record but please remember that artificial intelligence is not actually intelligent. It’s not thinking, it’s not making conscious decisions, it has no expert subject matter knowledge. No matter how helpful it is, you must always check the output of the code it gives you.\n\n\n\n4.5 Be critical\nFrom a cognitive science perspective, being critical when debugging with AI matters because learning is strongest when you engage in active processing rather than relying on external answers. Research on desirable difficulties shows that struggling with a problem, even briefly, improves long-term retention and transfer. Similarly, studies of self-explanation demonstrate that learners build deeper understanding when they articulate why an error occurred and how to fix it. If you immediately outsource error checking to AI, you bypass the very processes that consolidate your knowledge of syntax, functions, and debugging strategies.\nAnother benefit of practising debugging yourself—before turning to AI—is the development of self-efficacy and autonomy. In Bandura’s terms, mastery experiences are the strongest source of self-efficacy: each time you locate and fix an error unaided, you build the expectation that you can do so again.\nAutonomy is likewise enhanced when you make choices about how to proceed rather than defaulting to external solutions. Framed through self-determination theory, brief, well-timed AI support can still help, provided it is autonomy-supportive (you decide when to ask), competence-supportive (it explains rather than replaces your reasoning), and scaffolded (assistance fades as you improve).\nIn practice: attempt a fix first, articulate a hypothesis about the bug, then use AI to test or refine that hypothesis. This preserves a sense of authorship over your code, strengthens future problem-solving, and reduces learned dependence on external help.\n\n4.5.1 Common errors\nCoding errors tend to repeat and there’s actually a fairly small set of errors you will make constantly. But you won’t learn these patterns if you always ask the AI.\n\nMissing or extra ()\nMissing or extra commas\nMissing or extra quotation marks\nTypos in object or variable names - remember R is case sensitive\nMissing + for ggplot()\nMissing |&gt; or %&gt;% for piped lines of code\nUsing = instead of ==\n\nWriting code but not running it so that e.g., a package isn’t loaded or an object isn’t created that you later need.\nTrying to perform a numerical operation on a character/factor variable (or vice versa).\n\nTo help boost your confidence in error checking and debugging, you can create Error Mode questions like we showed you in Chapter 3. You could sk it to give you examples based on the common list of errors noted above and work your way through them until you’re more comfortable spotting them in your own code.\n\n\n\n\n\n\nTipKey Takeaways\n\n\n\n\nTry first, then ask AI. Read the error message, inspect recent edits, and attempt a fix before consulting AI. This strengthens understanding and builds self-efficacy.\nProvide full context. When you do use AI, include the code and the exact error message. Add brief intent (“what I meant to do”) and, if safe, a minimal reproducible example.\nKnow your data. Many “mystery” errors are case sensitivity, misspellings, or filtering mistakes. Use summary(), str(), or ls() to verify assumptions.\nProtect sensitive data. Prefer ls() first; only share summary()/str() outputs if your data management plan permits. Copilot Enterprise reduces but does not remove risk.\nExpect and learn common patterns in errors.\nState the goal. Tell AI what outcome you intended (e.g., “mean by species and sex”), not just the code, to help it detect functional (not just syntactic) errors.\nUse screenshots or full documents for format bugs. For Rmd/Qmd issues, share the whole document or a screenshot showing YAML, chunk fences, and working directory.\nTreat AI as scaffolding. Ask it to explain rather than replace reasoning, and fade assistance over time to preserve autonomy and develop durable debugging habits.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "04-errors.html#incorrect-but-functional-code",
    "href": "04-errors.html#incorrect-but-functional-code",
    "title": "\n4  Error checking and debugging\n",
    "section": "\n4.3 Incorrect (but functional) code",
    "text": "4.3 Incorrect (but functional) code\nSometimes (often) when we write code, the issue isn’t that our code doesn’t work, but that it doesn’t do what we intended to do and we can’t figure out why.\nFor example, let’s say that we want to calculate the average body_mass_g for each species by sex. We’re feeling a bit lazy and we copy and paste in the following from a previous script we have:\n\npenguins %&gt;%\n  group_by(sex, species) %&gt;%\n  summarise(mean_body_mass = sd(body_mass_g, na.rm = TRUE))\n\n\n\n\nsex\nspecies\nmean_body_mass\n\n\n\nfemale\nAdelie\n269.3801\n\n\nfemale\nChinstrap\n285.3339\n\n\nfemale\nGentoo\n281.5783\n\n\nmale\nAdelie\n346.8116\n\n\nmale\nChinstrap\n362.1376\n\n\nmale\nGentoo\n313.1586\n\n\nNA\nAdelie\n477.1661\n\n\nNA\nGentoo\n338.1937\n\n\n\n\n\n\nWe know something isn’t right here. Because we’re responsible researchers, we’ve taken time to understand our dataset and what plausible values should be and we know there’s no way that the average body mass of a penguin is 269 grams (unless the penguin is made of chocolate). But the code is running fine, we know it’s worked before, and we can’t see what we’ve done wrong.\nYou can ask the AI to help you but you can’t just give it the code and output, you also need to tell it what you intended to do. The more complex your code, the more information you will need to give it in order for it to help you find the error.\n\n\n\n\nFixing a functional error\n\n\n\nThis is a good example of why there is no AI tool that allows you to skip understanding the data you’re working with and knowing what it is you’re trying to do.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "04-errors.html#document-errors",
    "href": "04-errors.html#document-errors",
    "title": "\n4  Error checking and debugging\n",
    "section": "\n4.4 Document errors",
    "text": "4.4 Document errors\nIf you’re working in Rmd or Quarto, sometimes the errors will stem from your code chunk settings or YAML in the document.\n\n\n\n\n\n\nNoteActivity 4\n\n\n\n\nIn your Rmd or Qmd file, create a new code chunk and copy and paste the following:\n\n\npenguins %&gt;%\n  count()\n\n\nDelete one of the final back ticks (`) from the code chunk.\nTry and run the code and knit/render the file.\n\n\n\nThe code is fine, it provides a simple count of the number of observations in the dataset. But if you try and knit the file in Rmd you’ll get a very long error message and if you render the file in Quarto, it will work, but it won’t actually execute the code, it will just render it as text.\nIn these cases you have two options.\n\nCopy and paste the entire document into Copilot, not just the code but include the code chunks etc. This means it can see the formatting as well as the code.\nTake a screenshot. This can also sometimes help diagnose working directory issues if you include the files pane.\n\nIf you’re not at all sure where the issue is stemming from, you might need a combination of both. But whatever you do, make sure that you verify the explanation of the error, don’t trust it blindly.\n\n\n\n\n\n\nNoteActivity 5\n\n\n\nTry pasting the entire document into Copilot and/or providing a screenshot until it can diagnose the missing backtick.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nI know I might be starting to sound like a broken record but please remember that artificial intelligence is not actually intelligent. It’s not thinking, it’s not making conscious decisions, it has no expert subject matter knowledge. No matter how helpful it is, you must always check the output of the code it gives you.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  }
]