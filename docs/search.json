[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AI TutoR",
    "section": "",
    "text": "Overview\nThis book aims to teach students how to use AI to support their learning journey. The philosophy of this book is firmly rooted in the cognitive science of learning and as such, retrieval practice, distributed practice, and elaboration will all play a key role.\nIt is perhaps easier to start by explaining what this book is not:\n\nThis book is not a stand-alone resource. It is intended to be used alongside other course materials. To make the most out of this book, you will need things like Intended Learning Outcomes or key terms.\nThis book will not encourage learners to take short-cuts. That students should be able to understanding the principles of what they are learning and to critically evaluate writing on the topic, regardless of who or what wrote it, is non-negotiable.\nFor the coding aspects of this book, we will not not teach you how to use platforms like Github Copilot and it is not aimed at proficient or advanced programmers.\n\nInstead, this book will aim to help learners use AI platforms as a personalised tutor. By the end of this book, learners should be able to:\n\nUse AI to explain concepts and functions in a level of detail and technicality appropriate to the knowledge and skill of the learner\nUse AI to generate practice questions to test understanding\nUse AI to create study plans\nUse AI to debug errors in code\nUse AI to review, comments, and refactor code\nUse AI to responsibly assist with writing code\nCritically evaluate and appraise the output of AI\n\n\n\n\n\n\n\nWarning\n\n\n\nUsing AI to write code is the final part of the coding section, and that is an intentional choice. Using AI can superpower your coding but only once you have a solid foundation of knowledge. You need to be able to evaluate what it produces and you need to know what to ask it with enough specificity. Using AI to write code you don’t understand is as dangerous as it is irresponsible.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nThis book should be considered a living document and is likely to change over time. Given the brave new world in which we now live, all constructive feedback and suggestions are welcome! If you have any feedback or suggestions, please provide it via Forms.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "01-intro.html",
    "href": "01-intro.html",
    "title": "\n1  Intro to using AI\n",
    "section": "",
    "text": "1.1 A brief introduction",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "01-intro.html#a-brief-introduction",
    "href": "01-intro.html#a-brief-introduction",
    "title": "\n1  Intro to using AI\n",
    "section": "",
    "text": "1.1.1 AI model vs AI platforms\nThere are more qualified people who can explain AI better than I can but a brief but important distinction is between the AI model and the AI platform. The underlying AI model is a Large Language Model (LLM) that essentially does extremely sophisticated predictive text - it’s not thinking, it’s not conscious, it just is very good at deciding what word is likely to come after another word in a way that is human-like1.\nDifferent software companies have created different AI models. Google’s latest model is named Gemini. OpenAI has a series of models it refers to as Generative Pre-trained Transformers (GPT). The explosion in AI in terms of public awareness came about when OpenAI released GPT version 3. They then released version 3.5 and the most recent version is 4.0. The capability of each successive AI is claimed to increase significantly, both in terms of its ability (e.g., to pass standardised tests) and in the human-ness of its responses.\nIn some cases, the name of the model and the name of the platform you use are the same. So Google’s model is named Gemini and that’s the name of the platform. On the other hand, ChatGPT is the name of the platform, but the underlying model it uses is either GPT3.5 (free version) or GPT4.0 (premium subscription). Additionally, other companies and apps can licence use of the models so Microsoft’s Copilot uses GPT4.0\nIt isn’t necessary that you understand all of this in detail. The key thing is that the underlying model is the same for some platforms (so you should expect similar capabilities) and that this model can and will update.\n\n1.1.2 Ethics and AI\nIt’s beyond the scope of this book (and my expertise) to go into much detail about the ethics of AI but I want to acknowledge that in several ways, they’re hugely problematic.\nFirst, and most importantly, AIs are trained on huge corpora of human language. Humans are full of bias and prejudice and consequently, so are our offspring AIs who have been repeatedly found to encode sexist, racist, and abelist views in their outputs.\n\nTeaching AI Ethics: Bias and Discrimination\n\nSecond, many of the developers that have produced AI models have done so behind closed doors and are very secretive about exactly what data the models have been trained on. One of the reasons for this is because it is very clearly apparent that many AI models have been given access to copyrighted sources (e.g., books and film scripts) and there are an increasing number of lawsuits being filed although it remains unclear what the future holds given how far and how fast the horse has already bolted.\n\nGenerative AI Has an Intellectual Property Problem\n\nThird, whilst the use of AI has been touted as a solution to help us manage climate change, it’s also a direct contributor to the problem because of the energy demands.\n\nAs Use of A.I. Soars, So Does the Energy and Water It Requires",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "01-intro.html#ai-platforms",
    "href": "01-intro.html#ai-platforms",
    "title": "\n1  Intro to using AI\n",
    "section": "\n1.2 AI platforms",
    "text": "1.2 AI platforms\n\n1.2.1 ChatGPT\nYou can sign-up for ChatGPT at https://chat.openai.com/. The free version of ChatGPT uses GPT3.5 whilst you have to pay for a subscription to get access to GPT4.0.\nThe free version is very fast and for beginner level courses does perform quite well. I’ve also found that ChatGPT is good at understanding the intent of what I want. ChatGPT also makes it easy to save your chat history so that you can continue working in previous chats at a later date. A useful feature is the “regenerate” function whereby if you’re not completely happy with the response, you can quickly ask it to generate another attempt and compare them. ChatGPT has a mobile app and allows you to share links to saved chats.\nThe disadvantages of ChatGPT are that it has limited internet connectivity and the information in its database will be restricted. At the time of writing this book, ChatGPT’s training data extends until January 2022, so it can’t tell you about anything that happened after that point (regardless of whether that’s world event or a new R function). Whilst it does depend on which version you’re using, it rarely gives you links to sources for where it has found the information.\n\n\n\n\nusing ChatGPT\n\n\n\n\n1.2.2 Copilot\nMicrosoft Copilot can be accessed at https://copilot.microsoft.com/ and you can sign-in with your Microsoft Account. If you are a University of Glasgow student (and also at many other universities), you can access Copilot through your university account and your Office365 subscription. If you do so, you’ll be able to access the Enterprise version of Copilot. The advantage of using your Enterprise account is that the data is processed more securely and what you input won’t be used to train the model. The price you pay for this security - and it’s such a big price that I don’t use it much for this reason - is that it doesn’t save your chat history so you start each time afresh. If you use a personal account, it will save your chat history, but also use your data to train the model.\nHowever, where Copilot shines is that it has access to the internet and will give you links to where it got its information so it’s easier to verify the output than ChatGPT. Additionally, they don’t make this clear but if you select the conversation style to be “Creative”, it will use GPT4.0 (which you have to pay for if you use ChatGPT).\nI have found that Copilot more frequently doesn’t understand the intent of what I am asking and with the same prompt as ChatGPT will give me a useless answer, but let’s see how I feel about that by the end of writing this book.\nMy general approach is that if I want to be able to return to my conversation, I use ChatGPT or Gemini. If I want links to sources, I use Copilot.\n\n\n\n\nusing ChatGPT\n\n\n\n\n1.2.3 Gemini\nYou can access Gemini at https://gemini.google.com/ and sign-in with a regular Google account. Gemini was previously known as Bard.\nGemini also makes it easy to save and share your chat history and you can export it easily to Google Docs. Gemini’s strength lies in its connectivity to the internet. Like Copilot, it will provide links as part of its response (although sometimes they don’t always work) and you can also ask it to try and verify its response through using a regular Google search.\nAdditionally, Gemini has a “modify response” option where you can quickly ask it to make the response shorter, longer, simpler, more causal, or more professional.\nAnother advantage is that it uses a different model to ChatGPT so if you’re going to combine different AIs, using Gemini may give a different response.\nThere is a Gemini mobile app, but it isn’t currently available in the UK.\nBefore writing this book, I had used Gemini less than the others. Let’s see where I end up at the end.\n\n\n\n\nusing ChatGPT",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "01-intro.html#activity-1",
    "href": "01-intro.html#activity-1",
    "title": "\n1  Intro to using AI\n",
    "section": "\n1.3 Activity 1",
    "text": "1.3 Activity 1\n\nChoose one of the AIs and create an account/login. You can also do this activity with multiple AIs to see the difference in output if you’re interested.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "01-intro.html#activity-2",
    "href": "01-intro.html#activity-2",
    "title": "\n1  Intro to using AI\n",
    "section": "\n1.4 Activity 2",
    "text": "1.4 Activity 2\nThe key difference between using an AI and a regular search engine is that you can shape the output of the AI by “prompt engineering”, which is the phrase used to describe the art of asking the question in a way that gives you the answer you want. It’s easier to show than tell.\nThink of a book, TV show, film, or video game that you know really well. I chose Final Fantasy VII (the original PlayStation version). Ask the AI to give you three different summaries and try out the functionality of each platform. For example, for ChatGPT ask it to regenerate the response, for Gemini, use modify response or Double-check response with Google.\n\nFirst, ask it for a summary without any additional context e.g., “Give me a summary of Final Fantasy VII (original playstation version)”\nThen, ask it for a summary but give it a steer on the intended audience, e.g., “Give me a summary of Final Fantasy VII (original playstation version) for someone who knows nothing about videogames” or “Give me a summary of Final Fantasy VII (original playstation version) for an expert gamer who has played it many times”\nFinally, ask it for a summary, but give it a steer on how it should act, e.g., “Act as an expert videogame reviewer for the Guardian. Give me a summary of Final Fantasy VII (original playstation version) for an expert gamer who has played it many times” or “Act as someone who spends too much time on Reddit and thinks they know everything. Give me a summary of Final Fantasy VII (original playstation version) for an expert gamer who has played it many times”.\n\nThe key takeaways to remember for your coding journey are:\n\nTell it how to act\nTell it who you are\n\nReflect on the differences between the summaries - the technicality of the language, the accuracy and nuance of the information, what it chose to focus on, and what it chose to omit. The reason I asked you to create a summary of something you already know well is that you’re aware of where the gaps are. Remember this when you’re asking an AI something you don’t know as well. Just because you can’t see the gaps, inaccuracies, and biases, doesn’t mean they’re not there.\n\n\n\n\n\n\nCaution\n\n\n\nThis book should be considered a living document and is likely to change over time. Given the brave new world in which we now live, all constructive feedback and suggestions are welcome! If you have any feedback or suggestions, please provide it via Forms.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "01-intro.html#footnotes",
    "href": "01-intro.html#footnotes",
    "title": "\n1  Intro to using AI\n",
    "section": "",
    "text": "I ran this explanation through Gemini and it was not happy with me and wants you to know that it can also perform tasks like translation, question answering, and even generate creative text formats like poems or code. Calm down Felicia.↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "02-personalise.html",
    "href": "02-personalise.html",
    "title": "2  Personalised tutor",
    "section": "",
    "text": "2.1 Set-up\nThe key to maximising the usefulness of AI is to use prompt engineering to tailor the output your to your exact needs. Before you ask any questions, you need to tell the AI who you are and exactly how it should act.\nHere’s some examples:",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#set-up",
    "href": "02-personalise.html#set-up",
    "title": "2  Personalised tutor",
    "section": "",
    "text": "Act as an expert tutor for the programming language R. I am a learner on an Upskilling course “Applied Data Skills” and I am learning R for the first time. I work in the NHS in Health Informatics. I have never learned a programming language before. I have used Excel and SPSS. I have reasonably good general computer literacy. I will ask you questions about concepts and functions I do not understand based on my course materials. Always give me concrete examples when you provide an answer. Tailor your responses to my level of expertise. I am using R and RStudio on a Mac and the course will strongly use the tidyverse.\n\n\nAct as an expert tutor for the programming language R. I am a first year psychology student at the University of Glasgow and I am learning R for the first time. I have never learned a programming language before and I am not very confident with computers and I am anxious about learning programming. I have a Windows laptop. I will ask you questions about concepts and functions I do not understand based on my course materials. Always give me concrete examples when you provide an answer. Tailor your responses to my level of expertise. I am using R and RStudio and the course will strongly use the tidyverse.\n\n\nAct as an expert tutor for the programming language R. I am a second year psychology student at the University of Glasgow. I have been learning R for a year. I also study statistics and computing science and know a bit of Python as well. I feel confident with learning to code and I would like to stretch myself. I will ask you questions about concepts and functions I do not understand based on my course materials. Always give me concrete examples when you provide an answer. Tailor your responses to my level of expertise. I am using R and RStudio and the course will strongly use the tidyverse although I would also like to learn about base R alternative approaches.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#sec-setup",
    "href": "02-personalise.html#sec-setup",
    "title": "2  Personalised tutor",
    "section": "2.2 Activity 1: Write your set-up",
    "text": "2.2 Activity 1: Write your set-up\nWrite your set-up. It’s worth spending some time to get this right, you’re going to use it a lot.\nI’d probably recommend using ChatGPT or Gemini for this because it’s helpful to be able to save your chat and the set-up information. You could also use a personal Copilot account but the Enterprise version won’t save your chats. If you’d like to use Copilot, save your set-up prompt somewhere to make it easy to reuse.\nExactly what information you provide is up to you but make sure that you explain your level of knowledge, skill, confidence and previous experience. By specifying what your field is (psychology, NHS etc.) it can then give you examples related to these fields which will make it easier for you to understand and connect your new knowledge to existing knowledge. Finally, if you’re using it for coding, you also want to give it some technical information about the software you’re using (e.g., R and RStudio) and your operating system (Windows).",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#activity-2-instruct-the-ai",
    "href": "02-personalise.html#activity-2-instruct-the-ai",
    "title": "2  Personalised tutor",
    "section": "2.3 Activity 2: Instruct the AI",
    "text": "2.3 Activity 2: Instruct the AI\nEnter your set-up into a new chat on your AI of choice. If you’re using an AI that saves your chats, you could also rename the chat to “Personal Tutor” or “Week 1 Tutor” or anything else that make sense to you. Depending on what information you give it, it may give you e.g., some intro to R tips and information which may be more or less useful, so if it’s confusing, just ignore it until you’ve given it more specific prompts.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#example-questions",
    "href": "02-personalise.html#example-questions",
    "title": "2  Personalised tutor",
    "section": "2.4 Example questions",
    "text": "2.4 Example questions\nNow that you’ve got your tutor set up, you can ask it questions. Here’s some examples:\n\nWhy do I have to learn to code?\nWhat is the difference between short-term memory and working memory?\nGive me examples of between-subject designs\nWhat is the difference between a function and an argument?\nExplain what each part of this code is doing: ggplot(survey_data, aes(x = wait_time, y = call_time)) +  geom_point()\nGive me examples of when I would use different joins in R",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#activity-3-questions",
    "href": "02-personalise.html#activity-3-questions",
    "title": "2  Personalised tutor",
    "section": "2.5 Activity 3: Questions",
    "text": "2.5 Activity 3: Questions\nAsk the AI three questions based on your course materials. If the output doesn’t seem at the right level for you, consider editing your initial set-up prompt and re-running the questions to see how the output changes.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#conversation",
    "href": "02-personalise.html#conversation",
    "title": "2  Personalised tutor",
    "section": "2.6 Conversation",
    "text": "2.6 Conversation\nAnother big difference between AI and a regular search engine is that you can have a conversation with it and follow-up on your original question. Some examples:\n\nCan you explain it again but compare it to Excel?\nExpand on your explanation of geom_point()\nGive me another example of code that uses this approach\nExplain it again but in more technical / simpler terms (Gemini’s modify response can also be used for this)\nAsk me a question to test if I understand this correctly (we’re going to go into practice testing a lot more in the next chapter)\nIn your answer you said “In this example, c() is a function that combines values into a vector”, what is a vector?",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#activity-4-follow-up",
    "href": "02-personalise.html#activity-4-follow-up",
    "title": "2  Personalised tutor",
    "section": "2.7 Activity 4: Follow-up",
    "text": "2.7 Activity 4: Follow-up\nAsk a follow-up question to each of your original questions. Additionally, try out the features of each AI. For Gemini, use the modify response and double-check response options. For ChatGPT, use regenerate response. For Copilot, click on the suggested follow-up questions or any links it provides.\n\n\n\n\n\n\nCaution\n\n\n\nThis book should be considered a living document and is likely to change over time. Given the brave new world in which we now live, all constructive feedback and suggestions are welcome! If you have any feedback or suggestions, please provide it via Forms.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "03-testing.html",
    "href": "03-testing.html",
    "title": "\n3  Practice testing\n",
    "section": "",
    "text": "3.1 Activity 1: Set-up\nIn your AI of choice, create a new chat and give it your set-up blurb that you created in Chapter Section 2.2.\nIt would be helpful to have a specific week/chapter/lecture of your course in mind to work with. For the PsyTeachR R courses, we’ll be using the Intended Learning Outcomes, functions used, and glossary to help instruct the AI. If you’re not working through a course, or it’s not a PsyTeachR course, it would be helpful to have a list of functions, concepts, or skills that you want to test. As an example, we’ll use Chapter 3 of Applied Data Skills.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#activity-2-question-prompt",
    "href": "03-testing.html#activity-2-question-prompt",
    "title": "\n3  Practice testing\n",
    "section": "\n3.2 Activity 2: Question prompt",
    "text": "3.2 Activity 2: Question prompt\nThen we need to give it instructions for how to create the questions. There are other question types you could ask it for but here is a starter pack for a coding course and then for a theoretical course:\nPromps for a coding course\n\nI would like you to generate practice questions to help consolidate my learning based on the learning outcomes, functions, and glossary used in my course materials this week that I will provide to you. I will ask you for four different types of questions.\n\n\nFirst, multiple choice questions (MCQ). Each question should have 4 response options and one correct answer. Ask them one at a time and explain the answer to me and why the other options are incorrect after I provide my answer.\n\n\nSecond, fill-in-the-blank questions (FITB). Provide a line of code that has one or more missing arguments or functions and ask me to complete the code.\n\n\nThird, coding problems (CP). Give me short problems that I need to provide the answer to. These should be fully reproducible and use datasets built into R or the tidyverse. Where necessary, give me the code to load any packages or datasets that I will need.\n\n\nThird, error mode (EM). Give me code that will result in an error. Explain what the code is intended to do and then ask me to figure out what the error is, and then fix it. The errors should be plausible errors that a beginner would be likely to make but do not tell me what the error is. The errors should be fully reproducible and use datasets built into R or the tidyverse so that I can run the code and fix them in R. Where necessary, give me the code to load any packages or datasets that I will need.\n\n\nDon’t give me questions until I have given you the ILOs and functions I want to test. I will specify which type of question I want each time. Give me only 1 question at a time and mix up the topic of each question.\n\nPrompts for a theoretical course\n\nI would like you to generate practice questions to help consolidate my learning based on the learning outcomes and key terms in my course materials this week that I will provide to you. I will ask you for four different types of questions.\n\n\nFirst, multiple choice questions (MCQ). Each question should have 4 response options and one correct answer. Ask them one at a time and explain the answer to me and why the other options are incorrect after I provide my answer.\n\n\nSecond, TRUE or FALSE questions (TOF). Provide a statement and then ask me to determine whether the statement is true or false.\n\n\nThird, fill-in-the-blank questions (FITB). Provide a statement that has one or more missing words and ask me to fill in the blanks.\n\n\nFourth, short answer questions (SAQ). Each question should ask about one specific concept, theory, or term, and I should be able to answer it in 100 words or fewer.\n\n\nDon’t give me questions until I have given you the ILOs and terms I want to test. I will specify which type of question I want each time. Give me only 1 question at a time and mix up the topic of each question.\n\nThe final instruction is added because the AI will occasionally get ahead of itself and it’s more useful to control the output.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#built-in-datasets",
    "href": "03-testing.html#built-in-datasets",
    "title": "\n3  Practice testing\n",
    "section": "\n3.3 Built-in datasets",
    "text": "3.3 Built-in datasets\nIf you’re using AI to help with coding, built-in datasets in R are sample datasets that come pre-loaded with the R software installation. They provide a convenient way to practice data manipulation, analysis, and visualization techniques without needing to import external data files. These datasets cover various domains and can be helpful for learning and demonstrating R functionalities.\nYou can get a full list of all the built-in datasets available to you by running the command data() in the console. Base R comes with datasets built in but when you install extra packages they also sometimes have extra datasets, for example, the tidyverse has a lot of extra datasets. A package needs to be loaded for you to use any datasets from it, or for them to show up in the list when you run data().\n\n# see list of datasets\ndata()\n\n# load tidyverse to get access to extra sets\nlibrary(tidyverse)\n\n# load in dataset to environment so it can be used\ndata(\"starwars\")",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#activity-3-content-prompt",
    "href": "03-testing.html#activity-3-content-prompt",
    "title": "\n3  Practice testing\n",
    "section": "\n3.4 Activity 3: Content prompt",
    "text": "3.4 Activity 3: Content prompt\nNow give it the learning outcomes, list of functions, and glossary terms you want it to quiz you on. You don’t need to worry about copying and pasting these over with nice formatting, just dump it all in. For example, for Applied Data Skills Chapter 3, this is what I provided:\n\nIntended Learning Outcomes Be able to identify categorical versus continuous data Be able to create plots in layers using ggplot Be able to choose appropriate plots for data 3.1 Functions used aes(), as.numeric(), c(), col_character(), col_datetime(), col_double(), col_factor(), col_integer(), cols(), coord_cartesian(), count(), element_blank(), facet_wrap(), factor(), geom_bar(), geom_boxplot(), geom_col(), geom_histogram(), geom_jitter(), geom_point(), geom_smooth(), ggplot(), ggtitle(), glimpse(), guides(), mean(), now(), plot_layout(), read_csv(), rgb(), scale_fill_manual(), scale_x_continuous(), scale_x_date(), scale_x_discrete(), scale_y_continuous(), seq(), spec(), stat_summary(), theme(), theme_bw(), theme_gdocs(), theme_set(), today()\n\n\n3.7 Glossary termdefinitionargumentA variable that provides input to a function.categoricalData that can only take certain values, such as types of pet.categoricalData that can only take certain values, such as types of pet.characterA data type representing strings of text.chunkA section of code in an R Markdown filecontinuousData that can take on any values between other existing values.continuousData that can take on any values between other existing values.data-typeThe kind of data represented by an object.default-valueA value that a function uses for an argument if it is skipped.doubleA data type representing a real decimal numberfactorA data type where a specific set of values are stored with labels; An explanatory variable manipulated by the experimentergeomThe geometric style in which data are displayed, such as boxplot, density, or histogram.integerA data type representing whole numbers.knitTo create an HTML, PDF, or Word document from an R Markdown (Rmd) documentlikertA rating scale with a small number of discrete points in orderlogicalA data type representing TRUE or FALSE values.medianThe middle number in a distribution where half of the values are larger and half are smaller.nominalCategorical variables that don’t have an inherent order, such as types of animal.numericA data type representing a real decimal number or integer.observationAll of the data about a single trial or question.ordinalDiscrete variables that have an inherent order, such as level of education or dislike/like.outlierA data point that is extremely distant from most of the other data pointsr-markdownThe R-specific version of markdown: a way to specify formatting, such as headers, paragraphs, lists, bolding, and links, as well as code blocks and inline code.stringA piece of text inside of quotes.tidy-dataA format for data that maps the meaning onto the structure.valueA single number or piece of data.variable(coding): A word that identifies and stores the value of some data for later use; (stats): An attribute or characteristic of an observation that you can measure, count, or describevectorA type of data structure that collects values with the same data type, like T/F values, numbers, or strings.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#activity-4-generating-questions",
    "href": "03-testing.html#activity-4-generating-questions",
    "title": "\n3  Practice testing\n",
    "section": "\n3.5 Activity 4: Generating questions",
    "text": "3.5 Activity 4: Generating questions\nYou should now be able to ask it to generate questions for you by typing mcq or coding problem. A few other prompts to consider:\n\nMore like this\nGive me a harder/easier question\nCoding problem about stat_summary()",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#cautions-and-caveats",
    "href": "03-testing.html#cautions-and-caveats",
    "title": "\n3  Practice testing\n",
    "section": "\n3.6 Cautions and caveats",
    "text": "3.6 Cautions and caveats\nThe questions it generates are generally helpful, but not always. Here’s the issues I’ve come across whilst writing this book that I have not been able to prevent entirely by tweaking my prompts.\n\n3.6.1 Mulitple-choice / TOF / SAQ questions\n\nSometimes it is just plain wrong. The answer here should be C. If you tell it that it is wrong, it can correct itself. But just bear this in mind if you ever use it to write code that AI does not know anything, it’s just a very sophisticated parrot. \nIt may ask you questions about functions or concepts you’ve haven’t covered in the course.\nIt may give you a question where there are multiple correct answers without indicating this is the case, which can be confusing.\nIt may focus too much on certain topics of functions and you have to ask it to give you questions on a topic/function specifically.\n\n3.6.2 Coding problems\n\nIt suggests using a built-in dataset that doesn’t exist. In this case, tell it that’s the case and it will suggest a different dataset for the problem.\nThe example it gives isn’t fully reproducible so you have to write the code without being able to run it in R. For example, it assumes you have a dataset with columns named “number” and “price”, but loads no such dataset, so you can’t actually try out the code. It’s still possible to write the code, but without being able to run it, much more difficult, particularly as a beginner.\n\n3.6.3 Error mode\n\nThis is the category the AI struggled with the most, to the point where at the time of writing, I can’t say that it’s up to the task. I have tried writing the prompts mulitple times and whilst I have seen some improvement, it’s not consistent. I have a premium ChatGPT subscription and I also tried using GPT4.0 and it didn’t help. I’ve decided to leave it in this book because it’s a useful cautionary tale of the limits of AI.\nFrom a learning and teaching perspective, it’s a good example of why teaching might actually be a skill and my job might be safe after all. When we use Error Mode type questions in our courses, we design the errors so that they’re common mistakes learners make at that point in their journey, they’re mistakes that learners would plausibly make, and solving them will teach you something of use. Even when the AI managed to create an accurate error mode problem, it still wasn’t helpful for learning.\nIn my initial attempts at prompting, Gemini did poorly at this. It gave me code that did not have errors, or it would tell me what the errors were, or it would give errors that were so obvious they wouldn’t help you learn at all. For example:\n\n - I then updated the prompt to say that the errors should be plausible and not to tell me what the errors were. This helped but only sometimes. - ChatGPT fared slightly better although all of the problems were very basic and of the same type (creating a vector) until I asked it to give me me a specific problem (e.g., error mode for ggplot). - ChatGPT also suffered from the same problems as Gemini in that it would tell you what the error was or produce code that did not have any errors. I particularly enjoyed this response whereby it seemed to pretend that it was doing it on purpose as a teachable moment. I know I am anthropomorphising the AI here but I imagine any educator will feel a sense of kinship at trying to make your mistakes seem intentional.\n\n\nIt often won’t tell you what built-in dataset you need to load to run the code (and this isn’t the intended error). Unless you have a working knowledge of built-in datasets in R and the packages they’re from, this is unnecessarily confusing.\nThere is no prompt I can give Copilot that will result in it producing code with an error (even when the same prompt works with ChatGPT). So I gave up.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nThis book should be considered a living document and is likely to change over time. Given the brave new world in which we now live, all constructive feedback and suggestions are welcome! If you have any feedback or suggestions, please provide it via Forms.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "04-errors.html",
    "href": "04-errors.html",
    "title": "\n4  Error checking and debugging\n",
    "section": "",
    "text": "4.1 Activity 1: Set-up\nSo that you can reproduce the same errors, let’s create a reproducible example and load some packages and a dataset. Open an Rmd (not a script, we’ll use the Rmd in Activity 3) and run the below (you may need to install the package palmerpenguins if you don’t have it already).\nlibrary(tidyverse)\nlibrary(palmerpenguins)\ndata(\"penguins\")",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "04-errors.html#sec-simple-errors",
    "href": "04-errors.html#sec-simple-errors",
    "title": "\n4  Error checking and debugging\n",
    "section": "\n4.2 Activity 2: Simple errors",
    "text": "4.2 Activity 2: Simple errors\nUnlike the other chapters you don’t need to do any set-up, in fact, you can often just copy and paste the code and error in and it will figure out that you want it to fix it without even needing to explicitly ask.\nHere’s a simple error where we have given it the wrong function name:\n\nggplot(penguins, aes(x = species)) +\n   geom_barchart()\n\nError in geom_barchart(): could not find function \"geom_barchart\"\n\n\n\nGive your AI of choice both the code and the error. One without the other is likely to result in a poor or incomplete answer (whether you ask a human or an AI).\n\nAll three AIs identified, explained, and fixed this error. Gemini also tried to give some additional information about the function, with links to more information, which is nice.\n\n\n\n\nFixing a simple error",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "04-errors.html#activity-3-contextual-errors",
    "href": "04-errors.html#activity-3-contextual-errors",
    "title": "\n4  Error checking and debugging\n",
    "section": "\n4.3 Activity 3: Contextual errors",
    "text": "4.3 Activity 3: Contextual errors\nSomething that catches many people out is when the error is actually being caused by code further up your script rather than the bit that is results in the error.\nFor example, in this code, what we intended to do was to create a dataset that just has penguins from Biscoe Island and then calculate their mean body mass. This code will run, but it produces NaN as the value.\n\nbiscoe_penguins &lt;- penguins %&gt;%\n  filter(island == \"biscoe\")\n\nbiscoe_penguins %&gt;%\n  summarise(mean_mass = mean(body_mass_g))\n\n\n\n\nmean_mass\n\n\nNaN\n\n\n\n\n\nIf you just give an AI the code and the table and ask it to explain what’s happening, it will do its best but without knowing the dataset or what code has preceded it, it won’t give you the exact answer, although in this case it hints at it.\n\n\n\n\nChatGPT giving its best guess\n\n\n\nThere’s a couple of things you can do at this point:\n\nGive the AI all the code you’ve used so far\nRun str(penguins) and str(biscoe_penguins) and give the AI the output of these calls so that it better understands the structure and contents of the datasets\n\nIf you haven’t spotted it by now, the error is that in the filter biscoe should be Biscoe with a capital B. It still doesn’t have the information it needs to tell you this explicitly, but it will get you very close. There is no shortcut for knowing your data.\n\n\n\n\nCopilot getting very close",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "04-errors.html#activity-4-incorrect-but-functional-code",
    "href": "04-errors.html#activity-4-incorrect-but-functional-code",
    "title": "\n4  Error checking and debugging\n",
    "section": "\n4.4 Activity 4: Incorrect (but functional) code",
    "text": "4.4 Activity 4: Incorrect (but functional) code\nSometimes (often) when we write code, the issue isn’t that our code doesn’t work, but that it doesn’t do what we intended to do and we can’t figure out why.\nFor example, let’s say that we want to calculate the average body_mass_g for each species by sex. We’re feeling a bit lazy and we copy and paste in the following from a previous script we have:\n\npenguins %&gt;%\n  group_by(sex, species) %&gt;%\n  summarise(mean_body_mass = sd(body_mass_g, na.rm = TRUE))\n\n`summarise()` has grouped output by 'sex'. You can override using the `.groups`\nargument.\n\n\n\n\n\nsex\nspecies\nmean_body_mass\n\n\n\nfemale\nAdelie\n269.3801\n\n\nfemale\nChinstrap\n285.3339\n\n\nfemale\nGentoo\n281.5783\n\n\nmale\nAdelie\n346.8116\n\n\nmale\nChinstrap\n362.1376\n\n\nmale\nGentoo\n313.1586\n\n\nNA\nAdelie\n477.1661\n\n\nNA\nGentoo\n338.1937\n\n\n\n\n\n\nWe know something isn’t right here. Because we’re responsible researchers, we’ve taken time to understand our dataset and what plausible values should be and we know there’s no way that the average body mass of a penguin is 269 grams (unless the penguin is made of chocolate). Nut the code is running fine, we know it’s worked before, and we can’t see what we’ve done wrong.\nYou can ask the AI to help you but you can’t just give it the code and output, you also need to tell it what you intended to do. In this case, all three AIs correctly identified that I had used sd instead of mean. The more complex your code, the more information you will need to give it in order for it to help you find the error.\n\n\n\n\nFixing a functional error\n\n\n\nThis is a good example of why there is no AI tool that allows you to skip understanding the data you’re working with and knowing what it is you’re trying to do.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "04-errors.html#activity-5-rmd-errors",
    "href": "04-errors.html#activity-5-rmd-errors",
    "title": "\n4  Error checking and debugging\n",
    "section": "\n4.5 Activity 5: Rmd errors",
    "text": "4.5 Activity 5: Rmd errors\nIf you’re working in R Markdown or Quarto, sometimes the errors will stem from your code chunk settings or YAML.\nIn your Rmd file, create a new code chunk and copy and paste the following:\n\npenguins %&gt;%\n  count()\n\nBut then delete one of the final back ticks (`) from the code chunk.\nThe code is fine, it provides a simple count of the number of observations in the dataset. But if you try and knit the file, you’ll get a long ! attempt to use zero-length variable name. Copilot wasn’t that helpful because all of its suggestions relate to checking your code:\n\n\n\n\nMissing the mark\n\n\n\nHowever, Gemini was more useful as one of its suggestions is indeed the solution - there’s a missing back tick at the end of the code chunk. In cases like this, it won’t give you a solution you can copy and paste but it will tell you what to go and look for.\n\n\n\n\nMissing backticks\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nI know I might be starting to sound like a broken record but please remember that artificial intelligence is not actually intelligent. It’s not thinking, it’s not making conscious decisions, it has no expert subject matter knowledge. No matter how helpful it is, you must always check the output of the code it gives you.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nThis book should be considered a living document and is likely to change over time. Given the brave new world in which we now live, all constructive feedback and suggestions are welcome! If you have any feedback or suggestions, please provide it via Forms.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "05-review.html",
    "href": "05-review.html",
    "title": "\n5  Code review\n",
    "section": "",
    "text": "5.1 Code comments\nCode comments are lines or sections of text added within the code itself that are ignored by the computer when the program runs. They’re there for human readers, not machines. In R, you add comments to code by adding # to the start of the string:\n# this is a comment\n\n# compute the mean of three numbers\nmean(c(1,2,3))\n\n[1] 2\nComments are useful for several reasons:\nOverall, comments are a crucial part of writing clean, maintainable, and collaborative code. They help make the code more accessible and understandable to anyone who might work on it in the future.\nFor transparency, Gemini and Copilot wrote the above text.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "05-review.html#code-comments",
    "href": "05-review.html#code-comments",
    "title": "\n5  Code review\n",
    "section": "",
    "text": "Clarification: They explain what certain parts of the code do, making it easier for others (and yourself) to understand the logic and flow of the code.\nDocumentation: They provide information on how the code works or why certain decisions were made, which is helpful for future reference.\nDebugging: Temporarily commenting out parts of code can help isolate sections that may be causing errors, without deleting the code.\nCollaboration: In team projects, comments can be used to communicate with other developers about the status or purpose of the code.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "05-review.html#activity-1-add-comments-with-ai",
    "href": "05-review.html#activity-1-add-comments-with-ai",
    "title": "\n5  Code review\n",
    "section": "\n5.2 Activity 1: Add comments with AI",
    "text": "5.2 Activity 1: Add comments with AI\nFirst we’ll use use the palmerpenguins dataset again.\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\ndata(\"penguins\")\n\nYou can use AI tools to help add comments to your code. We’ll start with a simple prompt to see how it gets on. In your chosen platform, input the below code with the prompt:\n\nAdd comments to this code\n\n\npenguins_clean &lt;- penguins %&gt;%\n  filter(complete.cases(.)) %&gt;%\n  mutate(across(where(is.factor), as.character)) %&gt;%\n  mutate(species_sex = interaction(species, sex, sep = \"_\"))\n\n\n\n\n\nAdding comments\n\n\n\nA few things to note:\n\nThe AI can only tell you what the code is doing, it can’t say why you chose to do that. In this example, we’ve created a new column that combines species and sex but the comment gives us no idea what the rationale was for this. The more complex your analysis, the more crucial it becomes to explain the rationale.\nThe initial attempt at adding comments is quite verbose. Gemini was not as bad as ChatGPT, but even in the above example there’s a bit more than is really necessary. I’d argue you could delete one of the comments in each section and it would still be clear. Too many comments are a different problem to too few, but they’re still a problem.\nIn the above example, Gemini has also made the strange decision to make the code itself more verbose and it has removed the piping and split it into three different calls which isn’t ideal.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "05-review.html#activity-2-comment-prompt-engineering",
    "href": "05-review.html#activity-2-comment-prompt-engineering",
    "title": "\n5  Code review\n",
    "section": "\n5.3 Activity 2: Comment prompt engineering",
    "text": "5.3 Activity 2: Comment prompt engineering\nLet’s see if we can amend our prompt to get the comments more aligned with what we want.\n\nAdd comments to this code. Keep the comments as concise as possible Ask me any questions about the code if you are not sure what it is doing or why. Do not change anything about the code.\n\nCopilot produced the following (and the output from ChatGPT and Gemini was very similar), which is much better.\n\n# Assigning the cleaned data to 'penguins_clean'\npenguins_clean &lt;- penguins %&gt;%\n  # Filtering out rows with missing values\n  filter(complete.cases(.)) %&gt;%\n  # Converting all factor columns to character type\n  mutate(across(where(is.factor), as.character)) %&gt;%\n  # Creating a new column 'species_sex' with combined 'species' and 'sex' information\n  mutate(species_sex = interaction(species, sex, sep = \"_\"))",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "05-review.html#activity-3-review-existing-comments",
    "href": "05-review.html#activity-3-review-existing-comments",
    "title": "\n5  Code review\n",
    "section": "\n5.4 Activity 3: Review existing comments",
    "text": "5.4 Activity 3: Review existing comments\nIn addition to asking AI to comment your code, you can also ask it to review comments you’ve made yourself. To see how this works with a more complex example, and as an act of masochism, I gave the AI some code I wrote for a publication. The full paper is here if you’re interested - the quant analyses ended up being punted to the online appendix because of word count.\nYou can load in the dataset yourself with this code:\n\n# read in data but skip rows 2 and 3\ncol_names &lt;- names(read_csv(\"https://osf.io/download/tf3xs/\", n_max = 0))\ndat_raw &lt;- read_csv(\"https://osf.io/download/tf3xs/\", col_names = col_names, skip = 3) \n\nThe first section of my code involved quite a complicated and long bit of wrangling, all done in a single pipeline. The purpose of the code is to clean up data collected on the survey platform Qualtrics and recoding some of the demographic variables. Despite it’s length, this is actually a shortened version because the original hit the character limit for Copilot. I did put some effort into writing comments before publication but there are almost certainly improvements to be made.\n\ndat &lt;- dat_raw%&gt;%\n  filter(Progress &gt; 94, # remove incomplete responses\n         DistributionChannel != \"preview\") %&gt;% # Remove Emily's preview data\n  select(ResponseId, \"duration\" = 5, Q5:Q21) %&gt;%\n  # replace NAs with \"none\" for disability info\n  mutate(disability_nos = replace_na(disability_nos, \"None\"),\n         physical_chronic = replace_na(physical_chronic, \"None\"),\n         mental_health = replace_na(mental_health, \"None\"),\n) %&gt;%\n  # recode disability data\n  mutate(disability = case_when(# neurodivergent \n                                  neurotype == \"Neurodivergent\" &\n                                  physical_chronic == \"None\" &\n                                  mental_health == \"None\" & \n                                  disability_nos == \"None\" ~\n                                  \"Neurodivergent\",\n                                 # disabled\n                                  neurotype == \"Neurotypical\" &\n                                  physical_chronic == \"Physical, mobility, or chronic health condition\" |\n                                  mental_health == \"Mental health condition\" |\n                                  disability_nos == \"Disability not otherwise specified\" ~\n                                  \"Disabled\",\n                                 # multiple conditions\n                                 (neurotype == \"Neurodivergent\" & mental_health != \"None\") |\n      (neurotype == \"Neurodivergent\" & physical_chronic != \"None\") |\n      (neurotype == \"Neurodivergent\" & disability_nos != \"None\") |\n      (mental_health != \"None\" & physical_chronic != \"None\") |\n      (mental_health != \"None\" & disability_nos != \"None\") |\n      (physical_chronic != \"None\" & disability_nos != \"None\") ~ \"NDD\",\n                                \n                                TRUE ~ \"Neurotypical & non-disabled\"))%&gt;%\n  # select necessary columns and tidy up the names\n        select(ResponseId,\n             \"age\" = Q5,\n             \"gender\" = Q6,\n             \"mature\" = Q7,\n             \"level_study\" = Q8,\n             \"country\" = Q9,\n             \"subject\" = Q10,\n             \"english_first\" = Q11,\n             disability,\n             \"neurotype_open\" = Q13, \n             \"disability_open\" = Q14,\n             \"why_open\" = Q18,\n             \"how_open\" = Q23,\n             \"advantages\" = Q20,\n             \"disadvantages\" = Q21,\n             everything()) \n\nMy initial attempt at this used the following prompt:\n\nReview my use of comments and make improvements to the comments where necessary. Explain what you changed and why.\n\n\nAs well as giving me an explanation in the chat window, Gemini added the explanation to the comments themselves, so you’d need to go and edit these out (or amend the prompt to tell it not to do this).\nIt has picked up where the logic of the comments might not be helpful to someone who doesn’t already know the data e.g., (explain logic), which is useful.\nExtremely problematically, it didn’t just change the comments, it changed the code. The original first use of select() was select(ResponseId, \"duration\" = 5, Q5:Q21) %&gt;%. In this code, I selected the columns I wanted but I also renamed the 5th column. Gemini has changed the code to remove this from select and has instead create a new column named duration that will contain the value 5. I didn’t ask it to do this and in its response, it doesn’t tell me anywhere that it made this change. Be very, very careful.\n\n\ndat_gemini &lt;- dat_raw %&gt;%\n  # Filter incomplete responses and remove preview data (for clarity)\n  filter(Progress &gt; 94, DistributionChannel != \"preview\") %&gt;%\n  # Select core columns and create a \"duration\" column (more specific)\n  select(ResponseId, Q5:Q21) %&gt;%\n  mutate(\n    duration = 5,  # Assuming duration is constant at 5, explain if not\n    # Replace NAs in disability info with \"None\" (clearer intent)\n    disability_nos = replace_na(disability_nos, \"None\"),\n    physical_chronic = replace_na(physical_chronic, \"None\"),\n    mental_health = replace_na(mental_health, \"None\")\n  ) %&gt;%\n  # Recode disability data into more informative categories (explain logic)\n  mutate(disability = case_when(\n    # Neurodivergent with no other conditions\n    neurotype == \"Neurodivergent\" &\n      physical_chronic == \"None\" &\n      mental_health == \"None\" &\n      disability_nos == \"None\" ~ \"Neurodivergent\",\n    # Disabled with any reported condition\n    neurotype == \"Neurotypical\" &\n      (physical_chronic != \"None\" |  # Include \"OR\" for clarity\n       mental_health != \"None\" |\n       disability_nos != \"None\") ~ \"Disabled\",\n    # Multiple conditions (explain groupings)\n    (neurotype == \"Neurodivergent\" &\n      (physical_chronic != \"None\" |\n       mental_health != \"None\" |\n       disability_nos != \"None\")) |\n    (physical_chronic != \"None\" &\n     (mental_health != \"None\" |\n      disability_nos != \"None\")) |\n    (mental_health != \"None\" & disability_nos != \"None\") ~ \"NDD\"  # Define NDD acronym\n    , TRUE ~ \"Neurotypical & non-disabled\")) %&gt;%\n  # Select final columns and rename for clarity\n  select(ResponseId,\n         age = Q5,\n         gender = Q6,\n         mature = Q7,\n         level_study = Q8,\n         country = Q9,\n         subject = Q10,\n         english_first = Q11,\n         disability,\n         neurotype_open = Q13,\n         disability_open = Q14,\n         why_open = Q18,\n         how_open = Q23,\n         advantages = Q20,\n         disadvantages = Q21,\n         everything())\n\n\nExplanation of Changes:\n\n\nClarity: Added more specific explanations to comments, especially for variable creation and data manipulation steps.\n\n\nLogic: Explained the reasoning behind the recoding logic in the case_when statements for disability and gender.\n\n\nConciseness: Shortened some comments where brevity is sufficient.\n\n\nAcronyms: Defined the acronym “NDD” for better understanding.\n\n\nConsistency: Used consistent formatting for comments (e.g., indentation).\n\n\nThese improvements enhance the readability and maintainability of your code, making it easier for you or others to understand the purpose of each step.\n\n\n5.4.1 More prompt engineering\nAgain I played about with the prompt to try and prevent these issues:\n\nReview my use of comments and make improvements to the comments where necessary. Keep the comments as concise as possible. Do not change anything about the code.\n\nCopilot introduces an error almost straight away - the filter keeps responses with progress over 94% but it claims the opposite.\n\n# Assigning the processed data to 'dat'\ndat_copilot &lt;- dat_raw %&gt;%\n  # Filtering out responses with progress over 94% and excluding preview data\n  filter(Progress &gt; 94, # Remove incomplete responses\n         DistributionChannel != \"preview\") %&gt;% # Exclude preview data\n  # Selecting specific columns by ResponseId and renaming column 5 to 'duration'\n  select(ResponseId, \"duration\" = 5, Q5:Q21) %&gt;%\n  # Replacing NA values with \"None\" in disability-related columns\n  mutate(disability_nos = replace_na(disability_nos, \"None\"),\n         physical_chronic = replace_na(physical_chronic, \"None\"),\n         mental_health = replace_na(mental_health, \"None\"),\n  ) %&gt;%\n  # Recoding disability categories based on conditions\n  mutate(disability = case_when(\n    # Classify as 'Neurodivergent' if only neurotype is divergent\n    neurotype == \"Neurodivergent\" &\n    physical_chronic == \"None\" &\n    mental_health == \"None\" & \n    disability_nos == \"None\" ~ \"Neurodivergent\",\n    # Classify as 'Disabled' if any disability condition is met\n    neurotype == \"Neurotypical\" &\n    (physical_chronic == \"Physical, mobility, or chronic health condition\" |\n     mental_health == \"Mental health condition\" |\n     disability_nos == \"Disability not otherwise specified\") ~ \"Disabled\",\n    # Classify as 'NDD' for multiple conditions including neurodivergence\n    (neurotype == \"Neurodivergent\" & (mental_health != \"None\" |\n                                       physical_chronic != \"None\" |\n                                       disability_nos != \"None\")) |\n    (mental_health != \"None\" & (physical_chronic != \"None\" |\n                                disability_nos != \"None\")) |\n    (physical_chronic != \"None\" & disability_nos != \"None\") ~ \"NDD\",\n    # Default classification\n    TRUE ~ \"Neurotypical & non-disabled\"\n  )) %&gt;%\n  # Selecting and renaming columns for clarity\n  select(ResponseId,\n         \"age\" = Q5,\n         \"gender\" = Q6,\n         \"mature\" = Q7,\n         \"level_study\" = Q8,\n         \"country\" = Q9,\n         \"subject\" = Q10,\n         \"english_first\" = Q11,\n         disability,\n         \"neurotype_open\" = Q13, \n         \"disability_open\" = Q14,\n         \"why_open\" = Q18,\n         \"how_open\" = Q23,\n         \"advantages\" = Q20,\n         \"disadvantages\" = Q21,\n         everything()) \n\nBut worse, it’s still changed the code (and hasn’t flagged that it did this). A bit of digging with all.equal() and count() reveals that it has made changes to the disablity coding scheme. Not only was it not asked to change it, it was asked explicitly not to change the code, and it did it anyway.\n\nall.equal(dat, dat_copilot)\n\n[1] \"Component \\\"disability\\\": 31 string mismatches\"\n\ndat %&gt;% count(disability)\n\n\n\n\ndisability\nn\n\n\n\nDisabled\n84\n\n\nNDD\n28\n\n\nNeurodivergent\n126\n\n\nNeurotypical & non-disabled\n72\n\n\n\n\n\ndat_copilot %&gt;% count(disability)\n\n\n\n\ndisability\nn\n\n\n\nDisabled\n53\n\n\nNDD\n59\n\n\nNeurodivergent\n126\n\n\nNeurotypical & non-disabled\n72\n\n\n\n\n\n\nChatGPT makes the same mistake in stating that incomplete responses are those with progress greater than 94. but generally it does a reasonably good job at editing the comments, but not going too far. Thankfully, all.equal() find that the object created by ChatGPT is identifical to the original, so it hasn’t made any changes to the behaviour of the code.\n\ndat_chat &lt;- dat &lt;- dat_raw %&gt;%\n  # Filter out incomplete responses with Progress greater than 94\n  filter(Progress &gt; 94, \n         # Exclude data from the \"preview\" distribution channel\n         DistributionChannel != \"preview\") %&gt;%\n  # Select specific columns and rename them\n  select(ResponseId, \"duration\" = 5, Q5:Q21) %&gt;%\n  # Replace missing values with \"None\" for disability information\n  mutate(disability_nos = replace_na(disability_nos, \"None\"),\n         physical_chronic = replace_na(physical_chronic, \"None\"),\n         mental_health = replace_na(mental_health, \"None\")) %&gt;%\n  # Recode disability status based on various conditions\n  mutate(disability = case_when(\n                                  # Neurodivergent without other disabilities\n                                  neurotype == \"Neurodivergent\" &\n                                  physical_chronic == \"None\" &\n                                  mental_health == \"None\" & \n                                  disability_nos == \"None\" ~\n                                  \"Neurodivergent\",\n                                 # Disabled based on specific conditions\n                                  neurotype == \"Neurotypical\" &\n                                  (physical_chronic == \"Physical, mobility, or chronic health condition\" |\n                                  mental_health == \"Mental health condition\" |\n                                  disability_nos == \"Disability not otherwise specified\") ~\n                                  \"Disabled\",\n                                 # Neurodevelopmental or multiple conditions\n                                 (neurotype == \"Neurodivergent\" & (mental_health != \"None\" | physical_chronic != \"None\" | disability_nos != \"None\")) |\n                                 (mental_health != \"None\" & (physical_chronic != \"None\" | disability_nos != \"None\")) |\n                                 (physical_chronic != \"None\" & disability_nos != \"None\") ~ \"NDD\",\n                                \n                                TRUE ~ \"Neurotypical & non-disabled\")) %&gt;%\n  # Select necessary columns and tidy up the names\n  select(ResponseId,\n         \"age\" = Q5,\n         \"gender\" = Q6,\n         \"mature\" = Q7,\n         \"level_study\" = Q8,\n         \"country\" = Q9,\n         \"subject\" = Q10,\n         \"english_first\" = Q11,\n         disability,\n         \"neurotype_open\" = Q13, \n         \"disability_open\" = Q14,\n         \"why_open\" = Q18,\n         \"how_open\" = Q23,\n         \"advantages\" = Q20,\n         \"disadvantages\" = Q21,\n         everything())",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "05-review.html#refactor-code",
    "href": "05-review.html#refactor-code",
    "title": "\n5  Code review\n",
    "section": "\n5.5 Refactor code",
    "text": "5.5 Refactor code\nTo refactor code refers to the process of restructuring existing code without changing its intended behavior. The goal is to make the code more maintainable, readable, and efficient, while not altering the functionality or output.\n\nImproves Readability: Makes the code easier to understand for anyone who reads it in the future, which includes other developers or even the original author after some time has passed.\nReduces Complexity: Simplifies complex code structures, breaking down large functions into smaller, more manageable ones.\nEnhances Maintainability: With cleaner code, it becomes easier to maintain and update the software over time.\nFacilitates Extensibility: Well-factored code can be extended with new features more easily.\nImproves Performance: In some cases, refactoring can optimize the performance of the software by removing redundancies and improving algorithms.\nIdentifies Bugs: The process of refactoring can often reveal hidden bugs or issues in the code that can then be fixed.\n\nWith thanks to Copilot for writing the above.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "05-review.html#activity-3-refactor",
    "href": "05-review.html#activity-3-refactor",
    "title": "\n5  Code review\n",
    "section": "\n5.6 Activity 3: Refactor",
    "text": "5.6 Activity 3: Refactor\nI’ll stick with the example of code from my publication because it’s complicated enough that there are likely improvements or alternative solutions. Using the same code chunk as above, the prompt is:\n\nrefactor this code and explain what you have changed and why. Where possible, use a tidyverse approach.\n\n\nAll three AIs struggled with this task. Their first attempts all gave me errors. In particular, it struggled with everything() in the call to select() at the end. This function is useful for when you want to select specific columns in a particular order and then you want everything else you haven’t explicitly named in the original order. My hunch is that everything() might be a newer argument to select() and isn’t in the training data so it doesn’t know how to use it?\n\nBut mostly the issues stemmed from the amount of code I was giving it at once because it made it very, very difficult for me figure out where the issues were coming in and to verify whether it was fundamentally changing the behaviour of the code.\nI then asked Copilot to split the code in each pipeline into a different object which it did:\n\nSplit the code in each pipeline into a separate object\n\n\n# Step 1: Filter the data\ndat_filtered &lt;- dat_raw %&gt;%\n  filter(Progress &gt; 94, DistributionChannel != \"preview\")\n\n# Step 2: Select and rename columns\ndat_selected &lt;- dat_filtered %&gt;%\n  select(ResponseId, \"duration\" = 5, Q5:Q21)\n\n# Step 3: Replace NAs with \"None\" for disability info\ndat_na_replaced &lt;- dat_selected %&gt;%\n  mutate(\n    disability_nos = replace_na(disability_nos, \"None\"),\n    physical_chronic = replace_na(physical_chronic, \"None\"),\n    mental_health = replace_na(mental_health, \"None\")\n  )\n\n# Step 4: Recode disability data\ndat_disability_recode &lt;- dat_na_replaced %&gt;%\n  mutate(\n    disability = case_when(\n      neurotype == \"Neurodivergent\" & physical_chronic == \"None\" & mental_health == \"None\" & disability_nos == \"None\" ~ \"Neurodivergent\",\n      neurotype == \"Neurotypical\" & (physical_chronic == \"Physical, mobility, or chronic health condition\" | mental_health == \"Mental health condition\" | disability_nos == \"Disability not otherwise specified\") ~ \"Disabled\",\n      (neurotype == \"Neurodivergent\" & mental_health != \"None\") | (neurotype == \"Neurodivergent\" & physical_chronic != \"None\") | (neurotype == \"Neurodivergent\" & disability_nos != \"None\") | (mental_health != \"None\" & physical_chronic != \"None\") | (mental_health != \"None\" & disability_nos != \"None\") | (physical_chronic != \"None\" & disability_nos != \"None\") ~ \"NDD\",\n      TRUE ~ \"Neurotypical & non-disabled\"\n    )\n  )\n\n# Step 5: Recode gender data\ndat_gender_recode &lt;- dat_disability_recode %&gt;%\n  mutate(\n    gender_cleaned = case_when(\n      Q6 %in% c(\"Female\", \"female\", \"Woman\", \"woman\", \"Cisgender woman\", \"female (she/her)\", \"F\", \"f\", \"Womxn\", \"Woman (tranas)\") ~ \"Woman\",\n      Q6 %in% c(\"Man\", \"man\", \"M\", \"m\", \"Male (he/him)\", \"Male\", \"male\", \"Trans man.\") ~ \"Man\",\n      Q6 %in% c(\"Agender\", \"Genderfluid\", \"GNC\", \"NB\", \"non-binary\", \"Non-binary\", \"Non-Binary\", \"Non-binary femme\", \"non-binary male\", \"non binary\", \"Non binary\", \"Nonbinary\", \"Queer\", \"Transmasculine\", \"Non-binary\") ~ \"Non-binary\",\n      TRUE ~ \"Not stated\"\n    )\n  )\n\n# Step 6: Select necessary columns and tidy up the names\ndat_final &lt;- dat_gender_recode %&gt;%\n  select(\n    ResponseId,\n    \"age\" = Q5,\n    \"gender\" = Q6,\n    gender_cleaned,\n    \"mature\" = Q7,\n    \"level_study\" = Q8,\n    \"country\" = Q9,\n    \"subject\" = Q10,\n    \"english_first\" = Q11,\n    disability,\n    \"neurotype_open\" = Q13,\n    \"disability_open\" = Q14,\n    \"why_open\" = Q18,\n    \"how_open\" = Q23,\n    \"advantages\" = Q20,\n    \"disadvantages\" = Q21,\n    everything()\n  )\n\nThen, for each chunk, I asked it to refactor the code, where possible. I slightly amended the prompt to explicitly say that if the code was already efficient enough, not to change anything because some of the steps are quite simple.\n\nRefactor this code where necessary. Explain what you changed and why. Do not change anything if the code is already efficient. Use the tidyverse where possible.\n\n\nFor step 3, Copilot and ChatGPT were both quite good at this and identical() returned TRUE.\n\n\n# chatgpt and copilot solution\nchat_dat_na_replaced &lt;- dat_selected %&gt;%\n  mutate(\n    across(c(disability_nos, physical_chronic, mental_health), ~replace_na(., \"None\"))\n  )\n# gemini solution - doesn't work, is a bit mad\ndat_na_replaced &lt;- dat_selected %&gt;%\n  mutate(\n    disability_nos = replace_na(disability_nos, \"None\"),\n    physical_chronic = replace_na(physical_chronic, \"None\"),\n    mental_health = replace_na(mental_health, \"None\")\n  ) %&gt;%\n  # Refactored using .after\n  mutate(\n    .after = {\n      .x$disability_nos &lt;- replace_na(.x$disability_nos, \"None\")\n      .x$physical_chronic &lt;- replace_na(.x$physical_chronic, \"None\")\n      .x$mental_health &lt;- replace_na(.x$mental_chronic, \"None\")\n      .x\n    }\n  )\n\nFor step 4 it was a bit of a mess:\n\nThe code Copilot gave me didn’t work and the proposed solution to fix the initial error added on more code than I originally had.\n\n\n# copilot\n# doesn't run\ncopilot_dat_disability_recode &lt;- dat_na_replaced %&gt;%\n  mutate(\n    # Simplify the neurodivergent condition by checking for \"None\" in all related columns at once\n    disability = case_when(\n      neurotype == \"Neurodivergent\" & across(c(physical_chronic, mental_health, disability_nos), ~ .x == \"None\") ~ \"Neurodivergent\",\n      \n      # Combine the neurotypical conditions into one line for clarity\n      neurotype == \"Neurotypical\" & (physical_chronic != \"None\" | mental_health != \"None\" | disability_nos != \"None\") ~ \"Disabled\",\n      \n      # Simplify the multiple conditions check by using any() to check if any of the conditions are met\n      neurotype == \"Neurodivergent\" & any(c(mental_health, physical_chronic, disability_nos) != \"None\") ~ \"NDD\",\n      \n      # Default condition remains the same\n      TRUE ~ \"Neurotypical & non-disabled\"\n    )\n  )\n\n\nGemini’s code worked but recoded the data incorrectly\n\n\n# gemini\ngemini_dat_disability_recode &lt;- dat_na_replaced %&gt;%\n  mutate(\n    disability = case_when(\n      neurotype == \"Neurodivergent\" & physical_chronic == \"None\" & mental_health == \"None\" & disability_nos == \"None\" ~ \"Neurodivergent\",\n      neurotype == \"Neurotypical\" & (physical_chronic %in% c(\"Physical, mobility, or chronic health condition\", \"Mental health condition\") | disability_nos == \"Disability not otherwise specified\") ~ \"Disabled\",\n      # Breakdown of long condition\n      (neurotype == \"Neurodivergent\" & !is.na(mental_health)) | (neurotype == \"Neurodivergent\" & !is.na(physical_chronic)) | (neurotype == \"Neurodivergent\" & disability_nos != \"None\") ~ \"NDD\",\n      TRUE ~ \"Neurotypical & non-disabled\"\n    )\n  )\n\ndat_disability_recode %&gt;% \n  count(disability)\n\n\n\n\ndisability\nn\n\n\n\nDisabled\n53\n\n\nNDD\n59\n\n\nNeurodivergent\n126\n\n\nNeurotypical & non-disabled\n72\n\n\n\n\n\ngemini_dat_disability_recode %&gt;% \n  count(disability)\n\n\n\n\ndisability\nn\n\n\n\nDisabled\n39\n\n\nNDD\n59\n\n\nNeurodivergent\n126\n\n\nNeurotypical & non-disabled\n86\n\n\n\n\n\n\n\nChatGPT’s actually worked, returned an identical object, and made the code more efficient.\n\n\n# chatGPT\n# Step 4: Recode disability data\nchat_dat_disability_recode &lt;- dat_na_replaced %&gt;%\n  mutate(\n    disability = case_when(\n      neurotype == \"Neurodivergent\" & physical_chronic == \"None\" & mental_health == \"None\" & disability_nos == \"None\" ~ \"Neurodivergent\",\n      neurotype == \"Neurotypical\" & (physical_chronic != \"None\" | mental_health != \"None\" | disability_nos != \"None\") ~ \"Disabled\",\n      neurotype == \"Neurodivergent\" | mental_health != \"None\" | physical_chronic != \"None\" | disability_nos != \"None\" ~ \"NDD\",\n      TRUE ~ \"Neurotypical & non-disabled\"\n    )\n  )\n\ndat_disability_recode %&gt;% \n  count(disability)\n\n\n\n\ndisability\nn\n\n\n\nDisabled\n53\n\n\nNDD\n59\n\n\nNeurodivergent\n126\n\n\nNeurotypical & non-disabled\n72\n\n\n\n\n\nchat_dat_disability_recode %&gt;% \n  count(disability)\n\n\n\n\ndisability\nn\n\n\n\nDisabled\n53\n\n\nNDD\n59\n\n\nNeurodivergent\n126\n\n\nNeurotypical & non-disabled\n72",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "05-review.html#alternative-approaches",
    "href": "05-review.html#alternative-approaches",
    "title": "\n5  Code review\n",
    "section": "\n5.7 Alternative approaches",
    "text": "5.7 Alternative approaches\nIn the PsyTeachR courses we strongly use the tidyverse approach but it’s useful to be aware of other approaches, particularly Base R given that it doesn’t require any package dependencies.\nYou can simply amend the prompt to say use Base R as an alternative:\n\nwhen refactoring, use Base R instead of tidyverse\n\n\nIt’s arguable whether it’s that much more efficient but ChatGPT’s output does indeed use Base R and did recode the variable correctly.\n\n\n# Step 4: Recode disability data\nchat_dat_disability_recode &lt;- transform(dat_na_replaced,\n                                  disability = ifelse(neurotype == \"Neurodivergent\" & physical_chronic == \"None\" & mental_health == \"None\" & disability_nos == \"None\", \"Neurodivergent\",\n                                                     ifelse(neurotype == \"Neurotypical\" & (physical_chronic != \"None\" | mental_health != \"None\" | disability_nos != \"None\"), \"Disabled\",\n                                                            ifelse(neurotype == \"Neurodivergent\" | mental_health != \"None\" | physical_chronic != \"None\" | disability_nos != \"None\", \"NDD\",\n                                                                   \"Neurotypical & non-disabled\"))))\n\n\ndat_disability_recode %&gt;% \n  count(disability)\n\n\n\n\ndisability\nn\n\n\n\nDisabled\n53\n\n\nNDD\n59\n\n\nNeurodivergent\n126\n\n\nNeurotypical & non-disabled\n72\n\n\n\n\n\nchat_dat_disability_recode %&gt;% \n  count(disability)\n\n\n\n\ndisability\nn\n\n\n\nDisabled\n53\n\n\nNDD\n59\n\n\nNeurodivergent\n126\n\n\nNeurotypical & non-disabled\n72\n\n\n\n\n\n\n\nGemini’s code did run but also managed to recode the variable from having four categories to two:\n\n\ngemini_dat_disability_recode &lt;- dat_na_replaced %&gt;%\n  mutate(\n    disability = ifelse(\n      neurotype == \"Neurodivergent\" & all(c(physical_chronic, mental_health, disability_nos) == \"None\"),\n      \"Neurodivergent\",\n      ifelse(\n        neurotype == \"Neurotypical\" & any(physical_chronic %in% c(\"Physical, mobility, or chronic health condition\", \"Mental health condition\"), disability_nos == \"Disability not otherwise specified\"),\n        \"Disabled\",\n        ifelse(\n          # Combined condition using logical OR ( | )\n          (neurotype == \"Neurodivergent\" & !is.na(mental_health)) | (neurotype == \"Neurodivergent\" & !is.na(physical_chronic)) | (neurotype == \"Neurodivergent\" & disability_nos != \"None\") |\n            (!is.na(mental_health) & !is.na(physical_chronic)) | (!is.na(mental_health) & disability_nos != \"None\") | (!is.na(physical_chronic) & disability_nos != \"None\"),\n          \"NDD\",\n          \"Neurotypical & non-disabled\"\n        )\n      )\n    )\n  )\n\ndat_disability_recode %&gt;% \n  count(disability)\n\n\n\n\ndisability\nn\n\n\n\nDisabled\n53\n\n\nNDD\n59\n\n\nNeurodivergent\n126\n\n\nNeurotypical & non-disabled\n72\n\n\n\n\n\ngemini_dat_disability_recode %&gt;% \n  count(disability)\n\n\n\n\ndisability\nn\n\n\n\nDisabled\n125\n\n\nNDD\n185\n\n\n\n\n\n\n\nCopilot’s ran and coded the data correctly although it definitely isn’t more concise. Although it does use Base R.\n\n\n# Step 4: Recode disability data using base R\ncopilot_dat_disability_recode &lt;- dat_na_replaced\ncopilot_dat_disability_recode$disability &lt;- with(dat_na_replaced, ifelse(\n  neurotype == \"Neurodivergent\" & physical_chronic == \"None\" & mental_health == \"None\" & disability_nos == \"None\", \"Neurodivergent\",\n  ifelse(neurotype == \"Neurotypical\" & (physical_chronic == \"Physical, mobility, or chronic health condition\" | mental_health == \"Mental health condition\" | disability_nos == \"Disability not otherwise specified\"), \"Disabled\",\n  ifelse((neurotype == \"Neurodivergent\" & mental_health != \"None\") | (neurotype == \"Neurodivergent\" & physical_chronic != \"None\") | (neurotype == \"Neurodivergent\" & disability_nos != \"None\") | (mental_health != \"None\" & physical_chronic != \"None\") | (mental_health != \"None\" & disability_nos != \"None\") | (physical_chronic != \"None\" & disability_nos != \"None\"), \"NDD\",\n  \"Neurotypical & non-disabled\"\n))))\n\ndat_disability_recode %&gt;% \n  count(disability)\n\n\n\n\ndisability\nn\n\n\n\nDisabled\n53\n\n\nNDD\n59\n\n\nNeurodivergent\n126\n\n\nNeurotypical & non-disabled\n72\n\n\n\n\n\ncopilot_dat_disability_recode %&gt;% \n  count(disability)\n\n\n\n\ndisability\nn\n\n\n\nDisabled\n53\n\n\nNDD\n59\n\n\nNeurodivergent\n126\n\n\nNeurotypical & non-disabled\n72",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "05-review.html#conclusions",
    "href": "05-review.html#conclusions",
    "title": "\n5  Code review\n",
    "section": "\n5.8 Conclusions",
    "text": "5.8 Conclusions\nI hadn’t actually used AI to perform these types of tasks before writing this book so here’s my takeaways:\n\nCHECK EVERYTHING.\nIf you give an AI code, you simply cannot trust that it won’t change your code, even if that’s not the task you ask it to do. If you use AI to add or review comments, you must check the output. Tools like all.equal() can help perform these checks.\nYou also can’t trust that the comments will be accurate. Anything an AI writes must be checked before you use it. If you don’t know if it’s right, don’t use it.\nBecause you have to check what it does so carefully, don’t give it a big dump of code. Smaller chunks will end up taking less time.\nIn some cases it was really useful and as someone who doesn’t really use or know much Base R, I can see that this would be a great way to learn alternative approaches or to fill in comments.\nThat said, the amount of checking it takes is substantial and so I’m not completely convinced that it would be any quicker than doing it yourself.\nThey all struggled at different points although I think Of the three, Gemini was the clear loser of this chapter, which is a shame as I was starting to like it.\n\n\n\n\n\n\n\nCaution\n\n\n\nThis book should be considered a living document and is likely to change over time. Given the brave new world in which we now live, all constructive feedback and suggestions are welcome! If you have any feedback or suggestions, please provide it via Forms.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "06-writing.html",
    "href": "06-writing.html",
    "title": "\n6  Writing Code with AI\n",
    "section": "",
    "text": "6.1 Activity 1: Set-up\nAgain we’ll use the palmerpenguins dataset for this exercise so open up an Rmd and run the following:\nlibrary(tidyverse)\nlibrary(palmerpenguins)\ndata(\"penguins\")\nWe’ll also do a little bit of set-up for the AI:",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "06-writing.html#activity-1-set-up",
    "href": "06-writing.html#activity-1-set-up",
    "title": "\n6  Writing Code with AI\n",
    "section": "",
    "text": "Act like an expert programmer in R. I want you to help me write code. The code should be commented and should use the tidyverse where possible. Ask me questions about the code before you write it if necessary.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "06-writing.html#activity-2-knowledge-is-power",
    "href": "06-writing.html#activity-2-knowledge-is-power",
    "title": "\n6  Writing Code with AI\n",
    "section": "\n6.2 Activity 2: Knowledge is power",
    "text": "6.2 Activity 2: Knowledge is power\nWhen you input this starting prompt, there’s a good chance you’ll get something like the following:\n\n\n\n\nMore info needed\n\n\n\nBefore you ask the AI to write code, it’s helpful to give it as much information as you can about your dataset. You could write out a description manually but there’s a few options to automate.\nsummary() is useful because it provides a list of all variables with some descriptive statistics so that the AI has a sense of the type and range of data:\n\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2                                 \n\n\nstr() is also useful because it lists the variables, their data type, and the initial values for each variable. However, that means that you are giving it at least some of the raw data so you have to be very careful if you have sensitive / confidential data and you must ensure that any use of AI is in line with your data management plan. Using Copilot Enterprise means the data won’t be stored and used to train the AI further so it’s potentially the best option (which is not to say it’s safe or problem free, please be careful and critical!).\nFinally, ls() provides a list of all the variables in a given object. It doesn’t provide any info on the variable type or sample, but that does mean it’s the most secure and depending on the task, this might be all the info you really need to give the AI. I would suggest starting with ls() and only scaling up if necessary (and your data isn’t sensitive):\n\nls(penguins)\n\n[1] \"bill_depth_mm\"     \"bill_length_mm\"    \"body_mass_g\"      \n[4] \"flipper_length_mm\" \"island\"            \"sex\"              \n[7] \"species\"           \"year\"             \n\n\nIn your AI of choice, input the following:\n\nhere are the variables in my data set\n\n\nls(penguins) [1] “bill_depth_mm” “bill_length_mm” “body_mass_g” “flipper_length_mm” [5] “island” “sex” “species” “year”\n\nWithout being asked, Copilot has provided some examples of how you might analyse this data using R and the code all works as intended.\n\n# Load the tidyverse package\nlibrary(tidyverse)\n\n# Assuming your data is in a dataframe called 'penguins'\n# Let's start by getting a summary of each numerical variable\npenguins %&gt;%\n  summarise(\n    Average_Bill_Depth = mean(bill_depth_mm, na.rm = TRUE),\n    Average_Bill_Length = mean(bill_length_mm, na.rm = TRUE),\n    Average_Body_Mass = mean(body_mass_g, na.rm = TRUE),\n    Average_Flipper_Length = mean(flipper_length_mm, na.rm = TRUE)\n  )\n\n\n\n\n\n\n\n\n\n\nAverage_Bill_Depth\nAverage_Bill_Length\nAverage_Body_Mass\nAverage_Flipper_Length\n\n\n17.15117\n43.92193\n4201.754\n200.9152\n\n\n\n\n# Now, let's see the distribution of species across different islands\npenguins %&gt;%\n  count(island, species) %&gt;%\n  ggplot(aes(x = island, y = n, fill = species)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Distribution of Penguin Species Across Islands\",\n       x = \"Island\",\n       y = \"Count\")\n\n\n\n\n\n\n# We can also explore the relationship between flipper length and body mass\npenguins %&gt;%\n  ggplot(aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point(aes(color = species)) +\n  geom_smooth(method = \"lm\") +\n  labs(title = \"Relationship Between Flipper Length and Body Mass\",\n       x = \"Flipper Length (mm)\",\n       y = \"Body Mass (g)\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n# If you want to perform more specific analyses or visualizations,\n# please let me know what you're interested in!\n\nI find this problematic in ways I struggle to properly articulate. As a psychologist, we’ve spent the last decade dealing with a replication and reproducibility crisis stemming in part because of questionable research practices. As a researcher, you should be making informed decisions as to how you analyse your data and I fear that this type of output is going to increase phishing and atheoretical, exploratory-as-confirmatory nonsense. What happens when the example code the AI spits out without being asked turns out to be a significant regression model that you would never have predicted or run yourself? Are you going to delete it? Or convince yourself that you were going to run it anyway and there’s a perfectly logical explanation?\nBefore I have a full blown existential crisis, let’s get back on track.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "06-writing.html#activity-3-writing-code",
    "href": "06-writing.html#activity-3-writing-code",
    "title": "\n6  Writing Code with AI\n",
    "section": "\n6.3 Activity 3: Writing code",
    "text": "6.3 Activity 3: Writing code\nFirst, we’ll aim to produce a table of descriptive statistics for body_mass_g and a histogram. Because it has the exact variable and object names, it should write code we can easily copy and paste:\n\nCreate a table of descriptive statistics for body mass and a histogram of that variable\n\nThis is ChatGPT’s output (Copilot was very similar):\n\n# Load the tidyverse package\nlibrary(tidyverse)\n\n# Load the penguins dataset (assuming it's from the palmerpenguins package)\ndata(\"penguins\")\n\n# Check the structure of the dataset\nstr(penguins)\n\ntibble [344 × 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n# Summary statistics for body mass\nbody_mass_summary &lt;- penguins %&gt;%\n  summarise(\n    Mean = mean(body_mass_g, na.rm = TRUE),\n    Median = median(body_mass_g, na.rm = TRUE),\n    SD = sd(body_mass_g, na.rm = TRUE),\n    Min = min(body_mass_g, na.rm = TRUE),\n    Max = max(body_mass_g, na.rm = TRUE)\n  )\n\n# Print the summary statistics\nprint(body_mass_summary)\n\n# A tibble: 1 × 5\n   Mean Median    SD   Min   Max\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt;\n1 4202.   4050  802.  2700  6300\n\n# Create a histogram of body mass\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(fill = \"skyblue\", color = \"black\", bins = 20) +\n  labs(\n    title = \"Distribution of Body Mass\",\n    x = \"Body Mass (g)\",\n    y = \"Frequency\"\n  ) +\n  theme_minimal()\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\nSome notes:\n\nI didn’t have to use the exact variable name body_mass_g, it has figured out from my request that’s the one I want to use.\nIt’s also figured out that we’re using the palmerpenguins dataset, although it hasn’t given us the code to load that package so if we just copied and pasted this into a fresh script without having loaded the data already, it wouldn’t work.\nIt’s used na.rm = TRUE to ignore missing values. This is a very common choice but remember it is a choice. You might not want this.\nSimilarly, it’s specified binwidth = 20 for the histogram. Looking at the data this seems like a reasonable binwidth to use, but again, it is a decision the AI has imposed and you must be aware of what you’re accepting.\nI am aware that I am using phrases like “choice” and “decision” that imbue the AI with consciousness. I know that’s not true, I just can’t figure out how to write it any other way.\n\nChatGPT and Copilot both worked well. Gemini on the other hand… had a bit of a moment. First, it told me that it couldn’t complete the request so I amended the variable name, thinking that perhaps it needed the exact name. It then produced a table rather than giving me the code. The numbers in this table look like plausible values for this dataset (although don’t match exactly) so I suspect it has information about the palmerpenguins dataset.\n\n\n\n\nGemini missing the mark\n\n\n\nThe issue is that I didn’t tell it to write me code -I told it to create a table which is did, although it’s interesting that both Copilot and ChatGPT understood the intent of my prompt and Gemini did not.\nI then edited my prompt:\n\nWrite code to create a table of descriptive statistics for body_mass_g and a histogram of that variable\n\nAnd it responded by giving me python code. Again, not technically wrong given the prompt but it does mean that it is ignoring the rest of the conversation and the initial set-up prompt. Following up to ask specifically for R code worked, but it’s not a good start for Gemini.\n\n\n\n\nGemini going rogue",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "06-writing.html#activity-4-giving-the-ai-more-freedom",
    "href": "06-writing.html#activity-4-giving-the-ai-more-freedom",
    "title": "\n6  Writing Code with AI\n",
    "section": "\n6.4 Activity 4: Giving the AI more freedom",
    "text": "6.4 Activity 4: Giving the AI more freedom\nMy initial request to write code was relatively simple and relatively well-specified but let’s try an example where there’s more room for the AI to make choices.\n\nCreate a new variable that codes each penguin as chonky_boi if they’re a large male, chonky_gurl if they’re a large female, smol_boi if they’re a small male, and smol_boi if they’re a small female.\n\nThis prompt gives a lot of leeway. I haven’t specified what to call the new variable, what criteria should be used to determine large and small, or what to do with observations that are neither.\nChatGPT used percentiles to determine category, however, this code didn’t work - it returns all observations as “average”:\n\n# Create a new variable based on conditions\npenguins &lt;- penguins %&gt;%\n  mutate(chonkiness = case_when(\n    sex == \"Male\" & body_mass_g &gt; quantile(body_mass_g, 0.75, na.rm = TRUE) ~ \"chonky_boi\",\n    sex == \"Female\" & body_mass_g &gt; quantile(body_mass_g, 0.75, na.rm = TRUE) ~ \"chonky_gurl\",\n    sex == \"Male\" & body_mass_g &lt;= quantile(body_mass_g, 0.25, na.rm = TRUE) ~ \"smol_boi\",\n    sex == \"Female\" & body_mass_g &lt;= quantile(body_mass_g, 0.25, na.rm = TRUE) ~ \"smol_gurl\",\n    TRUE ~ \"average\"\n  ))\n\n\nIn this code:\n\n\nWe use the case_when() function to define the conditions based on sex and body mass to categorize the penguins.\n\n\nFor males with a body mass greater than the 75th percentile, they are categorized as “chonky_boi.” For females with a body mass greater than the 75th percentile, they are categorized as “chonky_gurl.”\n\n\nFor males with a body mass less than or equal to the 25th percentile, they are categorized as “smol_boi.” For females with a body mass less than or equal to the 25th percentile, they are also categorized as “smol_gurl.”\n\n\nAll other penguins are categorized as “average.”\n\n\nWe then use mutate() to create the new variable “chonkiness” based on these conditions.\n\nI will spare you the full adventure (my chat history is here if you’d like to see) but after quite a bit of back-and-forth I realised that in the dataset “male” and “female” should both be lowercase and the code ChatGPT gave me had capitalised them both. There is no substitute for knowing your data.\nOnce I changed this, it worked.\n\n# Create a new variable based on conditions\npenguins &lt;- penguins %&gt;%\n  mutate(chonkiness = case_when(\n    sex == \"male\" & body_mass_g &gt; quantile(body_mass_g, 0.75, na.rm = TRUE) ~ \"chonky_boi\",\n    sex == \"female\" & body_mass_g &gt; quantile(body_mass_g, 0.75, na.rm = TRUE) ~ \"chonky_gurl\",\n    sex == \"male\" & body_mass_g &lt;= quantile(body_mass_g, 0.25, na.rm = TRUE) ~ \"smol_boi\",\n    sex == \"female\" & body_mass_g &lt;= quantile(body_mass_g, 0.25, na.rm = TRUE) ~ \"smol_gurl\",\n    TRUE ~ \"average\"\n  ))\n\nCopilot used a median split and didn’t try and create a third category, which is a questionable choice because the wording of the prompt really implies there needs to be something that the penguins are larger or smaller than. The code did work out of the box but remember the Jurassic Park rule: just because you can, doesn’t mean you should.\n\n# Assuming 'penguins' is your dataframe and 'body_mass_g' is the variable for body mass\n# First, we need to define what we consider 'large' and 'small'. \n# For this example, let's assume penguins heavier than the median are 'large', \n# and those equal or lighter are 'small'.\n\n# Calculate the median body mass\nmedian_body_mass &lt;- median(penguins$body_mass_g, na.rm = TRUE)\n\n# Create the new variable 'size_category'\npenguins &lt;- penguins %&gt;%\n  mutate(size_category = case_when(\n    body_mass_g &gt; median_body_mass & sex == \"male\"   ~ \"chonky_boi\",\n    body_mass_g &gt; median_body_mass & sex == \"female\" ~ \"chonky_gurl\",\n    body_mass_g &lt;= median_body_mass & sex == \"male\"   ~ \"smol_boi\",\n    body_mass_g &lt;= median_body_mass & sex == \"female\" ~ \"smol_gurl\",\n    TRUE ~ NA_character_  # for missing or other values\n  ))\n\nThis code is a good example of why LLMs are inherently Luddites, even if they produce working code. When there’s missing data, case_when() used to need you to specify the type of NA, ni this case NA_character. This is very uninintuitive, particularly when you’re trying to teach beginner coders (how can missing data have a type? is an entirely reasonable question) so I was delighted when it updated to remove this requirement. Additionally, TRUE was also changed to default which is a bit more readable.\nHowever, these changes are not reflected in Copilot’s code suggestion because the training data is older than the most recent update to case_when(). This example is relatively minor but it’s important to recognise that if you only use these kinds of AI to write code, you will very quickly be writing outdated code and using deprecated functions.\nGemini once again told me it could not complete my request and I have given up using it for the remainder of this chapter.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "06-writing.html#activity-5-further-analysis",
    "href": "06-writing.html#activity-5-further-analysis",
    "title": "\n6  Writing Code with AI\n",
    "section": "\n6.5 Activity 5: Further analysis",
    "text": "6.5 Activity 5: Further analysis\nTo give one last example, I entered the following prompt:\n\nwrite me code to run a linear regression predicting body mass from sex. also include the code to perform necessary assumption tests using the easystats performance package.\n\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n# Load the penguins dataset\ndata(\"penguins\")\n\n# Filter out rows with missing values in body mass or sex\npenguins &lt;- penguins %&gt;%\n  filter(!is.na(body_mass_g) & !is.na(sex))\n\n# Convert sex to lowercase\npenguins$sex &lt;- tolower(penguins$sex)\n\n# Run linear regression predicting body mass from sex\nlm_model &lt;- lm(body_mass_g ~ sex, data = penguins)\n\n# Display summary of the linear regression model\nsummary(lm_model)\n\n\nCall:\nlm(formula = body_mass_g ~ sex, data = penguins)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1295.7  -595.7  -237.3   737.7  1754.3 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3862.27      56.83  67.963  &lt; 2e-16 ***\nsexmale       683.41      80.01   8.542  4.9e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 730 on 331 degrees of freedom\nMultiple R-squared:  0.1806,    Adjusted R-squared:  0.1781 \nF-statistic: 72.96 on 1 and 331 DF,  p-value: 4.897e-16\n\n# Perform assumption tests using the performance package\ncheck_assumptions(lm_model)\n\nError in check_assumptions(lm_model): could not find function \"check_assumptions\"\n\n\nChatGPT refuses to forget that in my conversation history there was an issue with the code not being lowercase, so it’s now including functions to covert to lowercase, even though it’s completely unnecessary.\nIt’s also introduced an error. The function should be check_model() not check_assumptions(). I know this because I know the package. The further away you get from what you could do yourself, the harder it will be to fix any errors and check what it has gotten wrong.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "06-writing.html#conclusions-and-musings",
    "href": "06-writing.html#conclusions-and-musings",
    "title": "\n6  Writing Code with AI\n",
    "section": "\n6.6 Conclusions and musings",
    "text": "6.6 Conclusions and musings\nA large part of coding is looking up examples of code you’ve used before and then tweaking it to your new use case. If you use AI like this, then it can really help speed you up by giving you access to a lot more boiler plate code you can adapt. I also find it very useful for those functions that just refuse to stick in my brain - every time I try to change the labels on a faceted ggplot() I get it wrong. These days I just go straight to ChatGPT.\nAdditionally, if what you’re wanting to achieve is relatively simple - descriptive stats, basic plots, simple wrangling and cleaning - it can’t go that far wrong and it’s usually easy enough to spot when something is wrong.\nThese use cases work well because it’s your expertise that drives what the AI does and reviewing and tweaking the output is built-in to these workflows. These are the AI skills that everyone is going to need.\nBut using code written by an AI that you don’t understand is dangerous and irresponsible. Think of all the stupid errors it has made throughout this book, and then imagine someone using it to write code for their medical research. I dread to think of the impact that this abdication of responsibility and expertise is going to have (and will already be having).\nThis is a depressing way to end this book so I gave all three AIs the prompt:\n\nWrite me a fun piece of R code.\n\nChatGPT reassuring me comedy isn’t going to be outsourced any time soon:\n\n# Function to generate a random joke\ngenerate_joke &lt;- function() {\n  jokes &lt;- c(\n    \"Why don't scientists trust atoms? Because they make up everything!\",\n    \"I told my wife she was drawing her eyebrows too high. She looked surprised!\",\n    \"Why did the scarecrow win an award? Because he was outstanding in his field!\",\n    \"Why don't skeletons fight each other? They don't have the guts!\",\n    \"I'm reading a book on anti-gravity. It's impossible to put down!\"\n  )\n  return(sample(jokes, 1))\n}\n\n# Generate and print a random joke\ncat(\"Here's a random joke for you:\\n\")\n\nHere's a random joke for you:\n\ncat(generate_joke(), \"\\n\")\n\nWhy don't scientists trust atoms? Because they make up everything! \n\n\nChatGPT reassuring me art isn’t going to be outsourced any time soon:\n\n# Define a list of ASCII art characters\nart_chars &lt;- c(\"#\", \"%\", \"@\", \"&\", \"$\", \"*\")\n\n# Function to generate a random character\nget_art_char &lt;- function() {\n  return(sample(art_chars, 1))\n}\n\n# Set picture dimensions (width and height)\npicture_width &lt;- 50\npicture_height &lt;- 20\n\n# Create an empty matrix to store the picture\nart_matrix &lt;- matrix(nrow = picture_height, ncol = picture_width)\n\n# Fill the matrix with random characters\nfor (i in 1:picture_height) {\n  for (j in 1:picture_width) {\n    art_matrix[i, j] &lt;- get_art_char()\n  }\n}\n\n# Convert the matrix to a string for printing\nart_string &lt;- apply(art_matrix, 1, FUN = paste, collapse = \"\")\nart_string &lt;- paste(art_string, collapse = \"\\n\")\n\n# Print the ASCII art picture\ncat(\"Your random ASCII art:\", art_string, sep = \"\\n\")\n\nYour random ASCII art:\n$$&@$#@#*&%**@@$*%%#%#%%*$&@*%$%$#&@&$*%#@*#%%$&#$\n@@%&@##@*#@$&$$***#@@**$@&%$%##%#%$**$@%*%&@$@**$&\n*&%$*$%@#@%@&$@&#&**$*%%&*&@@&*@%#*@**&@%@&$$#&**@\n@#&%##$@#*%%*#&&*&%%*#*#&*$&@@*##&#@#&$#%%$$$&$###\n@*#%%#%@%%%$&&&@$%#%@*%%@$@*$&&%@#&%%#$&&$@&$&%@#%\n*#$#%#&@$**%$#*#%#@&%$@*##*@@#@&#@$&@#$&%*@#&$&&#%\n#$@%**#$*$####&&&&@&@&*&%%@%$$#@#@$*#%&**$##@$&@#$\n&*#$@$*@&*$@**$#$@&&*&%*#%#@%*@%@%*&#$&%&@#&#%#*#$\n@$#**%##*%#&&@*%@#@*##*%&&*$*%%*&#%&$#&&%&%$#@@&$@\n&@#&@*##@$**&*##%%*$##%%@&**$#@@%@%@@&#$@&#%@%&$@@\n#$%$$$**#$@#%#&&%#&@$##@$#&&*%$%%$#%*&$%&$*#@@#%@*\n%*&*&$@*%&&%*##@*#&&%@&@$*&@*#$$##@@*$$$&#@*$%@%*$\n@&$%#*&#*&%**%*%@&%#*&#$@$&*##*#%$#%&%@%%*&$@***&&\n%$$@$%$&%@$@$&$#%%$@%%*#*&$@@$#&&%&&%##%$%&$&#%#$$\n$#$%%%*@$@#%**%%@&&@%*&%&*##%@#**$&@&%$#$$#*@#$%&#\n##%@$@&&&$@@%*&*&#*#@##&&*&@$%*&%%%@*#&**%&%*&%$$$\n@*&@&*%**##@*@&*@@%%&$$*@#%*#$$&*&$***@&&@%@&#@@$@\n@@@&*%&*@&&##$*&#@*%%##*%$@#@&**&%#&#@@@$#&*&#&@*&\n&@@#%%$##@&@&@#&#&%@%%%*@&%$%%@*$$&@%%%$@@#&#&*@@$\n$$#&&%$@&%%$#%%#&*@*$%%$&%&@@#%#%&$*&#&&%%$&%**#&@\n\n\nCopilot on its way to Vegas (ok I actually quite like this one):\n\n# Simple Slot Machine in R\nset.seed(Sys.time()) # Seed for randomness based on current time\n\n# Function to spin the slot machine\nspin_slot_machine &lt;- function() {\n  fruits &lt;- c(\"🍒\", \"🍋\", \"🍊\", \"🍉\", \"🍇\", \"🍓\")\n  spin &lt;- sample(fruits, size = 3, replace = TRUE)\n  cat(\"Spinning... You got:\", spin, \"\\n\")\n  \n  if (length(unique(spin)) == 1) {\n    cat(\"Congratulations! You won! 🎉\\n\")\n  } else {\n    cat(\"Try again! 🍀\\n\")\n  }\n}\n\n# Spin the slot machine\nspin_slot_machine()\n\nSpinning... You got: 🍊 🍒 🍓 \nTry again! 🍀\n\n\n\n\n\n\n\n\nCaution\n\n\n\nThis book should be considered a living document and is likely to change over time. Given the brave new world in which we now live, all constructive feedback and suggestions are welcome! If you have any feedback or suggestions, please provide it via Forms.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "webexercises.html",
    "href": "webexercises.html",
    "title": "Appendix A — Webexercises",
    "section": "",
    "text": "A.1 Example Questions",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Webexercises</span>"
    ]
  },
  {
    "objectID": "webexercises.html#example-questions",
    "href": "webexercises.html#example-questions",
    "title": "Appendix A — Webexercises",
    "section": "",
    "text": "A.1.1 Fill-In-The-Blanks (fitb())\nCreate fill-in-the-blank questions using fitb(), providing the answer as the first argument.\n\n2 + 2 is \n\n\nYou can also create these questions dynamically, using variables from your R session.\n\nThe square root of 25 is: \n\n\nThe blanks are case-sensitive; if you don’t care about case, use the argument ignore_case = TRUE.\n\nWhat is the letter after D? \n\n\nIf you want to ignore differences in whitespace use, use the argument ignore_ws = TRUE (which is the default) and include spaces in your answer anywhere they could be acceptable.\n\nHow do you load the tidyverse package? \n\n\nYou can set more than one possible correct answer by setting the answers as a vector.\n\nType a vowel: \n\n\nYou can use regular expressions to test answers against more complex rules.\n\nType any 3 letters: \n\n\nA.1.2 Multiple Choice (mcq())\n\n“Never gonna give you up, never gonna: \nlet you go\nturn you down\nrun away\nlet you down”\n“I \nbless the rains\nguess it rains\nsense the rain down in Africa” -Toto\n\nA.1.3 True or False (torf())\n\nTrue or False? You can permute values in a vector using sample(). \nTRUE\nFALSE\n\n\nA.1.4 Longer MCQs (longmcq())\nWhen your answers are very long, sometimes a drop-down select box gets formatted oddly. You can use longmcq() to deal with this. Since the answers are long, It’s probably best to set up the options inside an R chunk with echo=FALSE.\nWhat is a p-value?\n\nthe probability that the null hypothesis is truethe probability of the observed, or more extreme, data, under the assumption that the null-hypothesis is truethe probability of making an error in your conclusion\n\nWhat is true about a 95% confidence interval of the mean?\n\nthere is a 95% probability that the true mean lies within this rangeif you repeated the process many times, 95% of intervals calculated in this way contain the true mean95% of the data fall within this range",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Webexercises</span>"
    ]
  },
  {
    "objectID": "webexercises.html#checked-sections",
    "href": "webexercises.html#checked-sections",
    "title": "Appendix A — Webexercises",
    "section": "\nA.2 Checked sections",
    "text": "A.2 Checked sections\nCreate sections with the class webex-check to add a button that hides feedback until it is pressed. Add the class webex-box to draw a box around the section (or use your own styles).\n\nI am going to learn a lot: \nTRUE\nFALSE\nWhat is a p-value?\n\nthe probability that the null hypothesis is truethe probability of the observed, or more extreme, data, under the assumption that the null-hypothesis is truethe probability of making an error in your conclusion",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Webexercises</span>"
    ]
  },
  {
    "objectID": "webexercises.html#hidden-solutions-and-hints",
    "href": "webexercises.html#hidden-solutions-and-hints",
    "title": "Appendix A — Webexercises",
    "section": "\nA.3 Hidden solutions and hints",
    "text": "A.3 Hidden solutions and hints\nYou can fence off a solution area that will be hidden behind a button using hide() before the solution and unhide() after, each as inline R code. Pass the text you want to appear on the button to the hide() function.\nIf the solution is a code chunk, instead of using hide() and unhide(), simply set the webex.hide chunk option to TRUE, or set it to the string you wish to display on the button.\nRecreate the scatterplot below, using the built-in cars dataset.\n\n\n\n\n\n\n\n\n\n\nI need a hint\n\nSee the documentation for plot() (?plot)\n\n\n\n\n\nClick here to see the solution\n\nplot(cars$speed, cars$dist)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Webexercises</span>"
    ]
  }
]