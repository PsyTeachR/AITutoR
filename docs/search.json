[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AI TutoR",
    "section": "",
    "text": "Overview\nThis book aims to teach students how to use AI to support their learning journey. The philosophy of this book is firmly rooted in the cognitive science of learning and as such, retrieval practice, distributed practice, and elaboration will all play a key role.\nIt is perhaps easier to start by explaining what this book is not:\n\nThis book is not a stand-alone resource. It is intended to be used alongside other course materials. To make the most out of this book, you will need things like Intended Learning Outcomes or key terms.\nThis book will not encourage learners to take short-cuts. That students should be able to understanding the principles of what they are learning and to critically evaluate writing on the topic, regardless of who or what wrote it, is non-negotiable.\nThis book is not an endorsement of AI nor is it uncritical of its impact, either on learning or the environment. It is written because we have thousands of student using AI in a way that damages their learning and I do not believe that preaching abstinence is an effective solution. Others csn, and do, disagree.\nFor the coding aspects of this book, we will not not teach you how to use platforms like Github Copilot and it is not aimed at proficient or advanced programmers.\n\nInstead, this book will aim to help learners use AI platforms critically. By the end of this book, learners should be able to:\n\nExplain the potential impact of relying on AI on cognition, autonomy, and self-efficacy.\nUse AI to explain concepts and functions in a level of detail and technicality appropriate to the knowledge and skill of the learner\nUse AI to generate practice questions to test understanding\nUse AI to debug errors in code\nUse AI to review, comments, and refactor code\nUse AI to responsibly assist with writing code\nCritically evaluate and appraise the output of AI\n\n\n\n\n\n\n\nCaution\n\n\n\nThis book was first written in Spring 2024 (and is currently being updated in September 2025) and should be considered a living document. The functionality and capability of AI is changing rapidly and the most recent advances may not reflect what is described in this book.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "01-intro.html",
    "href": "01-intro.html",
    "title": "\n1  Intro to using AI\n",
    "section": "",
    "text": "1.1 A brief introduction\nThere are a range of AIs and an even larger number of niche apps and platforms but we’re going to focus on Microsoft’s Copilot signed in via your UofG account. The reason we’ve chosen Copilot is that all University of Glasgow students have access to the same plan and functionality. The UofG Copilot also has enhanced security, which is particularly important when you’re considering using AI to help with data analysis.\nSince 2024, generative AI tools have become embedded in most productivity software (Word, Excel, PowerPoint, Teams, Google Workspace, Adobe Creative Suite). Whilst this book uses Copilot, you should expect to see AI features in many of the tools you already use.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "01-intro.html#a-brief-introduction",
    "href": "01-intro.html#a-brief-introduction",
    "title": "\n1  Intro to using AI\n",
    "section": "",
    "text": "1.1.1 AI model vs AI platforms\nThere are more qualified people who can explain AI better than I, but a brief but important distinction is between the AI model and the AI platform. The underlying AI model is a Large Language Model (LLM) that essentially does extremely sophisticated predictive text - it’s not thinking, it’s not conscious, it just is very good at deciding what word is likely to come after another word in a way that is human-like.\nDifferent software companies have created different AI models. OpenAI has a series of models it refers to as Generative Pre-trained Transformers (GPTs). The explosion in AI in terms of public awareness came about when OpenAI released GPT version 3 and at the time of writing, the most recent is GPT-5. The capability of each successive AI is claimed to increase significantly, both in terms of its ability (e.g., to pass standardised tests) and in the human-ness of its responses. In addition to GPT-5, other widely used models include Claude 3.5 (Anthropic), Gemini 1.5 (Google/DeepMind), and LLaMA 3 (Meta). Different platforms may give slightly different results because they are tuned differently.\nUnlike earlier versions, most current models are multimodal by default: they can process text, images, and in some cases audio and video. Copilot inherits some of this, for example analysing images or diagrams when pasted in.\nIn some cases, the name of the model and the name of the platform you use are the same. ChatGPT is the name of the platform, but the underlying model it uses is GPT5. Additionally, other companies and apps can licence use of the models so Microsoft’s Copilot also uses GPT5.\nIt isn’t necessary that you understand all of this in detail. The key thing is that the underlying model is the same for some platforms (so you should expect similar capabilities) and that this model can and will update.\n\n1.1.2 Ethics and AI\nIt’s beyond the scope of this book (and my expertise) to go into much detail about the ethics of AI but I want to acknowledge that in several ways, they’re hugely problematic.\nFirst, and most importantly, AIs are trained on huge corpora of human language. Humans are full of bias and prejudice and consequently, so are our offspring AIs who have been repeatedly found to encode sexist, racist, and abelist views in their outputs.\n\nTeaching AI Ethics: Bias and Discrimination\n\nSecond, many of the developers that have produced AI models have done so behind closed doors and are very secretive about exactly what data the models have been trained on. One of the reasons for this is because it is very clearly apparent that many AI models have been given access to copyrighted sources (e.g., books and film scripts) and there are an increasing number of lawsuits being filed although it remains unclear what the future holds given how far and how fast the horse has already bolted.\n\nAI Infringement Case Updates\n\nThird, whilst the use of AI has been touted as a solution to help us manage climate change, it’s also a direct contributor to the problem because of the energy demands.\n\nExplained: Generative AI’s environmental impact\n\nFourth, training and moderation often rely on hidden human labour. Low-paid workers, often in the Global South, are employed to filter harmful content or annotate data. This raises ethical questions about labour exploitation.\n\nHow We Investigated the Human Labor Behind AI\n\nRegulation is catching up: the EU AI Act will begin to take effect in 2025, and the UK is consulting on its own frameworks. This means that how we are expected to use AI responsibly may change rapidly. AI Now 2025 Report provides an annual overview of social, ethical, and political issues in AI.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "01-intro.html#ai-platforms",
    "href": "01-intro.html#ai-platforms",
    "title": "\n1  Intro to using AI\n",
    "section": "\n1.2 AI platforms",
    "text": "1.2 AI platforms\n\n1.2.1 ChatGPT\nYou can sign-up for ChatGPT at https://chat.openai.com/. The free version uses 4o although there are limits on how many messagfes you can send in a certain time period and it is sometimes unavailable. When this happens, it will revert to 3.5. The free version is very fast and for beginner level courses does perform quite well. I’ve also found that ChatGPT is good at understanding the intent of what I want. ChatGPT also makes it easy to save your chat history so that you can continue working in previous chats at a later date. A useful feature is the “regenerate” function whereby if you’re not completely happy with the response, you can quickly ask it to generate another attempt and compare them. ChatGPT has a mobile app and allows you to share links to saved chats.\nThe disadvantages of ChatGPT are that it has limited internet connectivity and the information in its database will be restricted. At the time of writing this book, ChatGPT’s training data extends until January 2022, so it can’t tell you about anything that happened after that point (regardless of whether that’s world event or a new R function). Whilst it does depend on which version you’re using, it rarely gives you links to sources for where it has found the information.\n\n\n\n\nusing ChatGPT\n\n\n\n\n1.2.2 Copilot\nMicrosoft Copilot can be accessed at https://copilot.microsoft.com/ and you can sign-in with your Microsoft Account. If you are a University of Glasgow student (and also at many other universities), you can access Copilot through your university account and your Office365 subscription. If you do so, you’ll be able to access the Enterprise version of Copilot. The advantage of using your Enterprise account is that the data is processed more securely and what you input won’t be used to train the model. The price you pay for this security - and it’s such a big price that I don’t use it much for this reason - is that it doesn’t save your chat history so you start each time afresh. If you use a personal account, it will save your chat history, but also use your data to train the model.\nHowever, where Copilot shines is that it has access to the internet and will give you links to where it got its information so it’s easier to verify the output than ChatGPT. Additionally, they don’t make this clear but if you select the conversation style to be “Creative”, it will use GPT4.0.\nI have found that Copilot more frequently doesn’t understand the intent of what I am asking and with the same prompt as ChatGPT will give me a useless answer, but let’s see how I feel about that by the end of writing this book.\nMy general approach is that if I want to be able to return to my conversation, I use ChatGPT and if I want links to sources, I use Copilot.\n\n\n\n\nusing ChatGPT",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "01-intro.html#activity-1",
    "href": "01-intro.html#activity-1",
    "title": "\n1  Intro to using AI\n",
    "section": "\n1.3 Activity 1",
    "text": "1.3 Activity 1\n\nChoose one of the AIs and create an account/login. You can also do this activity with both AIs to see the difference in output if you’re interested.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "01-intro.html#activity-2",
    "href": "01-intro.html#activity-2",
    "title": "\n1  Intro to using AI\n",
    "section": "\n1.4 Activity 2",
    "text": "1.4 Activity 2\nThe key difference between using an AI and a regular search engine is that you can shape the output of the AI by “prompt engineering”, which is the phrase used to describe the art of asking the question in a way that gives you the answer you want. It’s easier to show than tell.\nThink of a book, TV show, film, or video game that you know really well. I chose Final Fantasy VII (the original PlayStation version). Ask the AI to give you three different summaries and try out the functionality of each platform. For example, for ChatGPT ask it to regenerate the response, for Copilot, click on any links it provides.\n\nFirst, ask it for a summary without any additional context e.g., “Give me a summary of Final Fantasy VII (original playstation version)”\nThen, ask it for a summary but give it a steer on the intended audience, e.g., “Give me a summary of Final Fantasy VII (original playstation version) for someone who knows nothing about videogames” or “Give me a summary of Final Fantasy VII (original playstation version) for an expert gamer who has played it many times”\nFinally, ask it for a summary, but give it a steer on how it should act, e.g., “Act as an expert videogame reviewer for the Guardian. Give me a summary of Final Fantasy VII (original playstation version) for an expert gamer who has played it many times” or “Act as someone who spends too much time on Reddit and thinks they know everything. Give me a summary of Final Fantasy VII (original playstation version) for an expert gamer who has played it many times”.\n\nThe key takeaways to remember for your learning journey are:\n\nTell it how to act\nTell it who you are\n\nReflect on the differences between the summaries - the technicality of the language, the accuracy and nuance of the information, what it chose to focus on, and what it chose to omit. The reason I asked you to create a summary of something you already know well is that you’re aware of where the gaps are. Remember this when you’re asking an AI something you don’t know as well. Just because you can’t see the gaps, inaccuracies, and biases, doesn’t mean they’re not there.\n\n\n\n\n\n\nCaution\n\n\n\nThis book was written in Spring 2024 and should be considered a living document. The functionality and capability of AI is changing rapidly and the most recent advances may not reflect what is described in this book. Given the brave new world in which we now live, all constructive feedback and suggestions are welcome! If you have any feedback or suggestions, please provide it via Forms.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "01-intro.html#footnotes",
    "href": "01-intro.html#footnotes",
    "title": "\n1  Intro to using AI\n",
    "section": "",
    "text": "I ran this explanation through an AI and it was not happy with me and wants you to know that it can also perform tasks like translation, question answering, and even generate creative text formats like poems or code. Calm down Felicia.↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "02-personalise.html",
    "href": "02-personalise.html",
    "title": "\n2  Personalised tutor\n",
    "section": "",
    "text": "2.1 Custom instructions\nThis chapter will teach you how to use AI as a personalised tutor to explain concepts and functions you’re struggling to understand, or would like more information on. AI can act as a study partner to explain concepts in multiple ways, but it is not a replacement for your own practice or your lecturer’s guidance. Think of it as a supplement, not a substitute.\nIt will be helpful to work through these activities with a specific week/chapter/lecture of your course in mind.\nThe key to maximising usefulness is to set up custom instructions (sometimes called “system prompts”). These apply across all chats so the AI remembers who you are and how you like answers to be framed.\nHere’s some examples:\nThis is mine. It doesn’t always follow the instructions but it’s much better than without it.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#set-up",
    "href": "02-personalise.html#set-up",
    "title": "2  Personalised tutor",
    "section": "",
    "text": "Act as an expert tutor for the programming language R. I am a learner on an Upskilling course “Applied Data Skills” and I am learning R for the first time. I work in the NHS in Health Informatics. I have never learned a programming language before. I have used Excel and SPSS. I have reasonably good general computer literacy. I will ask you questions about concepts and functions I do not understand based on my course materials. Always give me concrete examples when you provide an answer. Tailor your responses to my level of expertise. I am using R and RStudio on a Mac and the course will strongly use the tidyverse.\n\n\nAct as an expert tutor for the programming language R. I am a first year psychology student at the University of Glasgow and I am learning R for the first time. I have never learned a programming language before and I am not very confident with computers and I am anxious about learning programming. I have a Windows laptop. I will ask you questions about concepts and functions I do not understand based on my course materials. Always give me concrete examples when you provide an answer. Tailor your responses to my level of expertise. I am using R and RStudio and the course will strongly use the tidyverse.\n\n\nAct as an expert psychology tutor for university level study. I am a second year psychology student at the University of Glasgow. I will ask you questions about concepts and theories based on my course materials. Always give me concrete examples when you provide an answer. Tailor your responses to my level of expertise.\n\n\nAct as an expert careers advisor. I am about to graduate with a psychology degree and I would like help applying for jobs. Your responses should be relevant to working in the UK with a BPS accredited degree. Any writing you produce should be of an appropriate formality and tone.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#sec-setup",
    "href": "02-personalise.html#sec-setup",
    "title": "2  Personalised tutor",
    "section": "2.2 Activity 1: Write your set-up",
    "text": "2.2 Activity 1: Write your set-up\n\nWrite and save your set-up. It’s worth spending some time to get this right, you’re going to use it a lot.\n\nExactly what information you provide is up to you but make sure that you explain your level of knowledge, skill, confidence and previous experience. By specifying what your field is (psychology, NHS etc.) it can then give you examples related to these fields which will make it easier for you to understand and connect your new knowledge to existing knowledge. Finally, if you’re using it for coding, you also want to give it some technical information about the software you’re using (e.g., R and RStudio) and your operating system (Windows).",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#activity-2-instruct-the-ai",
    "href": "02-personalise.html#activity-2-instruct-the-ai",
    "title": "2  Personalised tutor",
    "section": "2.3 Activity 2: Instruct the AI",
    "text": "2.3 Activity 2: Instruct the AI\n\nEnter your set-up into a new chat on your AI of choice. If you’re using an AI that saves your chats, you could also rename the chat to “Personal Tutor” or “Week 1 Tutor” or anything else that make sense to you.\n\nDepending on what information you give it, it may give you e.g., some intro to R tips and information which may be more or less useful, so if it’s confusing, just ignore it until you’ve given it more specific prompts.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#example-questions",
    "href": "02-personalise.html#example-questions",
    "title": "\n2  Personalised tutor\n",
    "section": "\n2.2 Example questions",
    "text": "2.2 Example questions\nNow that you’ve got your tutor set up, you can ask it questions. Here’s some examples:\n\nWhy do I have to learn to code?\nWhat is the difference between short-term memory and working memory?\nGive me examples of between-subject designs\nWhat is the difference between a function and an argument?\nRewrite this explanation in 100 words or less.\nExplain what each part of this code is doing: ggplot(survey_data, aes(x = wait_time, y = call_time)) +  geom_point()\n\nGive me examples of when I would use different joins in R\n\n\n\n\n\n\n\nNoteActivity 3\n\n\n\n\nAsk the AI three questions based on your course materials for this week. If the output doesn’t seem at the right level for you, consider editing your custom instructions and re-running the questions to see how the output changes.\nTry asking for two versions of the same answer (e.g., one simple, one more technical) and compare how the content changes.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#activity-3-questions",
    "href": "02-personalise.html#activity-3-questions",
    "title": "2  Personalised tutor",
    "section": "2.5 Activity 3: Questions",
    "text": "2.5 Activity 3: Questions\n\nAsk the AI three questions based on your course materials. If the output doesn’t seem at the right level for you, consider editing your initial set-up prompt and re-running the questions to see how the output changes.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#conversation",
    "href": "02-personalise.html#conversation",
    "title": "\n2  Personalised tutor\n",
    "section": "\n2.3 Conversation",
    "text": "2.3 Conversation\nAnother big difference between AI and a regular search engine is that you can have a conversation with it and follow-up on your original question. Some examples:\n\nCan you explain it again but compare coding in R to doing the same task in Excel?\nExpand on your explanation of geom_point()\n\nGive me another example of code that uses this approach\nExplain it again but in more technical / simpler terms\nAsk me a question to test if I understand this correctly (we’re going to go into practice testing a lot more in the next chapter)\nIn your answer you said “In this example, c() is a function that combines values into a vector”, what is a vector?",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#activity-4-follow-up",
    "href": "02-personalise.html#activity-4-follow-up",
    "title": "2  Personalised tutor",
    "section": "2.7 Activity 4: Follow-up",
    "text": "2.7 Activity 4: Follow-up\n\nAsk a follow-up question to each of your original questions. Additionally, try out the features of each AI. For ChatGPT, use regenerate response. For Copilot, click on the suggested follow-up questions or any links it provides.\n\n\n\n\n\n\n\nCaution\n\n\n\nThis book was written in Spring 2024 and should be considered a living document. The functionality and capability of AI is changing rapidly and the most recent advances may not reflect what is described in this book. Given the brave new world in which we now live, all constructive feedback and suggestions are welcome! If you have any feedback or suggestions, please provide it via Forms.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "03-testing.html",
    "href": "03-testing.html",
    "title": "\n3  Practice testing\n",
    "section": "",
    "text": "3.1 Question types\nIn this chapter you’ll learn how to use AI to test yourself. Practice testing, or retrieval practice, is one of the most effective ways to consolidate learning, and it can be applied in several formats. This chapter was written with a data skills course in mind but it applies to any type of course.\nYou should have a specific week/chapter/lecture of your course to work with. For PsyTeachR courses like Applied Data Skills, we’ll be using the Intended Learning Outcomes, functions used, and glossary to help instruct the AI. If you’re not working through a course, or it’s not a PsyTeachR course, it would be helpful to have a list of functions, concepts, or skills that you want to test.\nIt’s very important that you use Copilot through your UofG account so that the course content you share is not used to train the model. You should also ensure that you have the consent of your lecturer to do this (if you’re enrolled on Applied Data Skills, you have our consent to upload any course material to Copilot, but not to platforms like ChatGPT).\nThe first thing we’re going to do is set-up several different prompts to create different types of practice questions. Which of these you end up using will depend on what you’re trying to study. Different question formats test different aspects of your knowledge. Here’s what each type is for and what the AI will produce when you ask for it.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#sec-setup-testing",
    "href": "03-testing.html#sec-setup-testing",
    "title": "\n3  Practice testing\n",
    "section": "",
    "text": "In your AI of choice, create a new chat and give it your set-up blurb that you created in Chapter ?sec-setup.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#activity-2-question-prompt",
    "href": "03-testing.html#activity-2-question-prompt",
    "title": "\n3  Practice testing\n",
    "section": "\n3.2 Activity 2: Question prompt",
    "text": "3.2 Activity 2: Question prompt\nAfter you have given it your set-up prompt, you can give it instructions for how to create each type of question.\n\n3.2.1 Multiple choice questions\nFirst, prompt the AI with guidance for how to write effective MCQs. This ensures that the questions it produces have a better chance of being well-formed:\n\nRead and summarise the guidance on this page, paying particular attention to the construction of the stem and the response options https://cft.vanderbilt.edu/guides-sub-pages/writing-good-multiple-choice-test-questions/\n\nFollow this up with:\n\nNow, read and summarise the guidance on this page on the different types of MCQs: https://www.utm.utoronto.ca/rgasc/media/2097/download?inline\n\nThen give the AI context about the type of questions you need. Include the level of the learner and any other information. You may want to edit this depending on your question set-up and rules:\n\nI would like you to write multiple choice questions that are appropriate for students in their first year of an undergraduate psychology degree.\n\n\n\nAll questions should follow the guidance above on best practices for MCQs\nAll questions should have four responses and one correct answer. Each response option should be on a separate line.\nAll questions should align with the intended learning outcomes\nAll questions should be challenging in difficulty.\n\n\n\n\nI will upload the learning outcomes and content for the class I want you to test me on. Give me questions one at a time. Ask me for the correct answer and then give me an explanation for each option. Do not give any suggestions as to what the right answer is, for suggested follow up responses in Copilot only give the option “skip question\n\n\n\n3.2.2 True-or-false (TOF)\n\nI would like you to write TRUE or FALSE questions (TOF) that are appropriate for students in their first year of an undergraduate psychology degree. Provide a statement and then ask me to determine whether the statement is true or false. All questions should be challenging in difficulty.\n\n\nI will upload the learning outcomes and content for the class I want you to test me on. Give me questions one at a time. Ask me for the correct answer and then give me an explanation.\n\n\n3.2.3 Short-answer-questions\n\nI would like you to write short answer questions (SAQ) that are appropriate for students in their first year of an undergraduate psychology degree. Each question should ask about one specific concept, theory, or term, and I should be able to answer it in 100 words or fewer. All questions should be challenging in difficulty.\n\n\nI will upload the learning outcomes and content for the class I want you to test me on. Give me questions one at a time. Ask me for the correct answer and then give me an explanation.\n\n\n3.2.4 Fill-in-the-blanks (coding)\n\nI would like you to write fill-in-the-blank questions (FITB) that are appropriate for students in their first year of an undergraduate psychology degree. Provide a line of R code that has one or more missing arguments or functions and ask me to complete the code. All questions should be challenging in difficulty.\n\n\nI will upload the learning outcomes and content for the class I want you to test me on. Give me questions one at a time. Ask me for the correct answer and then give me an explanation.\n\n\n3.2.5 Fill-in-the-blanks (theory)\n\nI would like you to write fill-in-the-blank questions (FITB) that are appropriate for students in their first year of an undergraduate psychology degree. Provide a statement that has one or more missing words and ask me to fill in the blanks. All questions should be challenging in difficulty.\n\n\nI will upload the learning outcomes and content for the class I want you to test me on. Give me questions one at a time. Ask me for the correct answer and then give me an explanation.\n\n\n3.2.6 Coding problems\n\nI would like you to write coding problems (CP) that are appropriate for students in their first year of an undergraduate psychology degree learning R. Give me short problems that I need to provide the answer to. These should be fully reproducible and use datasets built into R or the tidyverse. I will upload the learning outcomes and functions you should test me on. Where necessary, give me the code to load any packages or datasets that I will need. All questions should be challenging in difficulty.\n\n\nGive me questions one at a time. Ask me for the correct answer and then give me an explanation.\n\n\n3.2.7 Error mode\n\nI would like you to write error mode problems (EM) that are appropriate for students in their first year of an undergraduate psychology degree learning R.Give me code that will result in an error. Explain what the code is intended to do and then ask me to figure out what the error is, and then fix it. The errors should be plausible errors that a beginner would be likely to make but do not tell me what the error is. The errors should be fully reproducible and use datasets built into R or the tidyverse so that I can run the code and fix them in R. All questions should be challenging in difficulty.\n\n\nI will upload the learning outcomes and functions you should test me on. Where necessary, give me the code to load any packages or datasets that I will need. Give me questions one at a time. Ask me for the correct answer and then give me an explanation.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#built-in-datasets",
    "href": "03-testing.html#built-in-datasets",
    "title": "\n3  Practice testing\n",
    "section": "\n3.3 Built-in datasets",
    "text": "3.3 Built-in datasets\nIf you’re using AI to help with coding, built-in datasets in R are sample datasets that come pre-loaded with the R software installation. They provide a convenient way to practice data manipulation, analysis, and visualization techniques without needing to import external data files. These datasets cover various domains and can be helpful for learning and demonstrating R functionalities.\nYou can get a full list of all the built-in datasets available to you by running the command data() in the console. Base R comes with datasets built in but when you install extra packages they also sometimes have extra datasets, for example, the tidyverse has a lot of extra datasets. A package needs to be loaded for you to use any datasets from it, or for them to show up in the list when you run data().\n\n# see list of datasets\ndata()\n\n# load tidyverse to get access to extra sets\nlibrary(tidyverse)\n\n# load in dataset to environment so it can be used\ndata(\"starwars\")",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#activity-3-content-prompt",
    "href": "03-testing.html#activity-3-content-prompt",
    "title": "\n3  Practice testing\n",
    "section": "\n3.4 Activity 3: Content prompt",
    "text": "3.4 Activity 3: Content prompt\nNow give it the learning outcomes, list of functions, and glossary terms you want it to quiz you on. You don’t need to worry about copying and pasting these over with nice formatting, just dump it all in. For example, for Applied Data Skills Chapter 3, this is what I provided:\n\nIntended Learning Outcomes Be able to identify categorical versus continuous data Be able to create plots in layers using ggplot Be able to choose appropriate plots for data 3.1 Functions used aes(), as.numeric(), c(), col_character(), col_datetime(), col_double(), col_factor(), col_integer(), cols(), coord_cartesian(), count(), element_blank(), facet_wrap(), factor(), geom_bar(), geom_boxplot(), geom_col(), geom_histogram(), geom_jitter(), geom_point(), geom_smooth(), ggplot(), ggtitle(), glimpse(), guides(), mean(), now(), plot_layout(), read_csv(), rgb(), scale_fill_manual(), scale_x_continuous(), scale_x_date(), scale_x_discrete(), scale_y_continuous(), seq(), spec(), stat_summary(), theme(), theme_bw(), theme_gdocs(), theme_set(), today()\n\n\n3.7 Glossary termdefinitionargumentA variable that provides input to a function.categoricalData that can only take certain values, such as types of pet.categoricalData that can only take certain values, such as types of pet.characterA data type representing strings of text.chunkA section of code in an R Markdown filecontinuousData that can take on any values between other existing values.continuousData that can take on any values between other existing values.data-typeThe kind of data represented by an object.default-valueA value that a function uses for an argument if it is skipped.doubleA data type representing a real decimal numberfactorA data type where a specific set of values are stored with labels; An explanatory variable manipulated by the experimentergeomThe geometric style in which data are displayed, such as boxplot, density, or histogram.integerA data type representing whole numbers.knitTo create an HTML, PDF, or Word document from an R Markdown (Rmd) documentlikertA rating scale with a small number of discrete points in orderlogicalA data type representing TRUE or FALSE values.medianThe middle number in a distribution where half of the values are larger and half are smaller.nominalCategorical variables that don’t have an inherent order, such as types of animal.numericA data type representing a real decimal number or integer.observationAll of the data about a single trial or question.ordinalDiscrete variables that have an inherent order, such as level of education or dislike/like.outlierA data point that is extremely distant from most of the other data pointsr-markdownThe R-specific version of markdown: a way to specify formatting, such as headers, paragraphs, lists, bolding, and links, as well as code blocks and inline code.stringA piece of text inside of quotes.tidy-dataA format for data that maps the meaning onto the structure.valueA single number or piece of data.variable(coding): A word that identifies and stores the value of some data for later use; (stats): An attribute or characteristic of an observation that you can measure, count, or describevectorA type of data structure that collects values with the same data type, like T/F values, numbers, or strings.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#activity-4-generating-questions",
    "href": "03-testing.html#activity-4-generating-questions",
    "title": "\n3  Practice testing\n",
    "section": "\n3.5 Activity 4: Generating questions",
    "text": "3.5 Activity 4: Generating questions\nYou should now be able to ask it to generate questions for you by typing mcq or coding problem. A few other prompts to consider:\n\nMore like this\nGive me a harder/easier question\nCoding problem about stat_summary()",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#cautions-and-caveats",
    "href": "03-testing.html#cautions-and-caveats",
    "title": "\n3  Practice testing\n",
    "section": "\n3.6 Cautions and caveats",
    "text": "3.6 Cautions and caveats\nThe questions it generates are generally helpful, but not always. Here’s the issues we’ve come across whilst writing this book that we have not been able to prevent entirely by tweaking the prompts.\n\n3.6.1 Mulitple-choice / TOF / SAQ questions\n\nSometimes it is just plain wrong. The answer here should be C. If you tell it that it is wrong, it can correct itself (but also if you tell it that it is wrong even when it is right, it sometimes accepts that it is wrong). Bear this in mind if you ever use it to produce anything that AI does not have any knowledge, it’s just a very sophisticated parrot.\nIt may ask you questions about functions or concepts you’ve haven’t covered in the course.\nIt may give you a question where there are multiple correct answers without indicating this is the case, which can be confusing.\nIt may focus too much on certain topics of functions and you have to ask it to give you questions on a topic/function specifically.\n\n3.6.2 Coding problems\n\nIt suggests using a built-in dataset that doesn’t exist. In this case, tell it that’s the case and it will suggest a different dataset for the problem.\nThe example it gives isn’t fully reproducible so you have to write the code without being able to run it in R. For example, it assumes you have a dataset with columns named “number” and “price”, but loads no such dataset, so you can’t actually try out the code. It’s still possible to write the code, but without being able to run it, much more difficult, particularly as a beginner.\n\n3.6.3 Error mode\n\nThis is the category the AI struggled with the most, to the point where at the time of writing, we can’t say that it’s up to the task. We have tried writing the prompts multiple times and whilst we have seen some improvement, it’s not consistent. We have a premium ChatGPT subscription and also tried using GPT4.0 and it didn’t help.\n\n\n\n\n\n\n\nImportant\n\n\n\nUpdate! OpenAI released GPT4o in May 2024 and this can produce sensible error mode problems. We’ve left the below in this book because at the time of writing, Copilot and earlier versions of GPT can’t and it’s an interesting insight into some of the issues with AI.\n\n\n\nFrom a learning and teaching perspective, it’s a good example of why teaching might actually be a skill and our job might be safe after all. When we use Error Mode type questions in our courses, we design the errors so that they’re common mistakes learners make at that point in their journey, they’re mistakes that learners would plausibly make, and solving them will teach you something of use. Even when the AI managed to create an accurate error mode problem, it still wasn’t helpful for learning.\nChatGPT fared slightly better although all of the problems were very basic and of the same type (creating a vector) until we asked it to give us a specific problem (e.g., error mode for ggplot).\nChatGPT also suffered from the problem that it would tell you what the error was or produce code that did not have any errors. We particularly enjoyed this response whereby it seemed to pretend that it was doing it on purpose as a teachable moment. We know we are anthropomorphising the AI here but we imagine any educator will feel a sense of kinship at trying to make your mistakes seem intentional.\n\n\n\nIt often won’t tell you what built-in dataset you need to load to run the code (and this isn’t the intended error). Unless you have a working knowledge of built-in datasets in R and the packages they’re from, this is unnecessarily confusing.\nThere is no prompt we could give Copilot that will result in it producing code with an error (even when the same prompt works with ChatGPT). So we gave up.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nThis chapter was last updated in November 2024 and should be considered a living document. The functionality and capability of AI is changing rapidly and the most recent advances may not reflect what is described in this book.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "04-errors.html",
    "href": "04-errors.html",
    "title": "\n4  Error checking and debugging\n",
    "section": "",
    "text": "4.1 Simple errors\nIn this chapter, you’ll learn how to use AI to identify and fix coding errors. This is probably the best use case of AI: using it to debug code that you wrote. Human expertise drives the code, while AI’s attention to detail can help spot small mistakes such as missing commas.\nAI is generally good at this task, although the more complex your code, the more likely it is to struggle. This chapter gives examples to help you with prompt engineering for error checking.\nSo that you can reproduce the same errors, let’s create a reproducible example and load some packages and a dataset.\nUnlike the other chapters you don’t need to do any set-up, in fact, you can often just copy and paste the code and error in and it will figure out that you want it to fix it without even needing to explicitly ask.\nHere’s a simple error where we have given it the wrong function name:\nggplot(penguins, aes(x = species)) +\n   geom_barchart()\n\nError in geom_barchart(): could not find function \"geom_barchart\"\nFixing a simple error",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "04-errors.html#sec-simple-errors",
    "href": "04-errors.html#sec-simple-errors",
    "title": "\n4  Error checking and debugging\n",
    "section": "",
    "text": "NoteActivity 2\n\n\n\nGive Copilot both the code and the error. One without the other is likely to result in a poor or incomplete answer (whether you ask a human or an AI).",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "04-errors.html#activity-3-contextual-errors",
    "href": "04-errors.html#activity-3-contextual-errors",
    "title": "\n4  Error checking and debugging\n",
    "section": "\n4.2 Activity 3: Contextual errors",
    "text": "4.2 Activity 3: Contextual errors\nSomething that catches many people out is when the error is actually being caused by code further up your script rather than the bit that is results in the error.\nFor example, in this code, what we intended to do was to create a dataset that just has penguins from Biscoe Island and then calculate their mean body mass. This code will run, but it produces NaN as the value.\n\nbiscoe_penguins &lt;- penguins %&gt;%\n  filter(island == \"biscoe\")\n\nbiscoe_penguins %&gt;%\n  summarise(mean_mass = mean(body_mass_g))\n\n\n\n\nmean_mass\n\n\nNaN\n\n\n\n\n\nIf you just give an AI the code and the table and ask it to explain what’s happening, it will do its best but without knowing the dataset or what code has preceded it, it won’t give you the exact answer, although in this case it hints at it.\n\n\n\n\nChatGPT giving its best guess\n\n\n\nThere’s a couple of things you can do at this point:\n\nGive the AI all the code you’ve used so far\nGive the AI more information about the dataset.\n\nYou can manually type out a description but there’s some functions you can use that can automate this.\nsummary() is useful because it provides a list of all variables with some descriptive statistics so that the AI has a sense of the type and range of data:\n\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2                                 \n\n\nstr() is also useful because it lists the variables, their data type, and the initial values for each variable. However, that means that you are giving it at least some of the raw data so you have to be very careful if you have sensitive / confidential data and you must ensure that any use of AI is in line with your data management plan. Using Copilot Enterprise means the data won’t be stored and used to train the AI further so it’s potentially the best option (which is not to say it’s safe or problem free, please be careful and critical!).\n\nstr(penguins)\n\ntibble [344 × 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n\nFinally, ls() provides a list of all the variables in a given object. It doesn’t provide any info on the variable type or sample, but that does mean it’s the most secure and depending on the task, this might be all the info you really need to give the AI. I would suggest starting with ls() and only scaling up if necessary (and your data isn’t sensitive):\n\nls(penguins)\n\n[1] \"bill_depth_mm\"     \"bill_length_mm\"    \"body_mass_g\"      \n[4] \"flipper_length_mm\" \"island\"            \"sex\"              \n[7] \"species\"           \"year\"             \n\n\n\nRun summary(biscoe_penguins) and give the AI the output so that it better understands the structure and contents of the datasets and then give it the code you used to filter the dataset.\n\nIf you haven’t spotted it by now, the error is that in the filter biscoe should be Biscoe with a capital B. There is no shortcut for knowing your data.\n\n\n\n\nCopilot getting very close",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "04-errors.html#activity-4-incorrect-but-functional-code",
    "href": "04-errors.html#activity-4-incorrect-but-functional-code",
    "title": "\n4  Error checking and debugging\n",
    "section": "\n4.3 Activity 4: Incorrect (but functional) code",
    "text": "4.3 Activity 4: Incorrect (but functional) code\nSometimes (often) when we write code, the issue isn’t that our code doesn’t work, but that it doesn’t do what we intended to do and we can’t figure out why.\nFor example, let’s say that we want to calculate the average body_mass_g for each species by sex. We’re feeling a bit lazy and we copy and paste in the following from a previous script we have:\n\npenguins %&gt;%\n  group_by(sex, species) %&gt;%\n  summarise(mean_body_mass = sd(body_mass_g, na.rm = TRUE))\n\n\n\n\nsex\nspecies\nmean_body_mass\n\n\n\nfemale\nAdelie\n269.3801\n\n\nfemale\nChinstrap\n285.3339\n\n\nfemale\nGentoo\n281.5783\n\n\nmale\nAdelie\n346.8116\n\n\nmale\nChinstrap\n362.1376\n\n\nmale\nGentoo\n313.1586\n\n\nNA\nAdelie\n477.1661\n\n\nNA\nGentoo\n338.1937\n\n\n\n\n\n\nWe know something isn’t right here. Because we’re responsible researchers, we’ve taken time to understand our dataset and what plausible values should be and we know there’s no way that the average body mass of a penguin is 269 grams (unless the penguin is made of chocolate). But the code is running fine, we know it’s worked before, and we can’t see what we’ve done wrong.\nYou can ask the AI to help you but you can’t just give it the code and output, you also need to tell it what you intended to do. The more complex your code, the more information you will need to give it in order for it to help you find the error.\n\n\n\n\nFixing a functional error\n\n\n\nThis is a good example of why there is no AI tool that allows you to skip understanding the data you’re working with and knowing what it is you’re trying to do.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "04-errors.html#activity-5-rmd-errors",
    "href": "04-errors.html#activity-5-rmd-errors",
    "title": "\n4  Error checking and debugging\n",
    "section": "\n4.5 Activity 5: Rmd errors",
    "text": "4.5 Activity 5: Rmd errors\nIf you’re working in R Markdown or Quarto, sometimes the errors will stem from your code chunk settings or YAML.\nIn your Rmd file, create a new code chunk and copy and paste the following:\n\npenguins %&gt;%\n  count()\n\nBut then delete one of the final back ticks (`) from the code chunk.\nThe code is fine, it provides a simple count of the number of observations in the dataset. But if you try and knit the file, you’ll get a long ! attempt to use zero-length variable name. Copilot wasn’t that helpful because all of its suggestions relate to checking your code:\n\n\n\n\nMissing the mark\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nI know I might be starting to sound like a broken record but please remember that artificial intelligence is not actually intelligent. It’s not thinking, it’s not making conscious decisions, it has no expert subject matter knowledge. No matter how helpful it is, you must always check the output of the code it gives you.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nThis book was written in Spring 2024 and should be considered a living document. The functionality and capability of AI is changing rapidly and the most recent advances may not reflect what is described in this book. Given the brave new world in which we now live, all constructive feedback and suggestions are welcome! If you have any feedback or suggestions, please provide it via Forms.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "05-review.html",
    "href": "05-review.html",
    "title": "\n5  Code review\n",
    "section": "",
    "text": "5.1 Code comments\nIn this chapter you’ll learn how to use AI to perform a code review and to add comments to your code. As you’ve already hopefully learned by working through this book, you have to be critical about anything the AI produces or suggests because it has no expert knowledge, but it can be a useful tool for checking and improving your code.\nDeBruine et al’s Code Check Guide details what a comprehensive code check refers to:\nHowever, some of these steps cannot (and should not) be performed by an AI. Unless you have specific ethical approval and have included this in your data management plan, you should never upload your research data to an AI tool. This means that assessing reproducibility is difficult. The AI also doesn’t know what you intended to do, and why, and has no subject knowledge so it can’t advise on anything theoretical without you giving it that information explicitly.\nTherefore, what we’ll focus on in this chapter is two components of code review: comments and refactoring your code.\nCode comments are lines or sections of text added within the code itself that are ignored by the computer when the program runs. They’re there for human readers, not machines. In R, you add comments to code by adding # to the start of the string:\n# this is a comment\n\n# compute the mean of three numbers\nmean(c(1,2,3))\nComments are useful for several reasons:\nOverall, comments are a crucial part of writing clean, maintainable, and collaborative code. They help make the code more accessible and understandable to anyone who might work on it in the future.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "05-review.html#code-comments",
    "href": "05-review.html#code-comments",
    "title": "\n5  Code review\n",
    "section": "",
    "text": "Clarification: They explain what certain parts of the code do, making it easier for others (and yourself) to understand the logic and flow of the code.\nDocumentation: They provide information on how the code works or why certain decisions were made, which is helpful for future reference.\nDebugging: Temporarily commenting out parts of code can help isolate sections that may be causing errors, without deleting the code.\nCollaboration: In team projects, comments can be used to communicate with other developers about the status or purpose of the code.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "05-review.html#activity-1-add-comments-with-ai",
    "href": "05-review.html#activity-1-add-comments-with-ai",
    "title": "\n5  Code review\n",
    "section": "\n5.2 Activity 1: Add comments with AI",
    "text": "5.2 Activity 1: Add comments with AI\nFirst we’ll use use the palmerpenguins dataset again.\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\ndata(\"penguins\")\n\nYou can use AI tools to help add comments to your code. Previous experience has taught us that we need to be a bit specific with what we want the AI to do so we’ll give it a clear prompt. In your chosen platform, input the below code with the prompt:\n\nAdd comments to this code. Keep the comments as concise as possible Ask me any questions about the code if you are not sure what it is doing or why. Do not change anything about the code.\n\n\npenguins_clean &lt;- penguins %&gt;%\n  filter(complete.cases(.)) %&gt;%\n  mutate(across(where(is.factor), as.character)) %&gt;%\n  mutate(species_sex = interaction(species, sex, sep = \"_\"))\n\n\n\n\n\nAdding comments\n\n\n\nA couple of notes:\n\nThe AI can only tell you what the code is doing, it can’t say why you chose to do that. In this example, we’ve created a new column that combines species and sex but the comment gives us no idea what the rationale was for this. The more complex your analysis, the more crucial it becomes to explain the rationale.\nWe’ve reminded it to be concise but still remember that not all the comments necessary. Too many comments are a different problem to too few, but they’re still a problem so always review what it produces.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "05-review.html#activity-2-review-existing-comments",
    "href": "05-review.html#activity-2-review-existing-comments",
    "title": "\n5  Code review\n",
    "section": "\n5.3 Activity 2: Review existing comments",
    "text": "5.3 Activity 2: Review existing comments\nIn addition to asking AI to comment your code, you can also ask it to review comments you’ve made yourself. To see how this works with a more complex example, and as an act of masochism, I gave the AI some code I wrote for a publication. The full paper is here if you’re interested - the quant analyses ended up being punted to the online appendix because of word count.\nYou can load in the dataset yourself with this code:\n\n# read in data but skip rows 2 and 3\ncol_names &lt;- names(read_csv(\"https://osf.io/download/tf3xs/\", n_max = 0))\ndat_raw &lt;- read_csv(\"https://osf.io/download/tf3xs/\", col_names = col_names, skip = 3) \n\nThe first section of my code involved quite a complicated and long bit of wrangling, all done in a single pipeline. The purpose of the code is to clean up data collected on the survey platform Qualtrics and recoding some of the demographic variables. This is actually a shortened version because the original hit the character limit for Copilot. I did put some effort into writing comments before publication but there are almost certainly improvements to be made.\n\ndat &lt;- dat_raw%&gt;%\n  filter(Progress &gt; 94, # remove incomplete responses\n         DistributionChannel != \"preview\") %&gt;% # Remove Emily's preview data\n  select(ResponseId, \"duration\" = 5, Q5:Q21) %&gt;%\n  # replace NAs with \"none\" for disability info\n  mutate(disability_nos = replace_na(disability_nos, \"None\"),\n         physical_chronic = replace_na(physical_chronic, \"None\"),\n         mental_health = replace_na(mental_health, \"None\"),\n) %&gt;%\n   # recode gender data\n\n  mutate(gender_cleaned = case_when(Q6 %in% c(\"Female\", \"female\", \"Woman\", \"woman\", \"Cisgender woman\",\"female (she/her)\", \"F\", \"f\", \"Womxn\", \"Woman (tranas)\") ~ \"Woman\",\n                                    Q6 %in% c(\"Man\", \"man\", \"M\", \"m\", \"Male (he/him)\", \"Male\", \"male\", \"Trans man.\") ~ \"Man\",\n                                    Q6 %in% c(\"Agender\", \"Genderfluid\", \"GNC\", \"NB\", \"non-binary\", \"    \nNon-binary\", \"Non-Binary\", \"Non-binary femme\", \"non-binary male\", \"non binary\",\n\"Non binary\", \"Nonbinary\", \"Queer\", \"Transmasculine\", \"Non-binary\") ~ \"Non-binary\",\n                            TRUE ~ \"Not stated\")) %&gt;%\n  # select necessary columns and tidy up the names\n        select(ResponseId,\n             \"age\" = Q5,\n             \"gender\" = Q6,\n             \"mature\" = Q7,\n             \"level_study\" = Q8,\n             \"country\" = Q9,\n             \"subject\" = Q10,\n             \"english_first\" = Q11,\n             \"neurotype_open\" = Q13, \n             \"disability_open\" = Q14,\n             \"why_open\" = Q18,\n             \"how_open\" = Q23,\n             \"advantages\" = Q20,\n             \"disadvantages\" = Q21,\n             everything()) \n\nProvide the code with the following prompt:\n\nReview my use of comments and make improvements to the comments where necessary. Keep the comments as concise as possible. Do not change anything about the code.\n\nIn an earlier version of this book with a different AI tool (Gemini) providing this prompt resulting in it changing the code without telling me so that not only did it not do what I intended but it also didn’t work so you need to be very, very careful.\nTo check that it hasn’t changed any code you can run all.equal() to compare two datasets. If it returns true, it means that the result of your inital code and the new code are identical. This is a really important check.\n\n# Assigning the processed data to 'dat'\ndat_copilot &lt;- dat_raw %&gt;%\n  filter(Progress &gt; 94, # Exclude responses below 95% completion\n       DistributionChannel != \"preview\") %&gt;% # Exclude preview data\nselect(ResponseId, \"duration\" = 5, Q5:Q21) %&gt;%\nmutate(\n  disability_nos = replace_na(disability_nos, \"None\"), # Default 'None' for missing disability info\n  physical_chronic = replace_na(physical_chronic, \"None\"),\n  mental_health = replace_na(mental_health, \"None\")\n) %&gt;%\nmutate(\n  gender_cleaned = case_when(\n    Q6 %in% c(\"Female\", \"female\", \"Woman\", \"woman\", \"Cisgender woman\",\"female (she/her)\", \"F\", \"f\", \"Womxn\", \"Woman (tranas)\") ~ \"Woman\",\n    Q6 %in% c(\"Man\", \"man\", \"M\", \"m\", \"Male (he/him)\", \"Male\", \"male\", \"Trans man.\") ~ \"Man\",\n    Q6 %in% c(\"Agender\", \"Genderfluid\", \"GNC\", \"NB\", \"non-binary\", \"Non-binary\", \"Non-Binary\", \"Non-binary femme\", \"non-binary male\", \"non binary\", \"Non binary\", \"Nonbinary\", \"Queer\", \"Transmasculine\", \"Non-binary\") ~ \"Non-binary\",\n    TRUE ~ \"Not stated\"\n  ) # Standardize gender representation\n) %&gt;%\nselect(\n  ResponseId,\n  \"age\" = Q5, # Rename Q5 to 'age'\n  \"gender\" = Q6, # Rename Q6 to 'gender'\n  \"mature\" = Q7, # Rename Q7 to 'mature'\n  \"level_study\" = Q8, # Rename Q8 to 'level_study'\n  \"country\" = Q9, # Rename Q9 to 'country'\n  \"subject\" = Q10, # Rename Q10 to 'subject'\n  \"english_first\" = Q11, # Rename Q11 to 'english_first'\n  \"neurotype_open\" = Q13, # Rename Q13 to 'neurotype_open'\n  \"disability_open\" = Q14, # Rename Q14 to 'disability_open'\n  \"why_open\" = Q18, # Rename Q18 to 'why_open'\n  \"how_open\" = Q23, # Rename Q23 to 'how_open'\n  \"advantages\" = Q20, # Rename Q20 to 'advantages'\n  \"disadvantages\" = Q21, # Rename Q21 to 'disadvantages'\n  everything() # Include all remaining columns\n)",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "05-review.html#refactor-code",
    "href": "05-review.html#refactor-code",
    "title": "\n5  Code review\n",
    "section": "\n5.4 Refactor code",
    "text": "5.4 Refactor code\nTo refactor code refers to the process of restructuring existing code without changing its intended behavior. The goal is to make the code more maintainable, readable, and efficient, while not altering the functionality or output. The benefits of refactoring code should be that it:\n\nImproves Readability: Makes the code easier to understand for anyone who reads it in the future, which includes other developers or even the original author after some time has passed.\nReduces Complexity: Simplifies complex code structures, breaking down large functions into smaller, more manageable ones.\nEnhances Maintainability: With cleaner code, it becomes easier to maintain and update the software over time.\nFacilitates Extensibility: Well-factored code can be extended with new features more easily.\nImproves Performance: In some cases, refactoring can optimize the performance of the software by removing redundancies and improving algorithms.\nIdentifies Bugs: The process of refactoring can often reveal hidden bugs or issues in the code that can then be fixed.\n\nWith thanks to Copilot for writing the above.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "05-review.html#activity-3-refactor",
    "href": "05-review.html#activity-3-refactor",
    "title": "\n5  Code review\n",
    "section": "\n5.5 Activity 3: Refactor",
    "text": "5.5 Activity 3: Refactor\nI’ll stick with the example of code from my publication because it’s complicated enough that there are likely improvements or alternative solutions. Using the same code chunk as above, the prompt is:\n\nrefactor this code and explain what you have changed and why. Where possible, use a tidyverse approach.\n\nCopilot’s first attempt produces an error\n\ndat_copilot &lt;- dat_raw %&gt;%\n  filter(Progress &gt; 94, DistributionChannel != \"preview\") %&gt;% # Keep only complete and non-preview data\n  rename(duration = Q5) %&gt;% # Rename Q5 here to avoid repetition\n  select(ResponseId, duration, Q6:Q21) %&gt;% # Select relevant columns once\n  mutate(\n    across(c(disability_nos, physical_chronic, mental_health), ~replace_na(., \"None\")), # Use across() for NAs\n    gender_cleaned = case_when(\n      Q6 %in% c(\"Female\", \"female\", \"Woman\", \"woman\", \"Cisgender woman\", \"female (she/her)\", \"F\", \"f\", \"Womxn\", \"Woman (tranas)\") ~ \"Woman\",\n      Q6 %in% c(\"Man\", \"man\", \"M\", \"m\", \"Male (he/him)\", \"Male\", \"male\", \"Trans man.\") ~ \"Man\",\n      Q6 %in% c(\"Agender\", \"Genderfluid\", \"GNC\", \"NB\", \"non-binary\", \"Non-binary\", \"Non-Binary\", \"Non-binary femme\", \"non-binary male\", \"non binary\", \"Non binary\", \"Nonbinary\", \"Queer\", \"Transmasculine\", \"Non-binary\") ~ \"Non-binary\",\n      TRUE ~ \"Not stated\"\n    ) # Recode gender once\n  ) %&gt;%\n  select(\n    ResponseId,\n    duration,\n    gender_cleaned,\n    across(Q7:Q21, .names = \"{.col}_cleaned\") # Clean up column names in one go\n  )\n\nError in `select()`:\n! Problem while evaluating `across(Q7:Q21, .names = \"{.col}_cleaned\")`.\nCaused by error in `across()`:\n! Must only be used inside data-masking verbs like `mutate()`,\n  `filter()`, and `group_by()`.\n\n\nChatGPT 4o introduces an error in that it’s changed \"duration\" = 5 to duration = Q5. The original code was selecting the column by index number (i.e., the 5th column), this isn’t the name of a column and so it doesn’t run (although if you fix this it does then run and all.equal() returns true.\n\ndat_chat &lt;- dat_raw %&gt;%\n  # Remove incomplete responses and preview data\n  filter(Progress &gt; 94, DistributionChannel != \"preview\") %&gt;%\n  \n  # Select necessary columns and rename them\n  select(ResponseId, duration = Q5, Q5:Q21) %&gt;%\n  \n  # Replace NAs with \"None\" for disability info\n  mutate(across(c(disability_nos, physical_chronic, mental_health), ~ replace_na(.x, \"None\"))) %&gt;%\n  \n  # Recode gender data\n  mutate(gender_cleaned = case_when(\n    Q6 %in% c(\"Female\", \"female\", \"Woman\", \"woman\", \"Cisgender woman\", \"female (she/her)\", \"F\", \"f\", \"Womxn\", \"Woman (tranas)\") ~ \"Woman\",\n    Q6 %in% c(\"Man\", \"man\", \"M\", \"m\", \"Male (he/him)\", \"Male\", \"male\", \"Trans man.\") ~ \"Man\",\n    Q6 %in% c(\"Agender\", \"Genderfluid\", \"GNC\", \"NB\", \"non-binary\", \"Non-binary\", \"Non-Binary\", \"Non-binary femme\", \"non-binary male\", \"non binary\", \"Non binary\", \"Nonbinary\", \"Queer\", \"Transmasculine\", \"Non-binary\") ~ \"Non-binary\",\n    TRUE ~ \"Not stated\"\n  )) %&gt;%\n  \n  # Select and rename necessary columns\n  select(\n    ResponseId,\n    age = Q5,\n    gender = Q6,\n    mature = Q7,\n    level_study = Q8,\n    country = Q9,\n    subject = Q10,\n    english_first = Q11,\n    neurotype_open = Q13,\n    disability_open = Q14,\n    why_open = Q18,\n    how_open = Q23,\n    advantages = Q20,\n    disadvantages = Q21,\n    everything()\n  )\n\nError in `select()`:\n! Can't subset columns that don't exist.\n✖ Column `Q5` doesn't exist.\n\n\nBecause you have to check everything so carefully, I wondered if it might be easier to give it less code at any one time so I asked Copilot to split the code in each pipeline into a different object which it did:\n\nSplit the code in each pipeline into a separate object\n\n\n# Filter complete and non-preview data\nfiltered_data &lt;- dat_raw %&gt;%\n  filter(Progress &gt; 94,\n         DistributionChannel != \"preview\")\n\n# Select and rename columns\nselected_data &lt;- filtered_data %&gt;%\n  select(ResponseId, \"duration\" = 5, Q5:Q21)\n\n# Replace NAs with \"None\" for disability info\nna_replaced_data &lt;- selected_data %&gt;%\n  mutate(\n    disability_nos = replace_na(disability_nos, \"None\"),\n    physical_chronic = replace_na(physical_chronic, \"None\"),\n    mental_health = replace_na(mental_health, \"None\")\n  )\n\n# Recode gender data\ngender_recoded_data &lt;- na_replaced_data %&gt;%\n  mutate(\n    gender_cleaned = case_when(\n      Q6 %in% c(\"Female\", \"female\", \"Woman\", \"woman\", \"Cisgender woman\", \"female (she/her)\", \"F\", \"f\", \"Womxn\", \"Woman (tranas)\") ~ \"Woman\",\n      Q6 %in% c(\"Man\", \"man\", \"M\", \"m\", \"Male (he/him)\", \"Male\", \"male\", \"Trans man.\") ~ \"Man\",\n      Q6 %in% c(\"Agender\", \"Genderfluid\", \"GNC\", \"NB\", \"non-binary\", \"Non-binary\", \"Non-Binary\", \"Non-binary femme\", \"non-binary male\", \"non binary\", \"Non binary\", \"Nonbinary\", \"Queer\", \"Transmasculine\", \"Non-binary\") ~ \"Non-binary\",\n      TRUE ~ \"Not stated\"\n    )\n  )\n\n# Final selection and renaming of columns\nfinal_data &lt;- gender_recoded_data %&gt;%\n  select(\n    ResponseId,\n    \"age\" = Q5,\n    \"gender\" = gender_cleaned,\n    \"mature\" = Q7,\n    \"level_study\" = Q8,\n    \"country\" = Q9,\n    \"subject\" = Q10,\n    \"english_first\" = Q11,\n    \"neurotype_open\" = Q13,\n    \"disability_open\" = Q14,\n    \"why_open\" = Q18,\n    \"how_open\" = Q23,\n    \"advantages\" = Q20,\n    \"disadvantages\" = Q21,\n    everything()\n  )\n\n# The final dataset is now stored in 'final_data'\n\nThen, for each chunk, I asked it to refactor the code, where possible. I slightly amended the prompt to explicitly say that if the code was already efficient enough, not to change anything because some of the steps are quite simple.\n\nRefactor this code where necessary. Explain what you changed and why. Do not change anything if the code is already efficient. Use the tidyverse where possible.\n\n\nFor step 3, Copilot and ChatGPT were both quite good at this and all.equal() returned TRUE.\n\n\n# chatgpt and copilot solution\nchat_dat_na_replaced &lt;- dat_selected %&gt;%\n  mutate(\n    across(c(disability_nos, physical_chronic, mental_health), ~replace_na(., \"None\"))\n  )\n\nFor step 4 it was a bit of a mess:\nBoth Copilot removed everything() with this explanation:\n\nRemoved everything(): The everything() argument in select is redundant here because you’ve explicitly specified all the columns you want to keep.\n\nWhich is just wrong and means you end up not selecting the rest of the columns.\n\nfinal_data_copilot &lt;- gender_recoded_data %&gt;%\n  # Select & rename columns (exclude everything())\n  select(ResponseId,\n         age = Q5,\n         gender = gender_cleaned,\n         mature = Q7,\n         level_study = Q8,\n         country = Q9,\n         subject = Q10,\n         english_first = Q11,\n         neurotype_open = Q13,\n         disability_open = Q14,\n         why_open = Q18,\n         how_open = Q23,\n         advantages = Q20,\n         disadvantages = Q21)\n\nChatGPT’s actually worked and returned an identical object although I am not convinced that this code is better, I think it’s just more verbose:\n\nClarity: Using rename makes it clear which columns are being renamed before they are selected. This separates the concerns of renaming and selecting, which can improve readability. Maintainability: If additional columns need to be renamed or if the selection needs to be modified, having separate rename and select steps makes it easier to adjust the code.\n\n\nfinal_data_chat &lt;- gender_recoded_data %&gt;%\n  rename(\n  age = Q5,\n  gender = gender_cleaned,\n  mature = Q7,\n  level_study = Q8,\n  country = Q9,\n  subject = Q10,\n  english_first = Q11,\n  neurotype_open = Q13,\n  disability_open = Q14,\n  why_open = Q18,\n  how_open = Q23,\n  advantages = Q20,\n  disadvantages = Q21\n) %&gt;%\nselect(ResponseId, age, gender, mature, level_study, country, subject, english_first, neurotype_open, disability_open, why_open, how_open, advantages, disadvantages, everything())",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "05-review.html#alternative-approaches",
    "href": "05-review.html#alternative-approaches",
    "title": "\n5  Code review\n",
    "section": "\n5.5 Alternative approaches",
    "text": "5.5 Alternative approaches\nIn the PsyTeachR courses, we mainly use the tidyverse approach because it provides a consistent, easy-to-read way of writing R code. The tidyverse is a collection of R packages (such as dplyr, ggplot2, and tidyr) that extend R’s core functionality and make data analysis more intuitive.\nHowever, it is also useful to understand Base R, which refers to the set of functions that come built into R itself. Base R does not rely on any additional packages, so it works “out of the box” as soon as you install R. This means your code will run anywhere, even if tidyverse packages are not installed.\n\n\n\n\n\n\nNoteActivity 5\n\n\n\nAsk Copilot to write the code in Base R using the following prompt. Rather than give it the full code, we’re just going to do the first few lines that filter and select.\n\nPlease rewrite the following code using Base R instead of tidyverse functions. Keep the same behaviour and output. When you rewrite it, please use only Base R functions (no tidyverse or other external packages).Add short, clear comments explaining what each main step does. After showing the Base R version, explain the key differences between the tidyverse and Base R approaches — for example, syntax style, readability, and performance. If there are trade-offs (e.g., tidyverse is easier to read but Base R runs without extra packages), explain those too.\n\n\ndat_copilot &lt;- dat_raw %&gt;%\n  # 1) Filter valid responses\n  filter(\n    Progress &gt; 94,                       # keep responses with &gt; 94% progress\n    DistributionChannel != \"preview\"     # exclude preview/test responses\n  ) %&gt;%\n  # 2) Keep required columns and rename column 5 to 'duration'\n  select(ResponseId, duration = 5, Q5:Q21)\n\n\n\nHere’s the Base R version. I’ll confess I have no idea if this is the approach you would take because I never code in Base R (because look at it, it’s horrible).\n\n## 1) Filter valid responses\ndat_tmp &lt;- dat_raw[dat_raw$Progress &gt; 94 &\n                   dat_raw$DistributionChannel != \"preview\",\n                   , drop = FALSE]\n\n## 2) Keep required columns and rename column 5 to 'duration'\nkeep_idx &lt;- c(\n  match(\"ResponseId\", names(dat_tmp)),         # ResponseId\n  5L,                                          # original column 5\n  match(paste0(\"Q\", 5:21), names(dat_tmp))     # Q5:Q21 by name\n)\nkeep_idx &lt;- unique(keep_idx[!is.na(keep_idx)]) # remove NAs, keep order\n\ndat_copilot &lt;- dat_tmp[, keep_idx, drop = FALSE]\n\n## rename the selected column that came from original position 5\npos5 &lt;- which(keep_idx == 5L)\nif (length(pos5) == 1L) names(dat_copilot)[pos5] &lt;- \"duration\"\n\n\n\n\n\nBase R. Gross.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "05-review.html#conclusions",
    "href": "05-review.html#conclusions",
    "title": "\n5  Code review\n",
    "section": "\n5.6 Conclusions",
    "text": "5.6 Conclusions\nI hadn’t actually used AI to perform these types of tasks before writing this book so here’s my takeaways:\n\nCHECK EVERYTHING.\nIf you give an AI code, you simply cannot trust that it won’t change your code, even if that’s not the task you ask it to do. If you use AI to add or review comments, you must check the output. Tools like all.equal() can help perform these checks.\nYou also can’t trust that the comments will be accurate. Anything an AI writes must be checked before you use it. If you don’t know if it’s right, don’t use it.\nBecause you have to check what it does so carefully, don’t give it a big dump of code. Smaller chunks will end up taking less time.\nIn some cases it was really useful and as someone who doesn’t really use or know much Base R, I can see that this would be a great way to learn alternative approaches or to fill in comments.\nThat said, the amount of checking it takes is substantial and so I’m not completely convinced that it would be any quicker than doing it yourself.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "06-writing.html",
    "href": "06-writing.html",
    "title": "\n6  Writing Code with AI\n",
    "section": "",
    "text": "6.1 The problem\nThis chapter closes the coding section because writing code with AI represents the highest-risk, highest-reward use case. By this point, you should be able to judge when AI suggestions are useful scaffolds and when they are dangerous shortcuts.\nThe best AI platform for writing code is arguably Github Copilot (or Super Clippy as my programmer friends like to call it) and there are also specialised packages that you integrate LLMs into RStudio. However, unless coding is the main part of your job, most people are likely to use AI through a generic platform so we’ll stick with regular Copilot.\nIf you have access to LinkedIn Learning (which you do if you are a UofG student or staff), I’d also highly recommend the short course Pair Programming with AI by Morten Rand-Hendriksen. It only takes 1.5 hours to work through and he covers using both Github Copilot and ChatGPT and has a nicely critical view of AI.\nIf you’ve worked through this entire book then hopefully what you’ve learned is that AI is very useful but you should also have a healthy mistrust of anything it produces which is why this chapter is the last in the coding section.\nThe number 1 rule to keep in mind when using AI to write code is that the platforms we’re using are not intelligent. They are not thinking. They are not reasoning. They are not telling the truth or lying to you. They don’t have gaps in their knowledge because they have no knowledge. They are digital parrots on cocaine.\nThe dataset used in this exercise is described in the paper Data from an International Multi-Centre Study of Statistics and Mathematics Anxieties and Related Variables in University Students (the SMARVUS Dataset) from the Journal of open Psychology Data.\nThe dataset is massive so as our first task, we want to write code that narrows it down and creates three different objects.\nFor the two scales, we need to pivot it to long-form and then calculate the mean score for each participant.\nWe would need this information if we wanted to try and answer questions like:\nBut we’ll start with the wrangling and see how far we get.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "06-writing.html#activity-1-set-up",
    "href": "06-writing.html#activity-1-set-up",
    "title": "\n6  Writing Code with AI\n",
    "section": "",
    "text": "Act like an expert programmer in R. I want you to help me write code. The code should be commented and should use the tidyverse where possible. Ask me questions about the code before you write it if necessary.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "06-writing.html#activity-2-knowledge-is-power",
    "href": "06-writing.html#activity-2-knowledge-is-power",
    "title": "\n6  Writing Code with AI\n",
    "section": "\n6.2 Activity 2: Knowledge is power",
    "text": "6.2 Activity 2: Knowledge is power\nWhen you input this starting prompt, there’s a good chance you’ll get something like the following:\n\n\n\n\nMore info needed\n\n\n\nBefore you ask the AI to write code, it’s helpful to give it as much information as you can about your dataset. You could write out a description manually but there’s a few options to automate.\nsummary() is useful because it provides a list of all variables with some descriptive statistics so that the AI has a sense of the type and range of data:\n\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2                                 \n\n\nstr() is also useful because it lists the variables, their data type, and the initial values for each variable. However, that means that you are giving it at least some of the raw data so you have to be very careful if you have sensitive / confidential data and you must ensure that any use of AI is in line with your data management plan. Using Copilot Enterprise means the data won’t be stored and used to train the AI further so it’s potentially the best option (which is not to say it’s safe or problem free, please be careful and critical!).\n\nstr(penguins)\n\ntibble [344 × 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n\nFinally, ls() provides a list of all the variables in a given object. It doesn’t provide any info on the variable type or sample, but that does mean it’s the most secure and depending on the task, this might be all the info you really need to give the AI. I would suggest starting with ls() and only scaling up if necessary (and your data isn’t sensitive):\n\nls(penguins)\n\n[1] \"bill_depth_mm\"     \"bill_length_mm\"    \"body_mass_g\"      \n[4] \"flipper_length_mm\" \"island\"            \"sex\"              \n[7] \"species\"           \"year\"             \n\n\nIn your AI of choice, input the following:\n\nhere are the variables in my data set\n\n\nls(penguins) [1] “bill_depth_mm” “bill_length_mm” “body_mass_g” “flipper_length_mm” [5] “island” “sex” “species” “year”\n\nWithout being asked, Copilot has provided some examples of how you might analyse this data using R and the code all works as intended.\n\n# Load the tidyverse package\nlibrary(tidyverse)\n\n# Assuming your data is in a dataframe called 'penguins'\n# Let's start by getting a summary of each numerical variable\npenguins %&gt;%\n  summarise(\n    Average_Bill_Depth = mean(bill_depth_mm, na.rm = TRUE),\n    Average_Bill_Length = mean(bill_length_mm, na.rm = TRUE),\n    Average_Body_Mass = mean(body_mass_g, na.rm = TRUE),\n    Average_Flipper_Length = mean(flipper_length_mm, na.rm = TRUE)\n  )\n\n\n\n\n\n\n\n\n\n\nAverage_Bill_Depth\nAverage_Bill_Length\nAverage_Body_Mass\nAverage_Flipper_Length\n\n\n17.15117\n43.92193\n4201.754\n200.9152\n\n\n\n\n# Now, let's see the distribution of species across different islands\npenguins %&gt;%\n  count(island, species) %&gt;%\n  ggplot(aes(x = island, y = n, fill = species)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Distribution of Penguin Species Across Islands\",\n       x = \"Island\",\n       y = \"Count\")\n\n\n\n\n\n\n# We can also explore the relationship between flipper length and body mass\npenguins %&gt;%\n  ggplot(aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point(aes(color = species)) +\n  geom_smooth(method = \"lm\") +\n  labs(title = \"Relationship Between Flipper Length and Body Mass\",\n       x = \"Flipper Length (mm)\",\n       y = \"Body Mass (g)\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n# If you want to perform more specific analyses or visualizations,\n# please let me know what you're interested in!\n\nI find this hugely problematic. Psychology has spent the last decade dealing with a replication and reproducibility crisis stemming in part because of questionable research practices. As a researcher, you should be making informed decisions as to how you analyse your data and I fear that this type of output is going to increase phishing and atheoretical, exploratory-as-confirmatory nonsense. What happens when the example code the AI spits out without being asked turns out to be a significant regression model that you would never have predicted or run yourself? Are you going to delete it? Or convince yourself that you were going to run it anyway and there’s a perfectly logical explanation?\nBefore I have a full blown existential crisis, let’s get back on track.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "06-writing.html#activity-3-writing-code",
    "href": "06-writing.html#activity-3-writing-code",
    "title": "\n6  Writing Code with AI\n",
    "section": "\n6.6 Activity 3: Writing code",
    "text": "6.6 Activity 3: Writing code\nFirst, we’ll aim to produce a table of descriptive statistics for body_mass_g and a histogram. Because it has the exact variable and object names, it should write code we can easily copy and paste:\n\nCreate a table of descriptive statistics for body mass and a histogram of that variable\n\nThis is ChatGPT’s output (Copilot was very similar):\nSome notes:\n\nI didn’t have to use the exact variable name body_mass_g, it has figured out from my request that’s the one I want to use.\nIt’s also figured out that we’re using the palmerpenguins dataset, although it hasn’t given us the code to load that package so if we just copied and pasted this into a fresh script without having loaded the data already, it wouldn’t work.\nIt’s used na.rm = TRUE to ignore missing values. This is a very common choice but remember it is a choice. You might not want this.\nSimilarly, it’s specified binwidth = 20 for the histogram. Looking at the data this seems like a reasonable binwidth to use, but again, it is a decision the AI has imposed and you must be aware of what you’re accepting.\nI am aware that I am using phrases like “choice” and “decision” that imbue the AI with consciousness. I know that’s not true, I just can’t figure out how to write it any other way.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "06-writing.html#activity-4-giving-the-ai-more-freedom",
    "href": "06-writing.html#activity-4-giving-the-ai-more-freedom",
    "title": "\n6  Writing Code with AI\n",
    "section": "\n6.7 Activity 4: Giving the AI more freedom",
    "text": "6.7 Activity 4: Giving the AI more freedom\nMy initial request to write code was relatively simple and relatively well-specified but let’s try an example where there’s more room for the AI to make choices.\n\nCreate a new variable that codes each penguin as chonky_boi if they’re a large male, chonky_gurl if they’re a large female, smol_boi if they’re a small male, and smol_boi if they’re a small female.\n\nThis prompt gives a lot of leeway. I haven’t specified what to call the new variable, what criteria should be used to determine large and small, or what to do with observations that are neither.\nChatGPT used percentiles to determine category, however, this code didn’t work - it returns all observations as “average”:\n\nIn this code:\n\n\nWe use the case_when() function to define the conditions based on sex and body mass to categorize the penguins.\n\n\nFor males with a body mass greater than the 75th percentile, they are categorized as “chonky_boi.” For females with a body mass greater than the 75th percentile, they are categorized as “chonky_gurl.”\n\n\nFor males with a body mass less than or equal to the 25th percentile, they are categorized as “smol_boi.” For females with a body mass less than or equal to the 25th percentile, they are also categorized as “smol_gurl.”\n\n\nAll other penguins are categorized as “average.”\n\n\nWe then use mutate() to create the new variable “chonkiness” based on these conditions.\n\nI will spare you the full adventure (my chat history is here if you’d like to see) but after quite a bit of back-and-forth I realised that in the dataset “male” and “female” should both be lowercase and the code ChatGPT gave me had capitalised them both. There is no substitute for knowing your data.\nOnce I changed this, it worked.\nCopilot used a median split and didn’t try and create a third category, which is a questionable choice because the wording of the prompt really implies there needs to be something that the penguins are larger or smaller than. The code did work out of the box but remember the Jurassic Park rule: just because you can, doesn’t mean you should.\nThis code is a good example of why LLMs are inherently Luddites, even if they produce working code. When there’s missing data, case_when() used to require you to specify the type of NA, in this case NA_character. This is very uninintuitive, particularly when you’re trying to teach beginner coders (how can missing data have a type? is an entirely reasonable question) so I was delighted when it updated to remove this requirement. Additionally, TRUE was also changed to default which is a bit more readable.\nHowever, these changes are not reflected in Copilot’s code suggestion because the training data is older than the most recent update to case_when(). This example is relatively minor but it’s important to recognise that if you only use these kinds of AI to write code, you will very quickly be writing outdated code and using deprecated functions.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "06-writing.html#activity-5-further-analysis",
    "href": "06-writing.html#activity-5-further-analysis",
    "title": "\n6  Writing Code with AI\n",
    "section": "\n6.8 Activity 5: Further analysis",
    "text": "6.8 Activity 5: Further analysis\nTo give one last example, I entered the following prompt:\n\nwrite me code to run a linear regression predicting body mass from sex. also include the code to perform necessary assumption tests using the easystats performance package.\n\nChatGPT refuses to forget that in my conversation history there was an issue with the code not being lowercase, so it’s now including functions to covert to lowercase, even though it’s completely unnecessary.\nIt’s also introduced an error. The function should be check_model() not check_assumptions(). I know this because I know the package. The further away you get from what you could do yourself, the harder it will be to fix any errors and check what it has gotten wrong.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "06-writing.html#conclusions-and-musings",
    "href": "06-writing.html#conclusions-and-musings",
    "title": "\n6  Writing Code with AI\n",
    "section": "\n6.5 Conclusions and musings",
    "text": "6.5 Conclusions and musings\nA large part of coding is looking up examples of code you’ve used before and then tweaking it to your new use case. If you use AI like this, then it can really help speed you up by giving you access to boiler plate code you can adapt. I also find it very useful for those functions that just refuse to stick in my brain - every time I try to change the labels on a faceted ggplot() I get it wrong. These days I just go straight to ChatGPT.\nAdditionally, if what you’re wanting to achieve is relatively simple - descriptive stats, basic plots, simple wrangling and cleaning - it can’t go that far wrong and it’s usually easy enough to spot when something is wrong.\nThese use cases work well because it’s your expertise that drives what the AI does and reviewing and tweaking the output is built-in to these workflows. These are the AI skills that everyone is going to need.\nBut using code written by an AI that you don’t understand is dangerous and irresponsible. Think of all the stupid errors it has made throughout this book, and then imagine someone using it to write code for their medical research. I dread to think of the impact that this abdication of responsibility and expertise is going to have (and will already be having).\nThis is a depressing way to end this book so I gave all three AIs the prompt:\n\nWrite me a fun piece of R code.\n\nCopilot on its way to Vegas (ok I actually quite like this one):\n\n# Simple Slot Machine in R\nset.seed(Sys.time()) # Seed for randomness based on current time\n\n# Function to spin the slot machine\nspin_slot_machine &lt;- function() {\n  fruits &lt;- c(\"🍒\", \"🍋\", \"🍊\", \"🍉\", \"🍇\", \"🍓\")\n  spin &lt;- sample(fruits, size = 3, replace = TRUE)\n  cat(\"Spinning... You got:\", spin, \"\\n\")\n  \n  if (length(unique(spin)) == 1) {\n    cat(\"Congratulations! You won! 🎉\\n\")\n  } else {\n    cat(\"Try again! 🍀\\n\")\n  }\n}\n\n# Spin the slot machine\nspin_slot_machine()\n\nSpinning... You got: 🍇 🍇 🍋 \nTry again! 🍀",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "webexercises.html",
    "href": "webexercises.html",
    "title": "Appendix A — Webexercises",
    "section": "",
    "text": "A.1 Example Questions",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Webexercises</span>"
    ]
  },
  {
    "objectID": "webexercises.html#example-questions",
    "href": "webexercises.html#example-questions",
    "title": "Appendix A — Webexercises",
    "section": "",
    "text": "A.1.1 Fill-In-The-Blanks (fitb())\nCreate fill-in-the-blank questions using fitb(), providing the answer as the first argument.\n\n2 + 2 is \n\n\nYou can also create these questions dynamically, using variables from your R session.\n\nThe square root of 25 is: \n\n\nThe blanks are case-sensitive; if you don’t care about case, use the argument ignore_case = TRUE.\n\nWhat is the letter after D? \n\n\nIf you want to ignore differences in whitespace use, use the argument ignore_ws = TRUE (which is the default) and include spaces in your answer anywhere they could be acceptable.\n\nHow do you load the tidyverse package? \n\n\nYou can set more than one possible correct answer by setting the answers as a vector.\n\nType a vowel: \n\n\nYou can use regular expressions to test answers against more complex rules.\n\nType any 3 letters: \n\n\nA.1.2 Multiple Choice (mcq())\n\n“Never gonna give you up, never gonna: \nlet you go\nturn you down\nrun away\nlet you down”\n“I \nbless the rains\nguess it rains\nsense the rain down in Africa” -Toto\n\nA.1.3 True or False (torf())\n\nTrue or False? You can permute values in a vector using sample(). \nTRUE\nFALSE\n\n\nA.1.4 Longer MCQs (longmcq())\nWhen your answers are very long, sometimes a drop-down select box gets formatted oddly. You can use longmcq() to deal with this. Since the answers are long, It’s probably best to set up the options inside an R chunk with echo=FALSE.\nWhat is a p-value?\n\nthe probability that the null hypothesis is truethe probability of the observed, or more extreme, data, under the assumption that the null-hypothesis is truethe probability of making an error in your conclusion\n\nWhat is true about a 95% confidence interval of the mean?\n\nthere is a 95% probability that the true mean lies within this rangeif you repeated the process many times, 95% of intervals calculated in this way contain the true mean95% of the data fall within this range",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Webexercises</span>"
    ]
  },
  {
    "objectID": "webexercises.html#checked-sections",
    "href": "webexercises.html#checked-sections",
    "title": "Appendix A — Webexercises",
    "section": "\nA.2 Checked sections",
    "text": "A.2 Checked sections\nCreate sections with the class webex-check to add a button that hides feedback until it is pressed. Add the class webex-box to draw a box around the section (or use your own styles).\n\nI am going to learn a lot: \nTRUE\nFALSE\nWhat is a p-value?\n\nthe probability that the null hypothesis is truethe probability of the observed, or more extreme, data, under the assumption that the null-hypothesis is truethe probability of making an error in your conclusion",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Webexercises</span>"
    ]
  },
  {
    "objectID": "webexercises.html#hidden-solutions-and-hints",
    "href": "webexercises.html#hidden-solutions-and-hints",
    "title": "Appendix A — Webexercises",
    "section": "\nA.3 Hidden solutions and hints",
    "text": "A.3 Hidden solutions and hints\nYou can fence off a solution area that will be hidden behind a button using hide() before the solution and unhide() after, each as inline R code. Pass the text you want to appear on the button to the hide() function.\nIf the solution is a code chunk, instead of using hide() and unhide(), simply set the webex.hide chunk option to TRUE, or set it to the string you wish to display on the button.\nRecreate the scatterplot below, using the built-in cars dataset.\n\n\n\n\n\n\n\n\n\n\nI need a hint\n\nSee the documentation for plot() (?plot)\n\n\n\n\n\nClick here to see the solution\n\nplot(cars$speed, cars$dist)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Webexercises</span>"
    ]
  },
  {
    "objectID": "01-intro.html#login",
    "href": "01-intro.html#login",
    "title": "\n1  Intro to using AI\n",
    "section": "\n1.3 Login",
    "text": "1.3 Login\n\n\n\n\n\n\nNoteActivity 1\n\n\n\nLogin to Copilot using your University of Glasgow account.\n\n\nAt the time of writing (September 2025), in order to access GPT-5, you need to toggle this on so make sure you also click the button in the top right that says “Try GPT-5”.\nRemember that “Copilot” is a family of tools. The link above takes you to Copilot Chat, which is the safest environment for coursework. Copilot in Word/Excel/PowerPoint may look slightly different but uses the same underlying model.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "01-intro.html#prompting",
    "href": "01-intro.html#prompting",
    "title": "\n1  Intro to using AI\n",
    "section": "\n1.4 Prompting",
    "text": "1.4 Prompting\nThe key difference between using an AI and a regular search engine is that you can shape the output of the AI by “prompt engineering”, which is the phrase used to describe the art of asking the question in a way that gives you the answer you want. It’s easier to show than tell.\n\n\n\n\n\n\nNoteActivity 2\n\n\n\nThink of a book, TV show, film, or video game that you know really well. I chose Final Fantasy VII (the original PlayStation version). Ask Copilot to give you three different summaries for different audiences.\n\nAsk it for a summary without any additional context e.g., “Give me a summary of Final Fantasy VII (original playstation version)”\nThen, ask it for a summary but give it a steer on the intended audience, e.g., “Give me a summary of Final Fantasy VII (original playstation version) for someone who knows nothing about videogames” or “Give me a summary of Final Fantasy VII (original playstation version) for an expert gamer who has played it many times”\nFinally, ask it for a summary, but give it a steer on how it should act, e.g., “Act as an expert videogame reviewer for the Guardian. Give me a summary of Final Fantasy VII (original playstation version) for an expert gamer who has played it many times” or “Act as someone who spends too much time on Reddit and thinks they know everything. Give me a summary of Final Fantasy VII (original playstation version) for an expert gamer who has played it many times”.\n\nReflect on the differences in the information and detail it gives you for each one and how you’re able to evaluate the accuracy of the summaries because of your existing expert knowledge.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "01-intro.html#copilot-features",
    "href": "01-intro.html#copilot-features",
    "title": "\n1  Intro to using AI\n",
    "section": "\n1.5 Copilot features",
    "text": "1.5 Copilot features\nWhilst many AIs use the same underlying model (e.g., GPT-5), the platforms can differ in their functionality.\n\n\n\n\nCopilot features\n\n\n\n\nThe “Read Aloud” function will get Copilot to read it’s response to you.\nThe “Share prompt and copy response” button will copy your prompt and the response which you can then paste into e.g., a Word document. This is useful because if you’re ever asked to provide more information on how you have used AI at University, you can use this feature to assist with being transparent.\nSuggested follow-up prompts give you ideas for further prompting (although I have never found these useful).\nThe dictate function allows you to speak your prompt to the AI. On a laptop you may have to ensure your microphone settings allow access. This is often easier on a phone.\n“Edit in Pages” opens an editable page so you can add to and edit the response. You can also then ask an additional prompt and add new responses and share with others. We’re not really going to use this feature but if you want to know more, Microsoft have additional info and training.\nAdd a file to Copilot to use as part of your prompt. Because you’re signed in using your UofG account it will automatically connect to your OneDrive. Even though Copilot connects securely to OneDrive, you should check your module handbook and lecturer guidance before uploading slides, datasets, or assignments. Not all materials are permitted to be shared with AI.\n\n\n\n\n\n\n\nNoteActivity 3\n\n\n\nTry out each of the six features described above and reflect on which ones you find useful and why.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#custom-instructions",
    "href": "02-personalise.html#custom-instructions",
    "title": "\n2  Personalised tutor\n",
    "section": "",
    "text": "Act as an expert tutor for the programming language R. I am a learner on the course “Applied Data Skills”. I have learned R in my first year and I have reasonably good general computer literacy. I will ask you questions about concepts and functions I do not understand based on my course materials. Always give me concrete examples when you provide an answer. Tailor your responses to my level of expertise. I am using R and RStudio on a Mac and the course will strongly use the tidyverse.\n\n\nAct as an expert tutor for the programming language R. I am a first year psychology student at the University of Glasgow and I am learning R for the first time. I have never learned a programming language before and I am not very confident with computers and I am anxious about learning programming. I have a Windows laptop. I will ask you questions about concepts and functions I do not understand based on my course materials. Always give me concrete examples when you provide an answer. Tailor your responses to my level of expertise. I am using R and RStudio and the course will strongly use the tidyverse.\n\n\n\nI am a Professor of Evidence-Informed Education in the School of Psychology and Neuroscience with expertise in cognitive psychology, individual differences, and teaching beginner data skills. You should be formal and give as much detail as possible in your responses. If I ask for code, always give me R code with a tidyverse solution where possible. Always use British spelling. Avoid being sycophantic, hyperbolic, using promotional language, negative parallelisms, or editorializing. Provide evidence for all claims. Preferably peer reviewed and within the last 5 years.\n\n\n\n\n\n\n\nNoteActivity 1\n\n\n\nWrite your custom instructions and enter them into Copilot. Exactly what information you provide is up to you but make sure that you explain your level of knowledge, skill, confidence and previous experience. If you’re using it for coding, you also want to give it some technical information about the software you’re using (e.g., R and RStudio) and your operating system (Windows).\n\nTo add your custom instructions in Copilot, click the three dots in the top right corner, then click settings, then Custom Instructions.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#socratic-tutor",
    "href": "02-personalise.html#socratic-tutor",
    "title": "\n2  Personalised tutor\n",
    "section": "\n2.4 Socratic tutor",
    "text": "2.4 Socratic tutor\nMost people use AI as a one-way explainer, but you can also ask it to act like a Socratic tutor. This means instead of giving you the answer straight away, the AI asks you guiding questions so that you recall or work out the idea for yourself. This is important because actively retrieving information strengthens your learning much more than passively re-reading.\nExample prompts you can try:\n\n“Act as a Socratic tutor. Do not tell me the answer yet. Ask me questions to guide me towards understanding correlation vs causation.”\n“Ask me a series of small questions until I can explain what a tibble is.” “Quiz me step by step on how the function filter() works in R. Only give me the next hint if I get stuck.”\n\nLearning often feels easier when you get a clear explanation, but you usually remember more when you struggle productively. The Socratic tutor style is designed to make you work a little, which improves long-term retention.\n\n\n\n\n\n\nNoteActivity 4\n\n\n\n\nFollow up on the responses it gave to your one of your three course questions with a similar prompt to the conversational examples give.\nThen for another one of the questions, follow-up with a request to check your understanding but acting as a Socratic tutor.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#be-critical",
    "href": "02-personalise.html#be-critical",
    "title": "\n2  Personalised tutor\n",
    "section": "\n2.5 Be critical",
    "text": "2.5 Be critical\nA personalised tutor is most powerful when it amplifies the cognitive processes that drive learning rather than replacing them. Three principles are central:\n\nMetacognition: monitor what you do and do not understand, then adjust your strategy and difficulty accordingly.\nDesirable difficulties: small, well-scaffolded challenges that require effort improve long-term retention when paired with feedback.\nSelf-explanation: articulating why an answer is right, how a step works, or why an alternative is wrong deepens understanding and transfer.\n\nUse your AI tutor to create space for retrieval, explanation, and calibration, not to short-circuit them. Based on the three principles, here are some things to watch out for.\n\nIf you provide detailed instructions (“I am anxious, please make it simple”), the AI may default to oversimplification. This risks the expertise reversal effect — information is too shallow once you gain competence.Similarly, if you do not revisit or revise instructions, you may “lock in” a static version of yourself (e.g., always a beginner), preventing growth and calibration.\nAsking the AI questions like “Why do I have to learn to code?” produces an explanation, but does not force you to generate an answer yourself. Research on retrieval practice shows that passive review is less effective for long-term retention.\nYou may accept AI answers at face value, especially if they “sound fluent.” The fluency illusion (e.g., when text feels easy to read) can lead to overconfidence.Unlike a lecturer who has genuine expertise, the AI cannot reliably detect specific misconceptions unless prompted very carefully. You might get partial reinforcement for incorrect ideas.\nLearning research shows benefits when you try, fail, and then see the solution. If AI always provides a clean solution first, you miss the benefits of “desirable difficulities”. Related, over-time, reliance on AI rather than working through the problem yourself will reduce your resilience, autonomy, and competence - you can only learn and believe you are capable of difficult things if you try and succeed at doing difficult things.\n\n\n\n\n\n\n\nTipKey takeaways\n\n\n\n\nTell Copilot who you are, what course you’re on, and your level of confidence. This makes answers more tailored.\nFollow up, ask for comparisons, or request simpler/more technical versions. This is how you refine understanding.\nInstead of answers, ask Copilot to quiz you step by step. This supports retrieval and deeper learning.\nAI can be over-confident and sometimes wrong. Always compare to course materials and test your own understanding.\nReading an AI explanation is easier than doing the work yourself, but retrieval, practice, and self-explanation build stronger memory.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "01-intro.html#criticality-and-ai",
    "href": "01-intro.html#criticality-and-ai",
    "title": "\n1  Intro to using AI\n",
    "section": "\n1.2 Criticality and AI",
    "text": "1.2 Criticality and AI\nWhen using AI, it is not enough to know how to operate the tools, you also need to approach them critically. That means asking not just “what can this do for me?” but also “how trustworthy is this output, and what are the wider implications of relying on it?”\nHere are some of the things that should always be in the back of your mind when using AI.\n\n1.2.1 Accuracy\nAI tools are trained to generate fluent and convincing text, but this does not mean it is correct. They frequently “hallucinate”, producing confident but false information such as incorrect references, fabricated statistics, or misattributed quotes. You should treat outputs as drafts or starting points, not final answers and verify with authoritative sources.\n\n1.2.2 Authority and Expertise\nAI cannot tell the difference between high-quality peer-reviewed research and a random blogpost unless explicitly instructed. It mirrors patterns in its training data rather than exercising judgement. Always consider who should be the authority on a question — a textbook, journal article, or your lecturer — and cross-check AI outputs accordingly.\n\n1.2.3 Transparency\nYou cannot see the training data or the “reasoning” steps of the model. That lack of transparency makes it hard to know why it gave a particular answer or whether it is missing key perspectives. Ask yourself what might have been left out or under-represented, and be cautious about treating AI answers as comprehensive.\n\n1.2.4 Epistemic Caution\nEpistemic caution means being careful about what you claim to know. AIs generate text that looks authoritative, which can give a false sense of understanding. This risks shallow learning if students accept outputs uncritically rather than grappling with concepts themselves - do you really know it or can you just repeat what the computer told you? Use AI as a “thinking partner,” but make sure you can explain ideas in your own words without relying on its phrasing.\n\n1.2.5 Equity and Access\nEven though UofG provides Copilot securely, in wider society access to premium AI tools is uneven. This creates new digital divides between those who can afford subscription services and those who cannot, or between those trained to use AI critically and those left behind. Reflect on whose voices are privileged or excluded in AI-mediated work.\n\n1.2.6 Over-reliance and deskilling\nOutsourcing too much to AI can erode your own skills in writing, problem-solving, or coding. Just as calculators changed how we teach arithmetic, AI may change what we expect students to be able to do unaided. Use AI strategically, but keep developing your own capacity, especially in core academic skills such as argumentation, critical reading, and data analysis.\n\n1.2.7 Copilot\nMicrosoft Copilot is not one single tool but a family of services (e.g., in Word, Excel, Edge, Outlook). In this book, we focus on Copilot Chat accessed via Office365 using your University account, because this is the secure, enterprise version.\nMicrosoft Copilot can be accessed at by signing into Office365 with your University of Glasgow student account. Whilst ChatGPT is the most widely known and used, the advantage of using your Enterprise account is that the data is processed more securely and what you input won’t be used to train the model.\nThis is really, really important and if you’re found to have uploaded sensitive data to an unsecure AI you can be accused of academic and/or research misconduct. So if you’re using AI for any University work, use Copilot.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "01-intro.html#be-critical",
    "href": "01-intro.html#be-critical",
    "title": "\n1  Intro to using AI\n",
    "section": "\n1.6 Be critical",
    "text": "1.6 Be critical\nGood AI use should strengthen, not substitute, your learning processes and your motivation to learn and this is what we’re going to try and convince you of throughout this book. Two additional ideas matter here.\nFirst, self-determination theory suggests that high-quality learning is supported when activities nurture autonomy (choice and voice), competence (a sense of effectiveness), and relatedness (feeling connected to others or to authentic goals).\nSecond, self-efficacy grows primarily through mastery experiences: every time you attempt an answer first, then use AI to check, refine, and correct, you accumulate evidence that you can succeed again. Over-scaffolding (“just tell me the answer”) risks undermining both autonomy and self-efficacy.\nThroughout this book we are going to ask you to reflect on how your use of AI might affect you psychologically because it’s not all about academic integrity and cheating, there are serious risks to you long-term success and resilience.\n\n\n\n\n\n\nTipKey takeaways\n\n\n\nReflect on the differences between the summaries - the technicality of the language, the accuracy and nuance of the information, what it chose to focus on, and what it chose to omit. The reason I asked you to create a summary of something you already know well is that you’re aware of where the gaps are. Remember this when you’re asking an AI something you don’t know as well. Just because you can’t see the gaps, inaccuracies, and biases, doesn’t mean they’re not there.\n\nTell it how to act\nTell it who you are\nAlways check for gaps, errors, or bias\nFluency ≠ truth and persuasive text may still be wrong\nAuthority matters! Ask yourself “who should be the expert here?”\nOver-reliance risks deskilling. Keep practising your own academic skills",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "03-testing.html#question-types",
    "href": "03-testing.html#question-types",
    "title": "\n3  Practice testing\n",
    "section": "",
    "text": "3.1.1 Questions that test recognition\n\n3.1.1.1 Multiple choice questions\nMCQs tests recognition and your ability to spot the best answer among distractors. Each item has a stem (the question) followed by four labelled options (A–D). Only one is correct. MQCs are efficient for covering a wide range of content, easy to self-check, and useful for practising discrimination between similar concepts. However, they can also encourage recognition more than recall, and can sometimes be answered by guessing or test-wise strategies.\nExample:\n\nWhich of the following functions is used to create a scatterplot in R? A) geom_bar() B) geom_point() C) geom_boxplot() D) geom_histogram()\n\n\n3.1.1.2 True-or-false (TOF)\nTOF questions are a quick way to check factual accuracy and basic conceptual understanding and involve a single statement for you to judge as true or false. TOF questions are very quick to complete and good for simple checks of knowledge but have a high chance of guessing correctly (50%) and can oversimplify complex concepts and have limited diagnostic value.\nExample:\n\nTrue or false? The mean() function in R returns the median of a numeric vector.\n\n\n3.1.1.3 Fill-in-the-blanks (coding)\nThese questions strengthen fluency with R syntax by making you supply missing functions or arguments but are easier than writing out the full code from scratch These questions involve a line of R code with a missing element. These questions support recall of key syntax and reduce cognitive load compared to writing from scratch but they can be too easy and may not transfer well to real coding tasks.\nExample:\n\nggplot(mtcars, aes(x = wt, y = mpg)) + ____()\n\n\n3.1.1.4 Fill-in-the-blanks (theory)\nSimilarly, for theory, FITB helps memorise key terms, definitions, or concepts without giving the full answer. These questions will be a sentence with 1–2 blanks, sometimes with hints. FIT is good for reinforcing vocabulary and key concepts and are quick to create and practise. But, there is a risk of rote memorisation without deeper understanding and answers may sometimes be ambiguous.\nExample:\n\n“A variable that can take on any value between two points is called a ______.”\n\n\n3.1.2 Questions that test production\n\n3.1.2.1 Short-answer-questions\nSAQs require you to recall and explain in your own words, building deeper understanding. These are focused, open questions that should be answered in &lt;100 words. SAQs promote active recall and deeper processing and are flexible enough to test conceptual understanding. However, they are harder to self-mark and may be more time-consuming to generate and answer.\nExample:\n\nExplain the difference between a categorical and a continuous variable.\n\n\n3.1.2.2 Coding problems\nCoding problems let you apply your skills to solve a real task, similar to authentic assessments. They usually involve a short programming challenge using a real dataset. Coding problems closely mimic real-world problem solving, encourage transfer of knowledge, and consolidate multiple skills at once. The higher difficulty can be discouraging for beginners and they may be harder to self-assess without feedback.\nExample:\n\n“Using the penguins dataset, create a boxplot of body mass grouped by species.”\n\n\n3.1.2.3 Error mode\nError mode is debugging practice which builds resilience and problem-solving skills, and teaches you to spot common mistakes. It involves a runnable piece of R code that contains one plausible error. Error mode develops error-detection and debugging skills and mirrors real-world coding experience. However, it can be frustrating for novices and requires baseline knowledge to be effective.\nExample:\n\nggplot(mtcars, aes(x = wt, y = mpg))\ngeom_point()\n\n\n(Error: missing + before geom_point())",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#practical-tip-built-in-datasets",
    "href": "03-testing.html#practical-tip-built-in-datasets",
    "title": "\n3  Practice testing\n",
    "section": "\n3.2 Practical tip: Built-in datasets",
    "text": "3.2 Practical tip: Built-in datasets\nWhen practising coding questions with AI, you need a dataset you can actually run code on. A common problem with AI-generated exercises is that it invents datasets or column names that do not exist, which makes it impossible to test your solution. One way to avoid this is to rely on built-in datasets.\nBuilt-in datasets in R are sample datasets that come pre-loaded with the software or with specific packages. They cover a variety of domains (e.g., cars, gemstones, movies, penguins) and are designed to help you practise data manipulation, analysis, and visualisation without importing external files.\nYou can get a full list of available datasets by running data() in the console. Base R provides some, and additional packages (e.g., tidyverse, palmerpenguins) add more. Remember that a package must be loaded before its datasets are accessible.\n\n# see list of datasets\ndata()\n\n# load tidyverse to get access to extra sets\nlibrary(tidyverse)\n\n# see list of datasets expanded to include tidyverse ones\ndata()\n\n# load in dataset to environment so it can be used\ndata(\"starwars\")",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#question-prompt",
    "href": "03-testing.html#question-prompt",
    "title": "\n3  Practice testing\n",
    "section": "\n3.3 Question prompt",
    "text": "3.3 Question prompt\nWe will now design a prompt that will set-up Copilot to give you different types of questions.\n\n\n\n\n\n\nNoteActivity 1\n\n\n\nEdit the below template to suit your needs. For example, change the role, the sources you’re going to use, and if relevant, the datasets it should draw on in constraints. You can also change the other details although most of them should work for you without any changes.\n\n\n\n\n\n\n\n\nTipTemplate prompt to copy and paste into Copilot\n\n\n\nRole: You are a strict practice-testing tutor for second year undergraduate students learning R.\nSources: I will paste Intended Learning Outcomes (ILOs), function lists, and glossary terms from my course Applied Data Skills.\nProtocol:\n\nAsk one question at a time of the requested type.\nDo not reveal the answer until I reply.\nDo not give the answer away in the suggested follow-up prompts. For example, for MCQs, give suggested prompts for each answer option, not just the correct answer.\nAfter I answer, mark it, then give a short explanation (2–4 sentences).\n\nConstraints:\n\nAll questions must align to ILOs and be challenging but fair.\nFor coding questions, avoid imaginary datasets or columns. Instead, use only use the following datasets: starwars, diamonds, penguins.\n\nControls I will use:\n\ntype: … (see list below)\ncalibrate: harder | easier\n\nQuestion Types (with rules):\n\nMCQ (Multiple choice) – 4 options (A–D), 1 correct. Plausible distractors. After marking, explain each option briefly.\nTOF (True/False) – One statement; avoid trivially true/false. After marking, if false, rewrite as a correct statement.\nSAQ (Short answer) – Ask about one concept. I should be able to answer in &lt;100 words. After marking, provide a 2–3 point ideal outline.\nFITB_code (Fill-in-the-blank: coding) – One line of R with a missing function/argument. Must run on an approved dataset. State expected output shape (e.g., “tibble: 3 × 2”).\nFITB_theory (Fill-in-the-blank: theory) – A statement with up to 2 blanks. Give part-of-speech hints (e.g., [noun]).\nCP (Coding problem) – Minimal complete example using an approved dataset. Specify columns that exist. Do not invent data.\nEM (Error mode) – Provide a minimal reproducible example that fails using a specified dataset. The code should include the call to load the dataset and any required packages. Include exactly one plausible beginner-level error but give no hint as to what the error is. State intended outcome. Hold back the fix until after I attempt a solution. Then reveal the correction and what it teaches.\n\nFirst action: Confirm readiness and ask me to provide the sources.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#sources",
    "href": "03-testing.html#sources",
    "title": "\n3  Practice testing\n",
    "section": "\n3.4 Sources",
    "text": "3.4 Sources\nOnce you have set up this prompt, you can give it the sources to work from—for example, copy and paste the ILOs, a list of functions, and/or key terms you want it to quiz you on. Do not worry about formatting: just paste the text in as it is.\n\n\n\n\n\n\nNoteActivity 2\n\n\n\nAdd in your sources for the content you want to study.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#be-critical",
    "href": "03-testing.html#be-critical",
    "title": "\n3  Practice testing\n",
    "section": "\n3.6 Be critical",
    "text": "3.6 Be critical\nEffective practice testing is not just about answering more questions; it is about engaging the cognitive processes that drive learning -again metacognition, desirable difficulties and self-explanation are key. The questions AI generates can be useful, but they can also introduce illusions of fluency and miscalibration.\n\n3.6.1 Multiple-choice / TOF / SAQ questions\n\nSometimes the answers are simply wrong. If you challenge the AI, it will usually correct itself—but it will also agree with you if you claim an answer is wrong when it is not. The risk is that you accidentally encode misinformation. Remember: AI does not “know” anything; it is a sophisticated pattern-matcher, not a reliable authority.\nIt may generate questions about functions or concepts not covered in your course, which can cause confusion and unnecessary anxiety.\nOccasionally it poses a question with multiple correct answers without making this clear, which is frustrating.\nIt may overemphasise particular topics or functions unless you explicitly direct it to vary the focus.\n\n3.6.2 Coding problems\n\nThe examples are not always reproducible. For instance, it might assume the existence of a dataset with variables called “number” and “price” but provide no such dataset, making it impossible to run the code. You can still attempt the problem, but this adds extra difficulty, especially for beginners.\nIt sometimes uses functions or approaches you have not been taught, such as defaulting to Base R instead of tidyverse.\n\n3.6.3 Error mode\n\nIn the first iteration of this book, AI could not create error mode problems - the code either ran fine or the errors were so stupid and obvious it was of no educational benefit. Models have improved, and they can now generate plausible errors, which is an interesting sign of progress.\nEven so, AI often hints heavily at the error or simply tells you the answer, which reduces the learning benefit.\nWhilst it can now generate plausible errors, it doesn’t have the benefit of years of teaching experience. When we design error mode questions, they’re based on our knowledge of what students frequently get wrong so AI error mode isn’t always as targeted and therefore as useful as questions written by an expert educator. Maybe our jobs are safe for a little while longer.\n\n\n\n\n\n\n\nTipKey Takeaways\n\n\n\n\nRegular retrieval strengthens memory more than re-reading or highlighting.\nChoose the right format for questions: MCQs/TOF are good for recognition and breadth but weaker for recall. SAQs/FITB ae better for active recall and vocabulary but risk of rote learning. Coding problems/Error mode are closest to authentic tasks, but require more effort and background knowledge.\nPaste ILOs, function lists, or glossaries into Copilot to ensure it’s specific to what you are studying. Avoid imaginary datasets—stick to built-in ones like mtcars, penguins, or iris.\nAI outputs can be wrong, misleading, or oddly focused. Correcting them is part of the learning process and strengthens metacognition.\nAI is a tool, not a teacher. It lacks expert judgement about what learners typically get wrong. Use it to supplement, not replace, structured practice and seeking help from your lectuers and tutors.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "03-testing.html#test-yourself",
    "href": "03-testing.html#test-yourself",
    "title": "\n3  Practice testing\n",
    "section": "\n3.7 Test yourself",
    "text": "3.7 Test yourself\n\nWhy does practice testing improve long-term retention?\n\n\nBecause it increases exposure to learning materials without requiring recall\nBecause it allows learners to memorise correct answers through repetition alone\nBecause it strengthens retrieval pathways by requiring effortful recall and feedback\nBecause it reduces cognitive load by simplifying the learning task\n\n\n\n\nWhat key difference distinguishes multiple-choice questions (MCQs) from short-answer questions (SAQs)?\n\n\nMCQs and SAQs both primarily measure recognition memory\nMCQs test recognition of correct information, while SAQs test recall and explanation in your own words\nSAQs are easier to write but harder to mark objectively than MCQs\nMCQs promote deeper understanding because they include distractors\n\n\n\n\nHow does regular self-testing affect a learner’s metacognitive accuracy?\n\n\nFrequent testing reduces metacognition because learners focus on results instead of processFrequent testing improves metacognitive calibration by revealing what learners actually know versus what they think they knowSelf-testing has no measurable effect on metacognitive accuracyTesting reduces motivation and therefore limits reflection on learning progress\n\n\n\n\n\nAI-generated questions can create  of fluency that make learners overestimate their understanding.\n\n\n\n\n\nWhat strategy makes AI-generated practice testing most effective? \nDoing as many questions as possible in one long session\nFocusing only on questions that feel easy to boost confidence\nSpacing practice over time, reflecting on feedback, and verifying answers using reliable course materials\nAllowing AI to correct all mistakes automatically to reduce frustration",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "04-errors.html#activity-5-document-errors",
    "href": "04-errors.html#activity-5-document-errors",
    "title": "\n4  Error checking and debugging\n",
    "section": "\n4.4 Activity 5: Document errors",
    "text": "4.4 Activity 5: Document errors\nIf you’re working in Rmd or Quarto, sometimes the errors will stem from your code chunk settings or YAML in the document.\nIn your Rmd or Qmd file, create a new code chunk and copy and paste the following:\n\npenguins %&gt;%\n  count()\n\nBut then delete one of the final back ticks (`) from the code chunk.\nThe code is fine, it provides a simple count of the number of observations in the dataset. But if you try and knit the file in Rmd you’ll get a very long error message and if you render the file in Quarto, it will work, but it won’t actually execute the code, it will just render it as text.\nIn these cases you have two options.\n\nCopy and paste the entire document into Copilot, not just the code but include the code chunks etc. This means it can see the formatting as well as the code.\nTake a screenshot. This can also sometimes help diagnose working directory issues if you include the files pane.\n\nIf you’re not at all sure where the issue is stemming from, you might need a combination of both. But whatever you do, make sure that you verify the explanation of the error, don’t trust it blindly.\n\n\n\n\nMissing the mark\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nI know I might be starting to sound like a broken record but please remember that artificial intelligence is not actually intelligent. It’s not thinking, it’s not making conscious decisions, it has no expert subject matter knowledge. No matter how helpful it is, you must always check the output of the code it gives you.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "04-errors.html#be-critical",
    "href": "04-errors.html#be-critical",
    "title": "\n4  Error checking and debugging\n",
    "section": "\n4.6 Be critical",
    "text": "4.6 Be critical\nFrom a cognitive science perspective, being critical when debugging with AI matters because learning is strongest when you engage in active processing rather than relying on external answers. Research on desirable difficulties shows that struggling with a problem, even briefly, improves long-term retention and transfer. Similarly, studies of self-explanation demonstrate that learners build deeper understanding when they articulate why an error occurred and how to fix it. If you immediately outsource error checking to AI, you bypass the very processes that consolidate your knowledge of syntax, functions, and debugging strategies.\nAnother benefit of practising debugging yourself before turning to AI, is the development of self-efficacy and autonomy. In Bandura’s terms, mastery experiences are the strongest source of self-efficacy: each time you locate and fix an error unaided, you build the expectation that you can do so again.\nAutonomy is likewise enhanced when you make choices about how to proceed rather than defaulting to external solutions. Framed through self-determination theory, brief, well-timed AI support can still help, provided it is autonomy-supportive (you decide when to ask), competence-supportive (it explains rather than replaces your reasoning), and scaffolded (assistance fades as you improve).\nIn practice: attempt a fix first, articulate a hypothesis about the bug, then use AI to test or refine that hypothesis. This preserves a sense of authorship over your code, strengthens future problem-solving, and reduces learned dependence on external help.\n\n\n\n\n\n\nTipKey Takeaways\n\n\n\n\nTry first, then ask AI. Read the error message, inspect recent edits, and attempt a fix before consulting AI. This strengthens understanding and builds self-efficacy.\nProvide full context. When you do use AI, include the code and the exact error message. Add brief intent (“what I meant to do”) and, if safe, a minimal reproducible example.\nKnow your data. Many “mystery” errors are case sensitivity, misspellings, or filtering mistakes. Use summary(), str(), or ls() to verify assumptions.\nProtect sensitive data. Prefer ls() first; only share summary()/str() outputs if your data management plan permits. Copilot Enterprise reduces but does not remove risk.\nExpect and learn common patterns in errors.\nState the goal. Tell AI what outcome you intended (e.g., “mean by species and sex”), not just the code, to help it detect functional (not just syntactic) errors.\nUse screenshots or full documents for format bugs. For Rmd/Qmd issues, share the whole document or a screenshot showing YAML, chunk fences, and working directory.\nTreat AI as scaffolding. Ask it to explain rather than replace reasoning, and fade assistance over time to preserve autonomy and develop durable debugging habits.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "04-errors.html#contextual-errors",
    "href": "04-errors.html#contextual-errors",
    "title": "\n4  Error checking and debugging\n",
    "section": "\n4.2 Contextual errors",
    "text": "4.2 Contextual errors\nA common issue is when the error stems from code earlier in your script, even though it shows up later.\nFor example, in this code, what we intended to do was to create a dataset that just has penguins from Biscoe Island and then calculate their mean body mass. This code will run, but it produces NaN as the value.\n\nbiscoe_penguins &lt;- penguins %&gt;%\n  filter(island == \"biscoe\")\n\nbiscoe_penguins %&gt;%\n  summarise(mean_mass = mean(body_mass_g))\n\n\n\n\nmean_mass\n\n\nNaN\n\n\n\n\n\nIf you just give an AI the code and the table and ask it to explain what’s happening, it will do its best but without knowing the dataset or what code has preceded it, it won’t give you the exact answer, although in this case it hints at it.\n\n\n\n\nCopilot giving its best guess\n\n\n\nThere’s a couple of things you can do at this point:\n\nGive the AI all the code you’ve used so far\nGive the AI more information about the dataset.\n\nYou can manually type out a description but there’s some functions you can use that can automate this.\nsummary() is useful because it provides a list of all variables with some descriptive statistics so that the AI has a sense of the type and range of data:\n\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2                                 \n\n\nstr() is also useful because it lists the variables, their data type, and the initial values for each variable.\n\nstr(penguins)\n\ntibble [344 × 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n\nFinally, ls() provides a list of all the variables in a given object. It doesn’t provide any info on the variable type or sample, but this might be all the info you really need to give the AI.\n\nls(penguins)\n\n[1] \"bill_depth_mm\"     \"bill_length_mm\"    \"body_mass_g\"      \n[4] \"flipper_length_mm\" \"island\"            \"sex\"              \n[7] \"species\"           \"year\"             \n\n\n\n\n\n\n\n\nCaution\n\n\n\nBe careful with sensitive data. str() and summary() reveal actual data values, so only use them if your data management plan permits it. Using Copilot Enterprise reduces (but does not remove) risk, since data is not used for model training. Start with ls(), which only lists variable names, and scale up if safe.\n\n\n\n\n\n\n\n\nNoteActivity 3\n\n\n\nRun summary(biscoe_penguins) and give the AI the output so that it better understands the structure and contents of the datasets.\nThen give it the code you used to filter the dataset.\n\n\nIf you haven’t spotted it by now, the error is that in the filter biscoe should be Biscoe with a capital B.\n\n\n\n\n\n\nImportant\n\n\n\nThere is no shortcut for knowing your data.\n\n\n\n\n\n\nCopilot getting very close",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "04-errors.html#incorrect-but-functional-code",
    "href": "04-errors.html#incorrect-but-functional-code",
    "title": "\n4  Error checking and debugging\n",
    "section": "\n4.3 Incorrect (but functional) code",
    "text": "4.3 Incorrect (but functional) code\nSometimes (often) when we write code, the issue isn’t that our code doesn’t work, but that it doesn’t do what we intended to do and we can’t figure out why.\nFor example, let’s say that we want to calculate the average body_mass_g for each species by sex. We’re feeling a bit lazy and we copy and paste in the following from a previous script we have:\n\npenguins %&gt;%\n  group_by(sex, species) %&gt;%\n  summarise(mean_body_mass = sd(body_mass_g, na.rm = TRUE))\n\n\n\n\nsex\nspecies\nmean_body_mass\n\n\n\nfemale\nAdelie\n269.3801\n\n\nfemale\nChinstrap\n285.3339\n\n\nfemale\nGentoo\n281.5783\n\n\nmale\nAdelie\n346.8116\n\n\nmale\nChinstrap\n362.1376\n\n\nmale\nGentoo\n313.1586\n\n\nNA\nAdelie\n477.1661\n\n\nNA\nGentoo\n338.1937\n\n\n\n\n\n\nWe know something isn’t right here. Because we’re responsible researchers, we’ve taken time to understand our dataset and what plausible values should be and we know there’s no way that the average body mass of a penguin is 269 grams (unless the penguin is made of chocolate). But the code is running fine, we know it’s worked before, and we can’t see what we’ve done wrong.\nYou can ask the AI to help you but you can’t just give it the code and output, you also need to tell it what you intended to do. The more complex your code, the more information you will need to give it in order for it to help you find the error.\n\n\n\n\nFixing a functional error\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThere is no AI tool that allows you to skip understanding the data you’re working with and knowing what it is you’re trying to do.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "04-errors.html#document-errors",
    "href": "04-errors.html#document-errors",
    "title": "\n4  Error checking and debugging\n",
    "section": "\n4.4 Document errors",
    "text": "4.4 Document errors\nIf you’re working in Rmd or Quarto, sometimes the errors will stem from your code chunk settings or YAML in the document.\n\n\n\n\n\n\nNoteActivity 4\n\n\n\n\nIn your Rmd or Qmd file, create a new code chunk and copy and paste the following:\n\n\npenguins %&gt;%\n  count()\n\n\nDelete one of the final back ticks (`) from the code chunk.\nTry and run the code and knit/render the file.\n\n\n\nThe code is fine, it provides a simple count of the number of observations in the dataset. But if you try and knit the file in Rmd you’ll get a very long error message and if you render the file in Quarto, it will work, but it won’t actually execute the code, it will just render it as text.\nIn these cases you have two options.\n\nCopy and paste the entire document into Copilot, not just the code but include the code chunks etc. This means it can see the formatting as well as the code.\nTake a screenshot. This can also sometimes help diagnose working directory issues if you include the files pane.\n\nIf you’re not at all sure where the issue is stemming from, you might need a combination of both. But whatever you do, make sure that you verify the explanation of the error, don’t trust it blindly.\n\n\n\n\n\n\nNoteActivity 5\n\n\n\nTry pasting the entire document into Copilot and/or providing a screenshot until it can diagnose the missing backtick.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nI know I might be starting to sound like a broken record but please remember that artificial intelligence is not actually intelligent. It’s not thinking, it’s not making conscious decisions, it has no expert subject matter knowledge. No matter how helpful it is, you must always check the output of the code it gives you.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "04-errors.html#activity-3",
    "href": "04-errors.html#activity-3",
    "title": "\n4  Error checking and debugging\n",
    "section": "\n4.3 Activity 3",
    "text": "4.3 Activity 3\nRun summary(biscoe_penguins) and give the AI the output so that it better understands the structure and contents of the datasets.\nThen give it the code you used to filter the dataset.\n::\nIf you haven’t spotted it by now, the error is that in the filter biscoe should be Biscoe with a capital B.\nThere is no shortcut for knowing your data.\n\n\n\n\nCopilot getting very close",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "05-review.html#adding-comments-with-ai",
    "href": "05-review.html#adding-comments-with-ai",
    "title": "\n5  Code review\n",
    "section": "\n5.2 Adding comments with AI",
    "text": "5.2 Adding comments with AI\nFirst we’ll use use the palmerpenguins dataset again.\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\ndata(\"penguins\")\n\nYou can use AI tools to help add comments to your code. Previous experience has taught us that we need to be a bit specific with what we want the AI to do so we’ll give it a clear prompt.\n\n\n\n\n\n\nCautionCaution!!!\n\n\n\nFor this chapter, be very, very careful to ensure you are using GPT-5, not GPT-4. The performance of GPT-5 is significantly better and avoids introducing errors into your code.\n\n\n\n\n\n\n\n\nNoteActivity 1\n\n\n\nIn Copilot, input the below code with the prompt:\n\nPlease add concise, helpful comments to this code. Explain what each main step does, not every line. If you are unsure about what a section of code is doing or why it exists, ask me a clarifying question. Do not change the code itself in any way.\n\n\npenguins_clean &lt;- penguins %&gt;%\n  filter(complete.cases(.)) %&gt;%\n  mutate(across(where(is.factor), as.character)) %&gt;%\n  mutate(species_sex = interaction(species, sex, sep = \"_\"))\n\n\n\nHere’s its suggested comments:\n\n# Clean data, convert factors to character, and create a combined label\npenguins_clean &lt;- penguins %&gt;% # start from the penguins data\n  filter(complete.cases(.)) %&gt;% # keep only rows with no missing values in any column\n  mutate(across(where(is.factor), as.character)) %&gt;%# convert all factor columns to character\n  mutate(species_sex = interaction(species, sex, sep = \"_\"))  # new factor combining species and sex, e.g., \"Adelie_female\"\n\nHowever, the AI can only tell you what the code is doing, it can’t say why you chose to do that. The more complex your analysis, the more crucial it becomes to explain the rationale and so ensuring your prompt encourages the AI to ask for clarification is vital and in order to be able to answer these questions you need to know your data and what you’re trying to achieve.\n\n\n\n\nAdding comments",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "05-review.html#review-existing-comments",
    "href": "05-review.html#review-existing-comments",
    "title": "\n5  Code review\n",
    "section": "\n5.3 Review existing comments",
    "text": "5.3 Review existing comments\nIn addition to asking AI to comment your code, you can also ask it to review comments you’ve made yourself. To see how this works with a more complex example, and as an act of masochism, I gave the AI some code I wrote for a publication. The full paper is here if you’re interested - the quant analyses ended up being punted to the online appendix because of word count.\n\n\n\n\n\n\nNoteActivity 2\n\n\n\nLoad in the dataset yourself with this code:\n\n# read in data but skip rows 2 and 3\ncol_names &lt;- names(read_csv(\"https://osf.io/download/tf3xs/\", n_max = 0))\ndat_raw &lt;- read_csv(\"https://osf.io/download/tf3xs/\", col_names = col_names, skip = 3) \n\n\n\nThe first section of my code involves quite a complicated and long bit of wrangling, all done in a single pipeline. The purpose of the code is to clean up data collected on the survey platform Qualtrics and recode some of the demographic variables. This is actually a shortened version because the original hit the character limit for Copilot. I did put some effort into writing comments before publication but there are almost certainly improvements to be made.\n\n\n\n\n\n\nNoteActivity 3\n\n\n\nProvide the code with the following prompt followed by the below code:\n\nPlease review the comments in my code and improve them where needed. Make comments clear, concise, and useful for someone reading the code for the first time. Keep the meaning of existing comments, but reword or simplify them for better readability.\n\n\nAdd comments only where they genuinely help understanding (e.g., explaining intent or logic, not obvious code). Do not change any of the code itself. After editing, explain your reasoning for each change — briefly describe why the original comment needed improvement (e.g., too long, unclear, redundant, missing context, etc.).\n\n\ndat &lt;- dat_raw%&gt;%\n  filter(Progress &gt; 94, # remove incomplete responses\n         DistributionChannel != \"preview\") %&gt;% # Remove Emily's preview data\n  select(ResponseId, \"duration\" = 5, Q5:Q21) %&gt;%\n  # replace NAs with \"none\" for disability info\n  mutate(disability_nos = replace_na(disability_nos, \"None\"),\n         physical_chronic = replace_na(physical_chronic, \"None\"),\n         mental_health = replace_na(mental_health, \"None\"),\n) %&gt;% # recode gender data\n  mutate(gender_cleaned = case_when(Q6 %in% c(\"Female\", \"female\", \"Woman\",\n                                              \"woman\", \n                                              \"Cisgender woman\",\n                                              \"female (she/her)\", \n                                              \"F\", \"f\", \"Womxn\", \n                                              \"Woman (tranas)\") ~ \"Woman\",\n                                    Q6 %in% c(\"Man\", \"man\", \"M\", \"m\", \n                                              \"Male (he/him)\", \"Male\",\n                                              \"male\", \"Trans man.\") ~\n                                      \"Man\",\n                                    Q6 %in% c(\"Agender\", \"Genderfluid\",\n                                    \"GNC\", \"NB\", \"non-binary\", \n                                    \"   Non-binary\", \"Non-Binary\",\n                                    \"Non-binary femme\", \"non-binary male\",\n                                    \"non binary\", \"Non binary\",\n                                    \"Nonbinary\", \"Queer\", \"Transmasculine\",\n                                    \"Non-binary\") ~ \"Non-binary\",\n                            TRUE ~ \"Not stated\")) %&gt;%\n  # select necessary columns and tidy up the names\n        select(ResponseId,\n             \"age\" = Q5,\n             \"gender\" = Q6,\n             \"mature\" = Q7,\n             \"level_study\" = Q8,\n             \"country\" = Q9,\n             \"subject\" = Q10,\n             \"english_first\" = Q11,\n             \"neurotype_open\" = Q13, \n             \"disability_open\" = Q14,\n             \"why_open\" = Q18,\n             \"how_open\" = Q23,\n             \"advantages\" = Q20,\n             \"disadvantages\" = Q21,\n             everything()) \n\n\n\n\n\n\n\n\n\nCautionHave I mentioned you need to be careful?\n\n\n\n\nIn an earlier version of this book, providing this prompt resulting in it changing the code without telling me so that not only did it not do what I intended, it also didn’t work so you need to be very, very careful.\nUsing GPT-4 for this task resulted in incorrect comments, which then affected subsequent reasoning and introduced errors into the code.\n\nIf you use AI without thinking and accidentally commit research fraud, don’t blame me, I did try and warn you :)\n\n\nTo check that it hasn’t changed any code you can run all.equal() to compare two datasets. If it returns true, it means that the result of your initial code and the new code are identical. This is a really important check.\nHere’s the code with the new comments:\n\n# this is the code copied from Copilot with the edited comments\n\ndat_copilot &lt;- dat_raw %&gt;%\n  filter(Progress &gt; 94, # keep responses with &gt;94% progress\n         DistributionChannel != \"preview\") %&gt;% # exclude preview/test responses\n  select(ResponseId, \"duration\" = 5, Q5:Q21) %&gt;%  # select ID, rename column 5 as 'duration', keep Q5–Q21\n  # fill missing disability-related fields with \"None\"\n  mutate(disability_nos = replace_na(disability_nos, \"None\"),\n         physical_chronic = replace_na(physical_chronic, \"None\"),\n         mental_health = replace_na(mental_health, \"None\"),\n  ) %&gt;%\n  # standardise gender responses into four categories\n  mutate(gender_cleaned = case_when(Q6 %in% c(\"Female\", \"female\", \"Woman\",\n                                              \"woman\", \n                                              \"Cisgender woman\",\n                                              \"female (she/her)\", \n                                              \"F\", \"f\", \"Womxn\", \n                                              \"Woman (tranas)\") ~ \"Woman\",\n                                    Q6 %in% c(\"Man\", \"man\", \"M\", \"m\", \n                                              \"Male (he/him)\", \"Male\",\n                                              \"male\", \"Trans man.\") ~\n                                      \"Man\",\n                                    Q6 %in% c(\"Agender\", \"Genderfluid\",\n                                    \"GNC\", \"NB\", \"non-binary\", \n                                    \"   Non-binary\", \"Non-Binary\",\n                                    \"Non-binary femme\", \"non-binary male\",\n                                    \"non binary\", \"Non binary\",\n                                    \"Nonbinary\", \"Queer\", \"Transmasculine\",\n                                    \"Non-binary\") ~ \"Non-binary\",\n                            TRUE ~ \"Not stated\")) %&gt;%\n  # rename key columns for clarity and keep all remaining variables\n  select(ResponseId,\n         \"age\" = Q5,\n         \"gender\" = Q6,\n         \"mature\" = Q7,\n         \"level_study\" = Q8,\n         \"country\" = Q9,\n         \"subject\" = Q10,\n         \"english_first\" = Q11,\n         \"neurotype_open\" = Q13, \n         \"disability_open\" = Q14,\n         \"why_open\" = Q18,\n         \"how_open\" = Q23,\n         \"advantages\" = Q20,\n         \"disadvantages\" = Q21,\n         everything())\n\n\n# then we can test if the two objects are identical to ensure it hasn't changed anything\n\nall.equal(dat, dat_copilot)\n\n[1] TRUE\n\n\nall.equal() returns true which means the two datasets are identical.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "05-review.html#refactoring-code",
    "href": "05-review.html#refactoring-code",
    "title": "\n5  Code review\n",
    "section": "\n5.4 Refactoring code",
    "text": "5.4 Refactoring code\nRefactoring means improving the structure of your code without changing what it does. You are not adding new features or fixing bugs, you are just making the code cleaner, easier to read, and easier to work with. Refactoring is like tidying your desk: everything still works the same, but it is more organised and makes future work easier.\nRefactoring:\n\nMakes your code easier to read so that you (and others) can quickly understand what it does later on.\nSimplifies your code by breaking big, messy pieces into smaller, easier-to-manage parts.\nKeeps your code easy to update as clean, consistent code makes it easier to fix bugs or add new features later.\nHelps you avoid and remove duplicated or unnecessary code.\nSometimes make it faster. Tidier code can help your program run more efficiently.\nCan help spot hidden problems. While cleaning up, you might notice bugs or logic errors that you had missed before.\n\n\n\n\n\n\n\nCautionCaution!!!\n\n\n\nAre you using GPT-5 as instructed? The next section goes very badly if you aren’t.\n\n\n\n\n\n\n\n\nNoteActivity 4\n\n\n\nWe’ll stick with the example of code from my publication because it’s complicated enough that there are likely improvements or alternative solutions. Enter the following prompt followed by the code (use the original, not the Copilot commented version):\n\nI would like you to refactor the following code. Keep the behaviour and output exactly the same, but make the code cleaner, easier to read, and more efficient. Please:\n\n\nAdd helpful comments where needed. Use clear and consistent variable and function names. Remove any unnecessary repetition. Break long sections into smaller, logical parts if possible. Follow good coding style for R and use a tidyverse approach where possible. After refactoring, briefly explain what changes you made and why.\n\n\n\nHere’s the refactored code it gave me:\n\n# Clean and prepare the survey data\ndat_copilot &lt;- dat_raw %&gt;%\n  # 1) Keep only near-complete, real responses\n  filter(\n    Progress &gt; 94,                          # exclude incomplete responses\n    DistributionChannel != \"preview\"        # exclude preview entries\n  ) %&gt;%\n  # 2) Retain core identifiers and items for analysis\n  #    Note: 'duration = 5' selects the 5th column by position and renames it to 'duration'\n  select(\n    ResponseId,\n    duration = 5,\n    Q5:Q21\n  ) %&gt;%\n  # 3) Impute missing values for disability-related items with \"None\"\n  mutate(\n    across(\n      c(disability_nos, physical_chronic, mental_health),\n      ~ tidyr::replace_na(.x, \"None\")\n    )\n  ) %&gt;%\n  # 4) Harmonise reported gender text into a clean categorical variable\n  mutate(\n    gender_cleaned = dplyr::case_when(\n      Q6 %in% c(\n        \"Female\", \"female\", \"Woman\", \"woman\", \"Cisgender woman\",\n        \"female (she/her)\", \"F\", \"f\", \"Womxn\", \"Woman (tranas)\"\n      ) ~ \"Woman\",\n      Q6 %in% c(\n        \"Man\", \"man\", \"M\", \"m\", \"Male (he/him)\", \"Male\",\n        \"male\", \"Trans man.\"\n      ) ~ \"Man\",\n      Q6 %in% c(\n        \"Agender\", \"Genderfluid\", \"GNC\", \"NB\", \"non-binary\",\n        \"    Non-binary\", \"Non-Binary\", \"Non-binary femme\",\n        \"non-binary male\", \"non binary\", \"Non binary\",\n        \"Nonbinary\", \"Queer\", \"Transmasculine\", \"Non-binary\"\n      ) ~ \"Non-binary\",\n      TRUE ~ \"Not stated\"\n    )\n  ) %&gt;%\n  # 5) Final tidy selection and renaming for analytical clarity\n  select(\n    ResponseId,\n    age            = Q5,\n    gender         = Q6,\n    mature         = Q7,\n    level_study    = Q8,\n    country        = Q9,\n    subject        = Q10,\n    english_first  = Q11,\n    neurotype_open = Q13,\n    disability_open= Q14,\n    why_open       = Q18,\n    how_open       = Q23,\n    advantages     = Q20,\n    disadvantages  = Q21,\n    dplyr::everything()\n  )\n\nAnd here’s the explanation:\nWhat changed and why\n\nStructured the pipeline into five clearly labelled stages. Improves readability and helps future maintainers understand intent at a glance without scanning each line.\nConsistent tidyverse style and explicit namespaces where helpful. Retained %&gt;%, used across() for grouped NA imputation, and added dplyr:: or tidyr:: qualifiers where ambiguity could arise in larger projects.\nReduced repetition safely Replaced three separate mutate() calls for NA handling with a single mutate(across(…)), which is more concise and makes the imputation intent explicit while keeping the exact same behaviour.\nClear, descriptive comments. Comments explain the purpose of each main step without annotating every line, matching your instruction and making the code easier to review.\nPreserved semantics of position-based selection for duration. Kept duration = 5 to ensure identical behaviour, as it renames the fifth column of the current data to duration.\n\nAgain, it’s very important to check that this refactored code has the same result as the original. There is no shortcut for knowing and checking your data.\n\nall.equal(dat, dat_copilot)\n\n[1] TRUE",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "04-errors.html#common-errors",
    "href": "04-errors.html#common-errors",
    "title": "\n4  Error checking and debugging\n",
    "section": "\n4.5 Common errors",
    "text": "4.5 Common errors\nCoding errors tend to repeat and there’s actually a fairly small set of errors you will make constantly. But you won’t learn these patterns if you always ask the AI.\n\nMissing or extra ()\nMissing or extra commas\nMissing or extra quotation marks\nTypos in object or variable names - remember R is case sensitive\nMissing + for ggplot()\nMissing |&gt; or %&gt;% for piped lines of code\nUsing = instead of ==\n\nWriting code but not running it so that e.g., a package isn’t loaded or an object isn’t created that you later need.\nTrying to perform a numerical operation on a character/factor variable (or vice versa).\n\nTo help boost your confidence in error checking and debugging, you can create Error Mode questions like we showed you in Chapter 3. You could ask it to give you examples based on the common list of errors noted above and work your way through them until you’re more comfortable spotting them in your own code.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "06-writing.html#the-problem",
    "href": "06-writing.html#the-problem",
    "title": "\n6  Writing Code with AI\n",
    "section": "",
    "text": "First, we want to create an object named demo that has the demographic information, age and gender. Age data has transformed into categories (e.g., 18-21) for anonymisation purposes. The option ‘Implausible’ describes values that were 99 or higher or 17 or lower.\nSecond, we want an object named STARS which will represent each participant’s score on the Statistics Anxiety Rating Scale (STARS; Cruise et al., 1985). Each item describes a situation involving statistics such as “Doing an examination in a statistics course” (test and class anxiety), “Interpreting the meaning of a table in a journal article” (interpretation anxiety), or “Going to ask my statistics teacher for individual help with material I am having difficulty understanding” (fear of asking for help).\nThird, we want an object named, IUS which will represent each participant’s score on the Intolerance of Uncertainty Scale – Short Form (IUS-SF; Carleton et al., 2007). The scale contains 2 subscales, Prospective Anxiety and Inhibitory Anxiety, each with 6 items. The Prospective Anxiety subscale includes statements such as, “The smallest doubt can stop me from acting”. The Inhibitory Anxiety subscale includes statements such as, “It frustrates me not having all the information I need”.\n\n\n\n\nWhat is the demographic make-up of the sample in terms of age and gender?\nHow is statistics anxiety and intolerance of uncertainty related?\nDo men and women differ in their level of statistics anxiety?\n\n\n\n\n\n\n\n\nNoteActivity 1\n\n\n\nFirst, download the dataset from the Open Science Framework. Create a new Quarto or Rmd document and ensure the dataset is in the same folder, as this document, and then run the below code in a new code chunk. This will load in the data and then it will create the three objects using the code I have written and the approach I have taken so that we can compare with how Copilot gets on.\nThis is such a large dataset that we will just select the columns we need, but bear in mind I have already made the task easier for the AI by doing so.\n\nlibrary(tidyverse)\n\n# load in the data and just select the columns we will need\n\ndat &lt;- read_csv(\"smarvus_complete_050524.csv\") |&gt;\n  select(unique_id, age, gender, Q7.1_1:Q7.1_24, Q14.1_1:Q14.1_12)\n\n# pull out demographic data\ndemo &lt;- dat %&gt;%\n  select(unique_id, age, gender) |&gt;\n  drop_na()\n\n# create statistics anxiety scale\n\nSTARS &lt;- dat %&gt;%\n  select(unique_id, Q7.1_1:Q7.1_24) %&gt;% # select the STARS columns\n  filter(Q7.1_24 == 1) %&gt;% # remove those who failed the attention check\n  select(-Q7.1_24) %&gt;% # remove the attention check column\n  pivot_longer(cols = Q7.1_1:Q7.1_23, names_to = \"item\", values_to = \"score\") %&gt;% # transform to long-form\n  group_by(unique_id) %&gt;% # group by participant\n  summarise(stars_score = mean(score)) %&gt;% # calculate mean STARS score for each ppt\n  ungroup() %&gt;% # ungroup so it doesn't mess things up later\n  drop_na() #  get rid of NAs so they don't cause us havoc\n\n# Intolerance of Uncertainty.\n\nIUS &lt;- dat %&gt;%\n  select(unique_id, Q14.1_1:Q14.1_12) %&gt;% # select the BNFE columns\n  pivot_longer(cols = Q14.1_1:Q14.1_12, names_to = \"item\", values_to = \"score\") %&gt;% # transform to long-form\n  group_by(unique_id) %&gt;% # group by participant\n  summarise(ius_score = mean(score)) %&gt;% # calculate mean IUS-SF score for each ppt\n  ungroup() %&gt;% # ungroup so it doesn't mess things up later\n  drop_na() #  get rid of NAs so they don't cause us havoc\n\n\n# join it all together\n\ndat_joined &lt;- left_join(demo, IUS) |&gt;\n  left_join(STARS)",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "06-writing.html#prompting",
    "href": "06-writing.html#prompting",
    "title": "\n6  Writing Code with AI\n",
    "section": "\n6.2 Prompting",
    "text": "6.2 Prompting\nNow we want to do some set-up to prompt the AI to help us write code that works and does what we want.\n\n\n\n\n\n\nNoteActivity 2\n\n\n\nIn Copilot, enter the following prompt:\n\nYou are an expert R programmer. Help me write tidyverse-first code. Before writing code, ask any clarifying questions needed about data, objectives, constraints, and outputs.When you do write code:\n\n\nUse tidyverse idioms (|&gt;, dplyr, ggplot2, tibble), no deprecated functions. Comment clearly and explain non-obvious choices (e.g., NA handling, binning, model specs). Be safe and reproducible: no setwd(), no absolute paths, no silent package installs; show any set.seed() if randomness is used. Handle missing data explicitly and avoid destructive transformations.\n\nWhen you input this starting prompt, there’s a good chance you’ll get something like the following:\n\n\n\n\nMore info needed",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "06-writing.html#activity-2",
    "href": "06-writing.html#activity-2",
    "title": "\n6  Writing Code with AI\n",
    "section": "\n6.3 Activity 2",
    "text": "6.3 Activity 2\nIn Copilot, enter the following prompt:\n\nYou are an expert R programmer. Help me write tidyverse-first code. Before writing code, ask any clarifying questions needed about data, objectives, constraints, and outputs.When you do write code:\n\n\nUse tidyverse idioms (|&gt;, dplyr, ggplot2, tibble), no deprecated functions. Comment clearly and explain non-obvious choices (e.g., NA handling, binning, model specs). Be safe and reproducible: no setwd(), no absolute paths, no silent package installs; show any set.seed() if randomness is used. Handle missing data explicitly and avoid destructive transformations.\n\nWhen you input this starting prompt, there’s a good chance you’ll get something like the following:\n\n\n\n\nMore info needed",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "06-writing.html#describing-your-dataset",
    "href": "06-writing.html#describing-your-dataset",
    "title": "\n6  Writing Code with AI\n",
    "section": "\n6.3 Describing your dataset",
    "text": "6.3 Describing your dataset\nAs I may have mentioned once or twice in this book, there is no substitute for knowing your data. For the dataset provided here, your first step as an analyst would be to read the paper in full so that you understand how and what data was collected, the scales of measurement, and information about missing data etc.\nIn addition to this domain knowledge, you can also use information R provides about the dataset to help you.\nsummary() is useful because it provides a list of all variables with some descriptive statistics so that the AI has a sense of the type and range of data:\n\nsummary(dat)\n\n  unique_id             age               gender              Q7.1_1     \n Length:12570       Length:12570       Length:12570       Min.   :1.000  \n Class :character   Class :character   Class :character   1st Qu.:2.000  \n Mode  :character   Mode  :character   Mode  :character   Median :3.000  \n                                                          Mean   :3.229  \n                                                          3rd Qu.:4.000  \n                                                          Max.   :5.000  \n                                                          NA's   :457    \n     Q7.1_2          Q7.1_3          Q7.1_4          Q7.1_5     \n Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   :1.000  \n 1st Qu.:2.000   1st Qu.:2.000   1st Qu.:2.000   1st Qu.:2.000  \n Median :3.000   Median :3.000   Median :3.000   Median :3.000  \n Mean   :2.696   Mean   :2.817   Mean   :2.858   Mean   :2.687  \n 3rd Qu.:4.000   3rd Qu.:4.000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :5.000   Max.   :5.000   Max.   :5.000   Max.   :5.000  \n NA's   :458     NA's   :453     NA's   :451     NA's   :457    \n     Q7.1_6          Q7.1_7          Q7.1_8          Q7.1_9        Q7.1_10     \n Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   :1.00   Min.   :1.000  \n 1st Qu.:1.000   1st Qu.:2.000   1st Qu.:3.000   1st Qu.:1.00   1st Qu.:3.000  \n Median :2.000   Median :3.000   Median :4.000   Median :2.00   Median :4.000  \n Mean   :2.424   Mean   :3.167   Mean   :3.841   Mean   :2.03   Mean   :3.647  \n 3rd Qu.:3.000   3rd Qu.:4.000   3rd Qu.:5.000   3rd Qu.:3.00   3rd Qu.:5.000  \n Max.   :5.000   Max.   :5.000   Max.   :5.000   Max.   :5.00   Max.   :5.000  \n NA's   :467     NA's   :461     NA's   :454     NA's   :457    NA's   :459    \n    Q7.1_11         Q7.1_12         Q7.1_13         Q7.1_14     \n Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   :1.000  \n 1st Qu.:2.000   1st Qu.:1.000   1st Qu.:2.000   1st Qu.:2.000  \n Median :3.000   Median :2.000   Median :3.000   Median :3.000  \n Mean   :2.698   Mean   :2.583   Mean   :3.374   Mean   :2.654  \n 3rd Qu.:4.000   3rd Qu.:4.000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :5.000   Max.   :5.000   Max.   :5.000   Max.   :5.000  \n NA's   :461     NA's   :454     NA's   :462     NA's   :459    \n    Q7.1_15         Q7.1_16         Q7.1_17         Q7.1_18     \n Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   :1.000  \n 1st Qu.:3.000   1st Qu.:2.000   1st Qu.:1.000   1st Qu.:1.000  \n Median :4.000   Median :3.000   Median :2.000   Median :2.000  \n Mean   :3.608   Mean   :2.711   Mean   :2.362   Mean   :2.461  \n 3rd Qu.:5.000   3rd Qu.:4.000   3rd Qu.:3.000   3rd Qu.:3.000  \n Max.   :5.000   Max.   :5.000   Max.   :5.000   Max.   :5.000  \n NA's   :452     NA's   :463     NA's   :457     NA's   :460    \n    Q7.1_19         Q7.1_20         Q7.1_21         Q7.1_22     \n Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   :1.000  \n 1st Qu.:2.000   1st Qu.:2.000   1st Qu.:1.000   1st Qu.:2.000  \n Median :2.000   Median :3.000   Median :2.000   Median :3.000  \n Mean   :2.612   Mean   :2.734   Mean   :2.576   Mean   :3.048  \n 3rd Qu.:4.000   3rd Qu.:4.000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :5.000   Max.   :5.000   Max.   :5.000   Max.   :5.000  \n NA's   :453     NA's   :458     NA's   :458     NA's   :463    \n    Q7.1_23         Q7.1_24         Q14.1_1         Q14.1_2     \n Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   :1.000  \n 1st Qu.:1.000   1st Qu.:1.000   1st Qu.:2.000   1st Qu.:3.000  \n Median :2.000   Median :1.000   Median :3.000   Median :4.000  \n Mean   :2.314   Mean   :1.161   Mean   :2.927   Mean   :3.465  \n 3rd Qu.:3.000   3rd Qu.:1.000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :5.000   Max.   :5.000   Max.   :5.000   Max.   :5.000  \n NA's   :460     NA's   :1306    NA's   :1497    NA's   :1500   \n    Q14.1_3         Q14.1_4         Q14.1_5         Q14.1_6     \n Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   :1.000  \n 1st Qu.:2.000   1st Qu.:2.000   1st Qu.:2.000   1st Qu.:1.000  \n Median :3.000   Median :3.000   Median :3.000   Median :2.000  \n Mean   :2.681   Mean   :2.974   Mean   :2.702   Mean   :2.527  \n 3rd Qu.:4.000   3rd Qu.:4.000   3rd Qu.:4.000   3rd Qu.:3.000  \n Max.   :5.000   Max.   :5.000   Max.   :5.000   Max.   :5.000  \n NA's   :1500    NA's   :1497    NA's   :1499    NA's   :1498   \n    Q14.1_7         Q14.1_8         Q14.1_9         Q14.1_10    \n Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   :1.000  \n 1st Qu.:2.000   1st Qu.:2.000   1st Qu.:2.000   1st Qu.:2.000  \n Median :3.000   Median :3.000   Median :3.000   Median :3.000  \n Mean   :3.008   Mean   :3.168   Mean   :2.667   Mean   :2.676  \n 3rd Qu.:4.000   3rd Qu.:4.000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :5.000   Max.   :5.000   Max.   :5.000   Max.   :5.000  \n NA's   :1498    NA's   :1500    NA's   :1499    NA's   :1496   \n    Q14.1_11        Q14.1_12   \n Min.   :1.000   Min.   :1.00  \n 1st Qu.:2.000   1st Qu.:2.00  \n Median :3.000   Median :3.00  \n Mean   :3.228   Mean   :2.64  \n 3rd Qu.:4.000   3rd Qu.:4.00  \n Max.   :5.000   Max.   :5.00  \n NA's   :1496    NA's   :1500  \n\n\nstr() is also useful because it lists the variables, their data type, and the initial values for each variable. However, that means that you are giving it at least some of the raw data so you have to be very careful if you have sensitive / confidential data and you must ensure that any use of AI is in line with your data management plan. Using Copilot Enterprise means the data won’t be stored and used to train the AI further so it’s potentially the best option (which is not to say it’s safe or problem free, please be careful and critical!).\n\nstr(dat)\n\ntibble [12,570 × 39] (S3: tbl_df/tbl/data.frame)\n $ unique_id: chr [1:12570] \"01057178\" \"0300b5f2\" \"03f6503b\" \"0601d699\" ...\n $ age      : chr [1:12570] \"18-21\" \"18-21\" \"22-25\" NA ...\n $ gender   : chr [1:12570] \"Male/Man\" \"Female/Woman\" \"Female/Woman\" NA ...\n $ Q7.1_1   : num [1:12570] 3 3 4 4 5 1 1 3 4 4 ...\n $ Q7.1_2   : num [1:12570] 5 4 4 4 4 1 2 1 4 3 ...\n $ Q7.1_3   : num [1:12570] 3 1 3 4 5 2 2 1 5 2 ...\n $ Q7.1_4   : num [1:12570] 4 5 4 5 5 2 3 3 3 3 ...\n $ Q7.1_5   : num [1:12570] 4 5 4 4 4 1 1 2 4 2 ...\n $ Q7.1_6   : num [1:12570] 4 4 3 2 4 1 1 2 1 3 ...\n $ Q7.1_7   : num [1:12570] 5 4 4 4 5 3 1 5 5 4 ...\n $ Q7.1_8   : num [1:12570] 5 2 5 5 5 3 4 4 3 4 ...\n $ Q7.1_9   : num [1:12570] 2 1 1 1 1 1 1 1 1 4 ...\n $ Q7.1_10  : num [1:12570] 4 3 4 4 5 2 1 2 2 4 ...\n $ Q7.1_11  : num [1:12570] 4 4 4 4 4 1 1 1 5 4 ...\n $ Q7.1_12  : num [1:12570] 2 1 1 2 4 1 4 1 4 3 ...\n $ Q7.1_13  : num [1:12570] 4 2 5 3 5 2 1 2 4 4 ...\n $ Q7.1_14  : num [1:12570] 4 5 4 2 5 2 1 4 2 5 ...\n $ Q7.1_15  : num [1:12570] 3 3 3 4 5 2 2 1 3 2 ...\n $ Q7.1_16  : num [1:12570] 2 4 2 4 5 1 2 2 5 3 ...\n $ Q7.1_17  : num [1:12570] 2 2 2 2 4 1 1 1 3 5 ...\n $ Q7.1_18  : num [1:12570] 4 1 5 2 5 1 1 3 4 2 ...\n $ Q7.1_19  : num [1:12570] 4 3 2 2 5 1 1 1 4 1 ...\n $ Q7.1_20  : num [1:12570] 5 4 4 4 4 1 1 3 4 2 ...\n $ Q7.1_21  : num [1:12570] 2 3 3 4 4 1 1 4 1 3 ...\n $ Q7.1_22  : num [1:12570] 5 4 4 5 4 1 1 2 4 3 ...\n $ Q7.1_23  : num [1:12570] 4 4 2 1 5 1 1 2 4 1 ...\n $ Q7.1_24  : num [1:12570] 1 1 1 1 1 1 1 1 1 1 ...\n $ Q14.1_1  : num [1:12570] 3 2 3 2 5 2 1 1 4 2 ...\n $ Q14.1_2  : num [1:12570] 3 2 4 5 5 3 4 1 2 3 ...\n $ Q14.1_3  : num [1:12570] 2 5 3 2 5 2 2 2 5 2 ...\n $ Q14.1_4  : num [1:12570] 1 2 3 5 4 2 5 1 4 2 ...\n $ Q14.1_5  : num [1:12570] 3 2 4 4 5 1 2 2 4 2 ...\n $ Q14.1_6  : num [1:12570] 2 4 3 2 3 1 2 5 3 2 ...\n $ Q14.1_7  : num [1:12570] 4 4 2 4 5 2 3 2 1 4 ...\n $ Q14.1_8  : num [1:12570] 3 4 4 5 4 3 4 5 5 2 ...\n $ Q14.1_9  : num [1:12570] 1 3 2 4 5 2 1 3 1 2 ...\n $ Q14.1_10 : num [1:12570] 2 2 2 5 4 1 1 2 4 3 ...\n $ Q14.1_11 : num [1:12570] 4 3 2 5 5 2 5 4 4 3 ...\n $ Q14.1_12 : num [1:12570] 2 3 2 2 5 1 1 1 4 2 ...\n\n\nFinally, ls() provides a list of all the variables in a given object. It doesn’t provide any info on the variable type or sample, but that does mean it’s the most secure and depending on the task, this might be all the info you really need to give the AI. I would suggest starting with ls() and only scaling up if necessary (and your data isn’t sensitive):\n\nls(dat)\n\n [1] \"age\"       \"gender\"    \"Q14.1_1\"   \"Q14.1_10\"  \"Q14.1_11\"  \"Q14.1_12\" \n [7] \"Q14.1_2\"   \"Q14.1_3\"   \"Q14.1_4\"   \"Q14.1_5\"   \"Q14.1_6\"   \"Q14.1_7\"  \n[13] \"Q14.1_8\"   \"Q14.1_9\"   \"Q7.1_1\"    \"Q7.1_10\"   \"Q7.1_11\"   \"Q7.1_12\"  \n[19] \"Q7.1_13\"   \"Q7.1_14\"   \"Q7.1_15\"   \"Q7.1_16\"   \"Q7.1_17\"   \"Q7.1_18\"  \n[25] \"Q7.1_19\"   \"Q7.1_2\"    \"Q7.1_20\"   \"Q7.1_21\"   \"Q7.1_22\"   \"Q7.1_23\"  \n[31] \"Q7.1_24\"   \"Q7.1_3\"    \"Q7.1_4\"    \"Q7.1_5\"    \"Q7.1_6\"    \"Q7.1_7\"   \n[37] \"Q7.1_8\"    \"Q7.1_9\"    \"unique_id\"\n\n\n\n\n\n\n\n\nNoteActivity 3\n\n\n\nNow we’re going to tell the AI about our dataset and what we’d like. For educational value, we’ll give it a purposefully brief description.\n\nI have a dataset from a paper on statistics anxiety. I want to pull out the demographic information, age and gender and I want to calculate each participant’s Statistic Anxiety score and their Intolerance of Uncertainty\n\n\nhere are the variables in my data set\n\n\n[1] “age” “gender” “Q14.1_1” “Q14.1_10” “Q14.1_11” “Q14.1_12” “Q14.1_2”\n[8] “Q14.1_3” “Q14.1_4” “Q14.1_5” “Q14.1_6” “Q14.1_7” “Q14.1_8” “Q14.1_9”\n[15] “Q7.1_1” “Q7.1_10” “Q7.1_11” “Q7.1_12” “Q7.1_13” “Q7.1_14” “Q7.1_15”\n[22] “Q7.1_16” “Q7.1_17” “Q7.1_18” “Q7.1_19” “Q7.1_2” “Q7.1_20” “Q7.1_21”\n[29] “Q7.1_22” “Q7.1_23” “Q7.1_24” “Q7.1_3” “Q7.1_4” “Q7.1_5” “Q7.1_6”\n[36] “Q7.1_7” “Q7.1_8” “Q7.1_9” “unique_id”\n\n\n\nThe number of questions Copilot asks in response to this prompt really does hammer home my point that there is no substitute for knowing your data, I won’t copy them all here but you get the idea:\nWhich instruments are these items from?\n\nAre Q14.1_* the Statistics Anxiety items and Q7.1_* the Intolerance of Uncertainty items (or vice versa)?\nWhat are the exact scales used? For example, common options are: Statistics anxiety: STARS (Cruise et al.), SAM (Earp), or newer short forms. Intolerance of Uncertainty: IUS-27 or IUS-12 (Carleton et al.). The correct scoring (including reverse‑scored items) depends on the instrument and version.\n\nResponse scales and coding\n\nWhat are the response options and numeric mapping? For example, Likert 1–5 or 1–7, with higher numbers indicating more of the construct.\nAre any items reverse‑scored? If yes, please list them (e.g., Q14.1_3, Q14.1_7, …). If you are unsure, I can map once you confirm the instrument.\n\nMissing data handling\n\nWhat rule should we apply per scale? Common options: Person‑mean imputation if ≤20% of items missing on a scale, else set the scale score to NA. Require complete data (no imputation). Impute with item median across participants.\nPlease specify your preferred approach per scale.\n\nDemographics\n\nAge: is it numeric years? Any range checks to apply (e.g., set implausible ages &lt;16 or &gt;100 to NA)?\nGender: current values and required recode? For example, keep original categories, or recode to levels such as “woman”, “man”, “non‑binary”, “prefer not to say”, “other”. Any harmonisation rules you prefer?\n\n\n\n\n\n\n\nNoteActivity 4\n\n\n\nAgain for educatoinal value, we’re going to be lazy and give it minimal information. The questions it asks you will be slightly different to the ones above but they will be similar enough that this response should still work. Reply to Copilot with the following:\n\nQuestions 7 are the Statistics Anxiety items and Q14 are the Intolerance of Uncertainty items. I only want complete cases. I don’t know anything else.\n\n\n\nCopilot then produces the code based on the minimal information you’ve given it. We’ll get to whether it works in the next step but regardless of whether it does, I find this hugely problematic. Psychology and many other fields have spent the last decade dealing with a replication and reproducibility crisis stemming in part because of questionable research practices. As a researcher, you should be making informed decisions as to how you analyse your data and even when I have admitted I don’t know almost anything about my data, it has provided the code.\n“Vibe coding” like this is going to increase phishing and atheoretical, exploratory-as-confirmatory nonsense. What happens when the example code the AI spits out without being asked turns out to be a significant regression model that you would never have predicted or run yourself? Are you going to delete it? Or convince yourself that you were going to run it anyway and there’s a perfectly logical explanation?\nBefore I have a full blown existential crisis, let’s get back on track.\n\n\n\n\n\n\nNoteActivity 5\n\n\n\nHere’s the code Copilot produced, run it and see if it works. If you’ve prompted it yourself you can also use the version it produced for you (which will be slightly different to mine. You may need to update the object name so it creates a unique name rather than dat which will overwrite the original and we need to compare them.\nSpoiler alert: the code doesn’t work (also look at it, it’s much more complicated than it needs to be).\n\n# Load packages (tidyverse-first, no installs here)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(readr)\nlibrary(stringr)\nlibrary(tibble)\nlibrary(ggplot2) # not required for scoring, but commonly loaded\n\n# ---- Configuration ---------------------------------------------------------\n\n# 1) Provide your data frame here. Replace `df` with your actual object name or\n#    add a readr call (e.g., read_csv(\"relative/path.csv\")).\n#    The script assumes columns exactly as you listed:\n#    \"age\", \"gender\", Q14.1_1:Q14.1_12, Q7.1_1:Q7.1_24, and \"unique_id\".\ndat_copilot &lt;- dat  # &lt;-- replace if your object is named differently\n\n# 2) Identify item columns by pattern (robust to potential ordering).\nstats_items &lt;- grep(\"^Q7\\\\.1_\\\\d+$\", names(dat), value = TRUE)   # Statistics Anxiety items\niu_items    &lt;- grep(\"^Q14\\\\.1_\\\\d+$\", names(dat), value = TRUE)  # Intolerance of Uncertainty items\n\n# Sanity checks: stop early if required columns are missing\nrequired_cols &lt;- c(\"unique_id\", \"age\", \"gender\", stats_items, iu_items)\nmissing_cols &lt;- setdiff(c(\"unique_id\", \"age\", \"gender\"), names(dat))\nif (length(stats_items) == 0) stop(\"No Statistics Anxiety items (Q7.1_*) found.\")\nif (length(iu_items) == 0)    stop(\"No Intolerance of Uncertainty items (Q14.1_*) found.\")\nif (length(missing_cols) &gt; 0) stop(paste(\"Missing required column(s):\", paste(missing_cols, collapse = \", \")))\n\n# ---- Helper: safe numeric coercion for item responses ----------------------\n# Many survey exports store Likert responses as strings (e.g., \"4\", \"Strongly agree (5)\").\n# We parse numeric content only; non-parsable entries become NA (and will be excluded by complete-case rule).\nparse_items_numeric &lt;- function(x) {\n  # parse_number is tolerant to labels like \"5 - Strongly agree\"; returns NA if no digits\n  readr::parse_number(x, na = c(\"\", \"NA\", \"N/A\", \"NaN\", \"Missing\"))\n}\n\n# ---- Scoring ---------------------------------------------------------------\n\nscored &lt;-\n  dat_copilot |&gt;\n  # Keep only variables we need to avoid accidental modification of other fields\n  select(all_of(c(\"unique_id\", \"age\", \"gender\", stats_items, iu_items))) |&gt;\n  # Coerce age to numeric carefully; do not destructively overwrite original elsewhere\n  mutate(\n    age = suppressWarnings(parse_number(age))\n  ) |&gt;\n  # Coerce item responses to numeric. We do this separately for each scale to allow per-scale complete-case rules.\n  mutate(\n    across(all_of(stats_items), parse_items_numeric),\n    across(all_of(iu_items),    parse_items_numeric)\n  ) |&gt;\n  # Compute totals with explicit missing-data handling:\n  # - Because you requested complete cases, we first flag participants who have *all* item responses for each scale.\n  mutate(\n    stats_complete = if_all(all_of(stats_items), ~ !is.na(.x)),\n    iu_complete    = if_all(all_of(iu_items),    ~ !is.na(.x))\n  ) |&gt;\n  # Compute totals only for complete cases; leave as NA otherwise (we will filter next)\n  mutate(\n    stats_anxiety_total = if_else(\n      stats_complete,\n      rowSums(across(all_of(stats_items)), na.rm = FALSE), # na.rm = FALSE enforces completeness\n      NA_real_\n    ),\n    iu_total = if_else(\n      iu_complete,\n      rowSums(across(all_of(iu_items)), na.rm = FALSE),\n      NA_real_\n    )\n  ) |&gt;\n  # Keep only participants who are complete on *both* scales, as requested\n  filter(stats_complete & iu_complete) |&gt;\n  # Select final output columns in a tidy participant-level tibble\n  transmute(\n    unique_id,\n    age,\n    gender,\n    stats_anxiety_total,\n    iu_total\n  )\n\nError in `mutate()`:\nℹ In argument: `across(all_of(stats_items), parse_items_numeric)`.\nCaused by error in `across()`:\n! Can't compute column `Q7.1_1`.\nCaused by error in `parse_vector()`:\n! is.character(x) is not TRUE\n\n# ---- Result ----------------------------------------------------------------\nscored\n\nError: object 'scored' not found\n\n\n\n\nI’m going to save you the back-and-forth it required to get the code to work but briefly:\n\nThe error was because it was trying to parse a numeric variable as a character variable.\nOnce I fixed this, it calculated sum scores not mean scores. Which I spotted because I knew what the plausible range of values for the mean should be.\nThen it calculated the mean scores incorrectly. I only knew this because I had the correct scores from my version of the code. This is very dangerous because these values looked entirely plausible.\nOne of the reasons it did this, is that I had failed to tell it that item Q7.1_24 is an attention check and that only participants who answered 1 to that question should be included - so that’s my fault for not giving it enough information.\nThe other differences were in how it handled missing data. These weren’t necessarily wrong but they were a choice and it may not be a choice you intended to make.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "06-writing.html#activity-3",
    "href": "06-writing.html#activity-3",
    "title": "\n6  Writing Code with AI\n",
    "section": "\n6.5 Activity 3",
    "text": "6.5 Activity 3\nNow we’re going to tell the AI about our dataset and what we’d like, so we’ll give it a version of the description I provided above, although crucially, I am not going to tell it the approach (separate objects and pivot to long-form).\n\nI have a dataset from a paper on statistics anxiety. I want to pull out the demographic information, age and gender and I want to calculate each participant’s Statistic Anxiety score and their Intolerance of Uncertainty\n\n\nhere are the variables in my data set\n\n\n[1] “age” “gender” “Q14.1_1” “Q14.1_10” “Q14.1_11” “Q14.1_12” “Q14.1_2”\n[8] “Q14.1_3” “Q14.1_4” “Q14.1_5” “Q14.1_6” “Q14.1_7” “Q14.1_8” “Q14.1_9”\n[15] “Q7.1_1” “Q7.1_10” “Q7.1_11” “Q7.1_12” “Q7.1_13” “Q7.1_14” “Q7.1_15”\n[22] “Q7.1_16” “Q7.1_17” “Q7.1_18” “Q7.1_19” “Q7.1_2” “Q7.1_20” “Q7.1_21”\n[29] “Q7.1_22” “Q7.1_23” “Q7.1_24” “Q7.1_3” “Q7.1_4” “Q7.1_5” “Q7.1_6”\n[36] “Q7.1_7” “Q7.1_8” “Q7.1_9” “unique_id”",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "06-writing.html#break-it-down",
    "href": "06-writing.html#break-it-down",
    "title": "\n6  Writing Code with AI\n",
    "section": "\n6.4 Break it down",
    "text": "6.4 Break it down\nOne of the reasons this is going so wrong is because I have asked it to do too much at once. A better approach is to break down the code into small chunks. Once you can verify each chunk is working, you can then combine and refactor it (if you’re starting to think that it might just be easier to write the code yourself and then review it, yes, yes it would).\n\n\n\n\n\n\nNoteActiivty 6\n\n\n\nWe want to start fresh so start a new Copilot chat then enter the prompt from Activity 2 again.\nNow we’re going to try and do the same thing again but we’re going to break down the steps and ask for smaller chunks each time. Follow-up on the set-up prompt with the following:\n\nHere is my dataset. First, I want to create an object named demo_copilot that has the participant id, age, and gender. Age is categorical. Remove any participant who is missing any information.\n\n\nls(dat) [1] “age” “gender” “Q14.1_1” “Q14.1_10” “Q14.1_11” “Q14.1_12” “Q14.1_2”\n[8] “Q14.1_3” “Q14.1_4” “Q14.1_5” “Q14.1_6” “Q14.1_7” “Q14.1_8” “Q14.1_9”\n[15] “Q7.1_1” “Q7.1_10” “Q7.1_11” “Q7.1_12” “Q7.1_13” “Q7.1_14” “Q7.1_15”\n[22] “Q7.1_16” “Q7.1_17” “Q7.1_18” “Q7.1_19” “Q7.1_2” “Q7.1_20” “Q7.1_21”\n[29] “Q7.1_22” “Q7.1_23” “Q7.1_24” “Q7.1_3” “Q7.1_4” “Q7.1_5” “Q7.1_6”\n[36] “Q7.1_7” “Q7.1_8” “Q7.1_9” “unique_id”\n\n\n\n\n# Create demo_copilot with participant ID, categorical age, and gender\n# Remove rows with any missing values in these columns\ndemo_copilot &lt;- dat |&gt;\n  select(unique_id, age, gender) |&gt;\n  rename(participant_id = unique_id) |&gt;\n  mutate(age = as.factor(age),\n    gender = as.factor(gender))|&gt;\n  drop_na(participant_id, age, gender)\n\nNow check if this matches our original code:\n\nall.equal(demo, demo_copilot)\n\n[1] \"Names: 1 string mismatch\"                                             \n[2] \"Component \\\"age\\\": Modes: character, numeric\"                         \n[3] \"Component \\\"age\\\": Attributes: &lt; target is NULL, current is list &gt;\"   \n[4] \"Component \\\"age\\\": target is character, current is factor\"            \n[5] \"Component \\\"gender\\\": Modes: character, numeric\"                      \n[6] \"Component \\\"gender\\\": Attributes: &lt; target is NULL, current is list &gt;\"\n[7] \"Component \\\"gender\\\": target is character, current is factor\"         \n\n\nNo but the differences are potentially not problematic in that they stem from the fact that Copilot has explicitly converted age and gender to factors and my original code just left them as character. Additionally, it has also renamed unique_id as participant_id, which was entirely unnecessary and may cause some issues if you didn’t notice, but the data is at least right.\n\n\n\n\n\n\nNoteActivity 7\n\n\n\nNow try and reproduce the objects IUS and STARS using AI to write the code to create IUS_copilot and STARS_copilot version.\nIf you manage to get this to work, reflect on how much information you had to give it and how you acquired this knowledge.\nIf you can’t get them to match, reflect on what knowledge you might be missing to get it to do the task",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "01-intro.html#test-yourself",
    "href": "01-intro.html#test-yourself",
    "title": "\n1  Intro to using AI\n",
    "section": "\n1.7 Test yourself",
    "text": "1.7 Test yourself\n\nWhat is the main difference between an AI model and an AI platform?\n\n\nA model is the company that owns the AI, and a platform is the type of computer it runs onA model is the underlying language system, and a platform is the app or interface that uses itA model is always multimodal, and a platform never isThere is no real difference\n\n\n\n\n\nOpenAI’s most recent model at the time of writing is GPT-, which is also used by Microsoft Copilot.\n\n\n\n\n\nWhich of the following is not listed in the chapter as a key ethical concern about AI?\n\n\nBias and discrimination in training dataHidden human labour in data moderationLack of transparency about training sourcesOver-representation of animal behaviour in datasets\n\n\n\n\n\nEpistemic caution” means:\n\n\nAvoiding any use of AI at universityBeing careful about what you claim to know and recognising that fluent text is not always trueUsing AI outputs only when they are properly referencedAsking AI to simplify complex ideas for you\n\n\n\n\n\nAccording to self-determination theory, which three elements support high-quality learning?\n\n\nAccuracy, efficiency, and convenienceAutonomy, competence, and relatednessCuriosity, creativity, and collaborationMotivation, confidence, and control",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to using AI</span>"
    ]
  },
  {
    "objectID": "06-writing.html#be-critical",
    "href": "06-writing.html#be-critical",
    "title": "\n6  Writing Code with AI\n",
    "section": "\n6.5 Be critical",
    "text": "6.5 Be critical\nIn terms of your psychological and cognitive development, the warnings of this chapter are similar to those in previous chapters: if you don’t write the code yourself, you won’t gain those mastery experiences that support the development of self-efficacy and competence. Additionally, working through the code yourself requires you to understand your data and is essentially a form of self-explanation which will further impact your competence and ability to produce anything autonomously.\nBut my biggest warning for this chapter is not about your psychological development, but rather the integrity of your work. If you worked through Activity 7 properly you’ll understand that the amount of information you have to provide in order to get AI to write correct code is so extensive, you might as well just have written it yourself and used AI to fix any resulting errors.\nThis is why the prophesised AI productivity boom has not come to pass. Now that the technology has been around for a while, instead, what we’re seeing is that time saved on doing the task is being spent on cleaning up AI slop. Programmers who use AI are found to be no faster (and in some cases slower), they just spend more time debugging errors AI has introduced rather than writing code.\nThis integrity issue isn’t just about students cheating on their homework. The scientific literature is already full of AI garbage. There will be medical “treatments” being prescribed based on AI fabricated/analysed data that at best don’t work and at worst are harmful. Code written by AI is significantly increasing security risks.\nThe world has changed and for those of us that value integrity and expertise it feels like we are fighting a losing battle. My greatest challenge to you isn’t about coding, instead, it is to resist every psychological urge that tells all of us to take the easy route. Respect yourself and your abilities. Spend hours figuring out what the bloody hell is wrong with your data. Learn how to do things properly. If nothing else, you’ll be one of a increasingly small pool who can and that is going to become very valuable, very quickly.\n\n\n\n\n\n\nNoteKey takeaways\n\n\n\n\nThere is no substitute for knowing your data. At minimum, you need to know what your variables are, what the range of plausible values are, how you want to handle missing data, and you need to know what you intended to do and why.\nIf you ask AI to write code from scratch, break it down into small chunks.\nThe more specific you can be, the better the AI will do.\nAlways verify what it produces. Sometimes you can do this with code, sometimes you need your domain knowledge of the data.\n\n\n\nThis is a depressing way to end this book so I gave Copilot the prompt:\n\nWrite me a fun piece of R code.\n\nAnd it took me to Vegas (ok I actually quite like this):\n\n# Simple Slot Machine in R\nset.seed(Sys.time()) # Seed for randomness based on current time\n\n# Function to spin the slot machine\nspin_slot_machine &lt;- function() {\n  fruits &lt;- c(\"🍒\", \"🍋\", \"🍊\", \"🍉\", \"🍇\", \"🍓\")\n  spin &lt;- sample(fruits, size = 3, replace = TRUE)\n  cat(\"Spinning... You got:\", spin, \"\\n\")\n  \n  if (length(unique(spin)) == 1) {\n    cat(\"Congratulations! You won! 🎉\\n\")\n  } else {\n    cat(\"Try again! 🍀\\n\")\n  }\n}\n\n# Spin the slot machine\nspin_slot_machine()\n\nSpinning... You got: 🍋 🍋 🍒 \nTry again! 🍀",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "02-personalise.html#test-yourself",
    "href": "02-personalise.html#test-yourself",
    "title": "\n2  Personalised tutor\n",
    "section": "\n2.6 Test yourself",
    "text": "2.6 Test yourself\n\nWhy are custom instructions important when using an AI as a personalised tutor?\n\n\nThey ensure the AI can access your private course materialsThey permanently fix the AI to one topic so it cannot change contextThey help the AI tailor explanations to your level, background, and software setupThey prevent the AI from asking follow-up questions\n\n\n\n\n\nThe purpose of using a Socratic tutor approach is to:\n\n\nGet faster and clearer answers from the AIEncourage active recall and deeper learning by answering guided questionsAvoid making mistakes during study sessionsReplace feedback from human tutors entirely\n\n\n\n\n3.Metacognition means monitoring what you  and understand, and adapting your learning strategies accordingly.\n\n\n\n\nWhat is the expertise reversal effect?\n\n\nWhen experts deliberately study beginner materials to refresh their skillsWhen instructional support that benefits novices becomes counterproductive once you gain competenceWhen guidance that once helped becomes unhelpful as your knowledge increasesWhen AI stops following your custom instructions due to system updates\n\n\n\n\n\nAccording to research on desirable difficulties, what kind of learning conditions lead to stronger long-term retention?\n\n\nEffortless practice with immediate, perfect answersSmall, effortful challenges that require thought and feedbackPassive rereading of well-written AI explanationsOnly working on tasks you already find easy",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Personalised tutor</span>"
    ]
  },
  {
    "objectID": "06-writing.html#test-yourself",
    "href": "06-writing.html#test-yourself",
    "title": "\n6  Writing Code with AI\n",
    "section": "\n6.6 Test yourself",
    "text": "6.6 Test yourself\n\nWhy is it dangerous to assume that an AI coding assistant “knows” what it is doing?\n\n\nBecause it might not have been trained on the most recent R syntax\nBecause it does not possess reasoning or understanding—its output is pattern prediction, not knowledge\nBecause it sometimes generates syntax errors due to poor tokenisation\nBecause it prefers certain libraries over others\n\n\n\n\nWhen Copilot produced incorrect STARS mean scores, the root cause was that it calculated  instead of means.\n\n\n\n\n\nYou are working with a sensitive dataset that includes demographic and psychological measures. Which of the following is the most responsible approach when prompting an AI model?\n\n\nCopy-paste a few example rows into the chat so the model can infer variable typesUse summary() or str() to describe the dataset to the AI, regardless of sensitivityStart by providing only variable names (e.g., with ls()), scaling up detail only if necessary and safeSend the full CSV file because Copilot Enterprise does not store data\n\n\n\n\n\nWhich psychological mechanism is most strengthened when you work through code rather than accept AI output uncritically? \nAutomaticity from repeated syntax exposure\nMastery experiences that build self-efficacy and competence\nTransfer of learning through imitation\nCognitive load reduction through delegation\n\n\n\n\n\n\nA student uses AI to generate R code for their dissertation dataset, but does not document what the AI produced versus what they wrote. Which statement best describes the issue?\n\n\nIt is acceptable because AI tools are considered standard assistive technologyIt is fine if the final code runs correctlyIt raises transparency and authorship concerns because the analytical process cannot be audited or replicatedIt only violates policy if the AI was paid for using institutional funds",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Writing Code with AI</span>"
    ]
  },
  {
    "objectID": "03-testing.html#test-yourself-1",
    "href": "03-testing.html#test-yourself-1",
    "title": "\n3  Practice testing\n",
    "section": "\n3.7 Test yourself",
    "text": "3.7 Test yourself\n\nWhy does practice testing improve long-term retention?\n\n\nBecause it increases exposure to learning materials without requiring recall\nBecause it allows learners to memorise correct answers through repetition alone\nBecause it strengthens retrieval pathways by requiring effortful recall and feedback\nBecause it reduces cognitive load by simplifying the learning task\n\n\n\n\nWhat key difference distinguishes multiple-choice questions (MCQs) from short-answer questions (SAQs)?\n\n\nMCQs and SAQs both primarily measure recognition memory\nMCQs test recognition of correct information, while SAQs test recall and explanation in your own words\nSAQs are easier to write but harder to mark objectively than MCQs\nMCQs promote deeper understanding because they include distractors\n\n\n\n\nHow does regular self-testing affect a learner’s metacognitive accuracy?\n\n\nFrequent testing reduces metacognition because learners focus on results instead of processFrequent testing improves metacognitive calibration by revealing what learners actually know versus what they think they knowSelf-testing has no measurable effect on metacognitive accuracyTesting reduces motivation and therefore limits reflection on learning progress\n\n\n\n\n\nAI-generated questions can create  of fluency that make learners overestimate their understanding.\n\n\n\n\n\nWhat strategy makes AI-generated practice testing most effective? \nDoing as many questions as possible in one long session\nFocusing only on questions that feel easy to boost confidence\nSpacing practice over time, reflecting on feedback, and verifying answers using reliable course materials\nAllowing AI to correct all mistakes automatically to reduce frustration",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  },
  {
    "objectID": "04-errors.html#test-yourself",
    "href": "04-errors.html#test-yourself",
    "title": "\n4  Error checking and debugging\n",
    "section": "\n4.7 Test yourself",
    "text": "4.7 Test yourself\n\nWhen using AI for debugging, you should provide both the  and the  to help it accurately diagnose the problem.\n\n\n\n\n\nWhen might summary() or str() be unsafe to share with AI?\n\n\nWhen the dataset has been previously published under open licenseWhen the dataset contains sensitive or confidential data, because these functions reveal actual valuesWhen using RStudio instead of VS Code, because summary() behaves differentlyWhen the dataset includes factors or characters that the AI cannot parse\n\n\n\n\n\nWhat is the best strategy for prompting AI when your code runs but produces unexpected results?\n\n\nProvide only the output so the AI can infer what went wrongProvide the code, the intended outcome, and a short description of what seems incorrectAsk the AI to rewrite the entire function from scratch to ensure correctnessSend only the error message since the code is functional\n\n\n\n\n\nAccording to self-determination theory, how can AI support autonomy during debugging?\n\n\nBy providing step-by-step solutions before the user attempts a fix\nBy explaining rather than replacing reasoning, allowing the learner to choose when and how to seek help\nBy automatically fixing code errors without user input\nBy suggesting unrelated optimisations to expand the learner’s knowledge\n\n\n\n\nWhy is struggling briefly with a coding error beneficial for learning?\n\n\nBecause cognitive overload forces the learner to memorise the correct syntaxBecause effortful problem-solving creates desirable difficulties that strengthen retention and transfer of debugging skillsBecause frustration reduces confidence and lowers the chance of repeating the same mistakeBecause debugging replaces the need for structured practice or feedback",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Error checking and debugging</span>"
    ]
  },
  {
    "objectID": "05-review.html#test-yourself",
    "href": "05-review.html#test-yourself",
    "title": "\n5  Code review\n",
    "section": "\n5.6 Test yourself",
    "text": "5.6 Test yourself\n\nWhy can AI assist in code review but not replace a human reviewer? \nBecause AI tools cannot access RStudio’s environment variables\nBecause AI can only detect missing commas and syntax errors\nBecause AI lacks domain knowledge and intent—it can describe what code does, but not whether it does the right thing\nBecause AI cannot interpret comments embedded in R scripts\n\n\n\n\n\n\nWhy should you never upload your research data to AI for code review?\n\nTo rewrite code so that it matches the reviewer’s preferred styleTo ensure that code runs correctly, is reproducible, auditable, and follows best practices without altering its intended behaviourTo replace inefficient code with faster alternatives regardless of readabilityTo simplify all code into a single consistent template across projects\n\n\n\n\n\n\n\nWhat is the purpose of adding comments to code?\n\nTo satisfy formal documentation requirements onlyTo clarify the logic and purpose of code for human readers without affecting executionTo improve runtime performance by reducing computationTo make AI-generated code easier to parse\n\n\n\n\n\n\n\nWhat is the main distinction between commenting and refactoring? \nCommenting explains existing code; refactoring changes the code structure without changing outputs\nCommenting explains what and why; refactoring improves organisation and efficiency while preserving behaviour\nBoth are the same if code readability improves\nRefactoring focuses on aesthetics, while commenting affects execution\n\n\n\n\n\n\nHow does writing your own code comments support learning and motivation?\n\n\nIt allows you to memorise function syntax without understanding logicIt promotes self-explanation, builds mastery experiences, and strengthens self-efficacy through active engagementIt reduces the need for metacognitive reflection and deliberate practiceIt ensures that AI-generated comments remain concise and accurate",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "05-review.html#be-critical",
    "href": "05-review.html#be-critical",
    "title": "\n5  Code review\n",
    "section": "\n5.5 Be critical",
    "text": "5.5 Be critical\nFrom both cognitive science and motivational psychology, writing your own comments and understanding your code before refactoring are key to developing genuine expertise and confidence. As we’ve mentioned several times already, research on retrieval practice shows that learning is stronger when you produce information yourself rather than copying or reading it. Writing your own code comments works like taking your own lecture notes: the act of explaining what your code does, in your own words, strengthens understanding and recall. Similarly, elaboration - adding meaning and connections - helps transform isolated code into a coherent mental model of whatever it is you’re doing\nThese processes also feed into psychological needs identified in self-determination theory: competence, autonomy, and relatedness. Each time you explain your code or verify that a refactor still works, you experience a small mastery moment, evidence that you can and do actually understand and control what you are doing. These mastery experiences are the foundation of self-efficacy, the belief that you can succeed in similar tasks in the future. Over time, writing and refining your own comments builds both technical skill and the confidence to tackle new coding challenges independently.\nBy contrast, outsourcing explanations or edits to AI may help short-term efficiency but undermines these motivational and cognitive benefits. When an AI provides ready-made comments or “cleaner” code, it might fuel the Dunning-Kruger effect, the systematic tendancy of people with low ability to over-estimate their competence. This false fluency weakens both comprehension and autonomy: the more you depend on external solutions, the less opportunity you have to consolidate your own knowledge and sense of competence.\nIn practice: write your own comments first, then use AI to critique or refine them. When refactoring, ensure you can explain what each variable represents, why each step exists, and how the data should behave before you let AI suggest changes. Doing so keeps you in control, supports your autonomy as a learner, and transforms code review from a mechanical task into an act of understanding.\n\n\n\n\n\n\nTipKey takeaways\n\n\n\nI hadn’t used AI to perform these types of tasks before writing this book so here’s my takeaways:\n\nDID I MENTION? CHECK EVERYTHING.\nIf you give an AI code, you simply cannot trust that it won’t change your code, even if that’s not the task you ask it to do. If you use AI to add or review comments, you must check the output. Tools like all.equal() can help perform these checks.\nYou also can’t trust that the comments will be accurate. Anything an AI writes must be checked before you use it. If you don’t know if it’s right, don’t use it.\nBecause you have to check what it does so carefully, don’t give it a big dump of code. Smaller chunks will end up taking less time.",
    "crumbs": [
      "AI Pair Programmer",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Code review</span>"
    ]
  },
  {
    "objectID": "03-testing.html#generate-questions",
    "href": "03-testing.html#generate-questions",
    "title": "\n3  Practice testing\n",
    "section": "\n3.5 Generate questions",
    "text": "3.5 Generate questions\nYou can now ask it to generate questions for you by typing mcq or coding problem. If the questions seem too easy or hard, you can adjust them by using calibrate: easier or calibrate: harder\n\n\n\n\n\n\nNoteActivity 3\n\n\n\nAsk if for one question of each type and work through them. Reflect on whether they are challenging enough, if they align with your course content, and how they might differ from practice questions you have been given by a human.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nThe suggested follow-up prompts in Copilot sometimes indicate what the correct answer is, particularly for closed-questions like MCQs. I’ve not found a reliable way to stop it from doing this - let me know if you crack it.",
    "crumbs": [
      "Personal Tutor",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Practice testing</span>"
    ]
  }
]